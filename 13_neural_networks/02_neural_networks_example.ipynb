{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b>NEURAL NETWORKS: EXAMPLE</b></font>\n",
    "\n",
    "<font size=\"5\"><b>Serhat Çevikel</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(data.table) # to handle the data in a more convenient manner\n",
    "library(tidyverse) # for a better work flow and more tools to wrangle and visualize the data\n",
    "library(plotly) # for interactive visualizations\n",
    "library(neuralnet) # for neural network model\n",
    "library(NeuralNetTools) # for visualizing neural nets\n",
    "library(fastDummies) # for dummification\n",
    "library(caret) # for confusion matrix\n",
    "library(MASS) # for data\n",
    "library(Metrics) # for model fit criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.matrix.max.rows=20, repr.matrix.max.cols=15) # for limiting the number of top and bottom rows of tables printed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath <- \"~/databa\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![xkcd](../imagesba/trained_a_neural_net.png)\n",
    "\n",
    "(https://xkcd.com/2173/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two examples in this session for neural networks:\n",
    "\n",
    "- In the first example, we are going to use the Google trends and stock market dataset. These daily data (between 2008 and 2009) can be used to examine the associations between Google search trends and the daily market index - Dow Jones Industrial Average.\n",
    "\n",
    "    Example adapted from:\n",
    "\n",
    "    Data Science and Predictive Analytics: Biomedical and Health Applications using R,\n",
    "\n",
    "    By Ivo D. Dinov, 2018\n",
    "\n",
    "    Chapter 11:\n",
    "\n",
    "    https://books.google.com.tr/books?id=g-xqDwAAQBAJ&lpg=PR2&pg=PA382#v=onepage&q&f=false\n",
    "    \n",
    "- In the second example, we are going to use the Boston Housing Dataset, from a study carried out in 1978 concerning the median prices of housing in 506 residential areas of Boston, MA, USA.\n",
    "\n",
    "    Example adapted from:\n",
    "    \n",
    "    Deep Learning Made Easy with R\n",
    "    \n",
    "    By Nigel Da Costa Lewis, 2016\n",
    "    \n",
    "    https://books.google.com.tr/books/about/Deep_Learning_Made_Easy_with_R.html?id=8rk8jwEACAAJ\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Trends and Stock Market Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables are:\n",
    "\n",
    "- Index: Time Index of the Observation\n",
    "- Date: Date of the observation (Format: YYYY-MM-DD)\n",
    "- Unemployment: The Google Unemployment Index tracks queries related to \"unemployment, social, social security, unemployment benefits\" and so on.\n",
    "- Rental: The Google Rental Index tracks queries related to “rent, apartments, for rent, rentals,” etc.\n",
    "- RealEstate: The Google Real Estate Index tracks queries related to “real estate, mortgage, rent, apartments” and so on.\n",
    "- Mortgage: The Google Mortgage Index tracks queries related to \"mortgage, calculator, mortgage calculator, mortgage rates\".\n",
    "- Jobs: The Google Jobs Index tracks queries related to \"jobs, city, job, resume, career, monster\" and so forth.\n",
    "- Investing: The Google Investing Index tracks queries related to \"stock, finance,capital, yahoo finance, stocks\", etc.\n",
    "- DJI_Index: The Dow Jones Industrial (DJI) index. These data are interpolated from 5 records per week (Dow Jones stocks are traded on week-days only) to 7 days per week to match the constant 7-day records of the Google-Trends data.\n",
    "- StdDJI: The standardized-DJI Index computed by: StdDJI ¼ 3 + (DJI-11,091)/ 1,501, where m ¼ 11,091 and s ¼ 1,501 are the approximate mean and standard-deviation of the DJI for the period (2005–2011).\n",
    "- 30-Day Moving Average Data Columns: The 8 variables below are the 30-day moving averages of the 8 corresponding (raw) variables above.\n",
    "    - Unemployment30MA,Rental30MA, RealEstate30MA, Mortgage30MA, Jobs30MA, Investing30MA, DJI_Index30MA, StdDJI_30MA\n",
    "- 180-Day Moving Average Data Columns: The 8 variables below are the 180-day moving averages of the 8 corresponding (raw) variables.\n",
    "    - Unemployment180MA, Rental180MA, RealEstate180MA, Mortgage180MA, Jobs180MA, Investing180MA, DJI_Index180MA, StdDJI_180MA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the RealEstate as our dependent variable.\n",
    "\n",
    "Let’s see if the Google Real Estate Index could be predicted by other variables in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google <- fread(sprintf(\"%s/csv/GoogleTrends_Markets_Data.csv\", datapath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First view the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(google)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may delete the first two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google[,c(\"Index\", \"Date\") := NULL]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the numeric ranges of variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google %>% lapply(class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google %>% purrr::keep(is.numeric) %>% sapply(quantile, na.rm = T) %>% t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now normalize the values to range 0-1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_norm <- google %>% transmute_all(BBmisc::normalize, \"range\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And check the ranges again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_norm %>% purrr::keep(is.numeric) %>% sapply(quantile, na.rm = T) %>% t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN for numeric prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "train <- google_norm[,sample(.I, 0.75 * .N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_train <- google_norm[train]\n",
    "google_test <- google_norm[-train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First keep variable names in a vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namess <- names(google_norm)\n",
    "namess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_model <- neuralnet::neuralnet(RealEstate ~ Unemployment + Rental + Mortgage + Jobs + Investing + DJI_Index + StdDJI,\n",
    "                                     data = google_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_model$result.matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuralNetTools::plotnet(google_model, cex_val = 0.4, line_stag = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have only a single hidden node H1. B2 and B2 are bias values - constant values, similar to intercept in linear regression\n",
    "\n",
    "The width of lines show the strength of weights and the color is black for positive and gray for negative weights "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function garson() obtains and plots (using the ggplot2 infra-structure) a bar plot with the feature relevance\n",
    "scores of each of the input variables. It is interesting to observe the ranking of the features provided by the garson() function:\n",
    "\n",
    "(From \n",
    "\n",
    "Data Mining with R: Learning with Case Studies, Second Edition\n",
    "\n",
    "By Luis Torgo, 2017\n",
    "\n",
    "https://books.google.com.tr/books?id=2aedDQAAQBAJ&lpg=PP1&pg=PP1#v=onepage&q&f=false\n",
    "\n",
    "Chapter 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuralNetTools::garson(google_model) + theme(axis.text.x = element_text(angle = 45, hjust = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the variables with most impact are rental, unemplyoment and jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the weights only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuralNetTools::neuralweights(google_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_pred <- neuralnet::compute(google_model, google_test[,c(1:2, 4:8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the correlation between predictions and actual values in the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor(google_pred$net.result, google_test$RealEstate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will add four hidden nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_model2 <- neuralnet::neuralnet(RealEstate ~ Unemployment + Rental + Mortgage + Jobs + Investing + DJI_Index + StdDJI, data = google_train, hidden = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_model2$result.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuralNetTools::plotnet(google_model2, cex_val = 0.4, line_stag = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a smaller error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuralNetTools::neuralweights(google_model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_pred2 <- neuralnet::compute(google_model2, google_test[,c(1:2, 4:8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor(google_pred2$net.result, google_test$RealEstate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation between predictions and actual values in the test set are higher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding more layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will add 3 hidden layers with 4, 3, and 3 nodes respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_model3 <- neuralnet::neuralnet(RealEstate ~ Unemployment + Rental + Mortgage + Jobs + Investing + DJI_Index + StdDJI, data = google_train, hidden = c(4,3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error is even lower:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_model3$result.matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuralNetTools::plotnet(google_model3, cex_val = 0.4, line_stag = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuralNetTools::neuralweights(google_model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_pred3 <- neuralnet::compute(google_model3, google_test[,c(1:2, 4:8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor(google_pred3$net.result, google_test$RealEstate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation is slightly higher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, ANN models are also useful as classifiers. Let’s demonstrate this by using again the Stock Market data. We will binarize the samples according to their RealEstate values. For those higher than the 75%, we will lable them 0; For those lower than the 25%, we will label them 2; all others will be labeled 1. Even in the classification setting, the response still must be numeric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes <- cut(-google_norm$RealEstate, quantile(-google_norm$RealEstate, c(0, 0.25, 0.75, 1)), include.lowest=TRUE) %>% as.integer %>% -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes <- google_norm[,cut(-RealEstate,\n",
    "                            quantile(-RealEstate, c(0, 0.25, 0.75, 1)),\n",
    "                            include.lowest=TRUE) %>%\n",
    "            as.integer %>% -1]\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the normalized values and classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbind(google_norm$RealEstate %>% round(2), classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a copy of the google_norm into google_class.\n",
    "\n",
    "Note that you should create a deep copy with copy() function, otherwise the object will be locked and you cannot use := operator on columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_class <- copy(google_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And replace RealEstate with class values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_class[,RealEstate := classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the distribution of classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_class[,table(RealEstate)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can dummify the classes using fastDummies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dummies1 <- google_class[,fastDummies::dummy_cols(.(RealEstate = RealEstate),\n",
    "                            remove_first_dummy = F)] %>%\n",
    "    dplyr::select(-RealEstate) %>%\n",
    "    magrittr::set_colnames(c(\"High\", \"Median\", \"Low\")) %>%\n",
    "    dplyr::select(c(\"High\", \"Median\", \"Low\"))\n",
    "\n",
    "class_dummies1 %>% str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or using base model.matrix() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dummies2 <- google_class[,model.matrix(~factor(RealEstate)-1)] %>%\n",
    "    magrittr::set_colnames(c(\"High\", \"Median\", \"Low\"))\n",
    "\n",
    "class_dummies2 %>% str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a matrix with rownames\n",
    "\n",
    "We can use either"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First split the google_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_train_class <- google_class[train]\n",
    "google_test_class <- google_class[-train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then get the x and y values also from the dummies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x <- google_train_class[,c(1:2, 4:8)]\n",
    "train_y_ind <- as.data.table(class_dummies1)[train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set <- cbind(train_x, train_y_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names2 <- names(train_set)\n",
    "names2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use non-linear output and display every 2,000 iterations:\n",
    "\n",
    "Note that threshold and stepmax should be finetuned so that the model reaches the minimum error before the maximum steps, otherwise, computing the predictions may cause errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_single <- neuralnet::neuralnet(High + Median + Low ~ Unemployment + Rental + Mortgage + Jobs + Investing + DJI_Index + StdDJI,\n",
    "                                 data = train_set,\n",
    "                                 hidden = 4,\n",
    "                                 linear.output = F,\n",
    "                                 lifesign = \"full\",\n",
    "                                 lifesign.step = 2000,\n",
    "                                 threshold = 0.03,\n",
    "                                 stepmax = 200000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuralNetTools::plotnet(nn_single, cex_val = 0.4, line_stag = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the predictions on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1 <- neuralnet::compute(nn_single, google_test_class[,c(1:2, 4:8)])\n",
    "prediction1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the net resulsts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results <- prediction1$net.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(pred_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results %>% round"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions have three columns for each of the 0,1,2 values (High, Median, Low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's convert the dummies back into numeric class values of 0,1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_preds <- apply(pred_results, 1, which.max) - 1\n",
    "class_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And these are the actual values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_test <- google_test_class[,RealEstate]\n",
    "class_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(fitted = class_preds, actual = class_test) %>% caret::confusionMatrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an accuracy of 96.7%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also have multiple hidden layers in our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_single2 <- neuralnet::neuralnet(High + Median + Low ~ Unemployment + Rental + Mortgage + Jobs + Investing + DJI_Index + StdDJI,\n",
    "                                 data = train_set,\n",
    "                                 hidden = c(4,5),\n",
    "                                 linear.output = F,\n",
    "                                 lifesign = \"full\",\n",
    "                                 lifesign.step = 2000,\n",
    "                                 threshold = 0.03,\n",
    "                                 stepmax = 200000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuralNetTools::plotnet(nn_single2, cex_val = 0.4, line_stag = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_preds2 <- neuralnet::compute(nn_single2,\n",
    "                   google_test_class[,c(1:2, 4:8)])$net.result %>%\n",
    "                    apply(1, which.max) - 1\n",
    "\n",
    "class_preds2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare actual and predicted classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(fitted = class_preds2, actual = class_test) %>% caret::confusionMatrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is lower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Generating Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_id <- 2025000000\n",
    "library(tidyverse)\n",
    "library(data.table)\n",
    "library(BBmisc)\n",
    "library(neuralnet)\n",
    "library(NeuralNetTools)\n",
    "library(psych)\n",
    "library(Metrics)\n",
    "set.seed(student_id)\n",
    "nx <- 4\n",
    "xmeans <- c(rnorm(nx, 0, 1), 0)\n",
    "xsds <- c(rexp(nx, 2), rexp(1, 2))\n",
    "nobs <- 1e3\n",
    "data1 <- mapply(function(x, y) rnorm(nobs, x, y), xmeans, xsds, SIMPLIFY = F)\n",
    "colnamesx <- paste(sample(words, nx + 1), \"1\", sep = \"\")\n",
    "names(data1) <- c(paste(\"x\", 1:nx, sep = \"\"), \"e\")\n",
    "setDT(data1)\n",
    "data1[, e := normalize(e)]\n",
    "coefs <- rnorm(nx + 1, 0, 3)\n",
    "yvals <- data1[, coefs[1] + (coefs[2] * x1 + coefs[3] * x2 + coefs[4] * x3 + coefs[5] * x4)^3 + e]\n",
    "data2 <- copy(data1)\n",
    "data1[, e := NULL]\n",
    "#data1[, x4 := NULL]\n",
    "data1 <- cbind(yvals, data1)\n",
    "data1 <- data1 %>% mutate_all(normalize, \"range\")\n",
    "setnames(data1, colnamesx)\n",
    "delvar <- names(which.max(cor(data1)[1,-1]))[1]\n",
    "data1[, (delvar) := NULL]\n",
    "train_ratio <- 0.7\n",
    "train_indices <- data1[,sample(.I, .N * train_ratio)]\n",
    "train_data <- data1[train_indices]\n",
    "test_data <- data1[-train_indices]            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Single Hidden Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run a neural network model with a single hidden layer with only 4 nodes, by setting an arbitrary seed for full reproducibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(5)\n",
    "model1 <- neuralnet(six1 ~ study1 + they1 + tonight1,\n",
    "                    data = train_data,\n",
    "                    hidden = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 10, repr.plot.height = 10)\n",
    "plotnet(model1, cex_val = 1, line_stag = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the fitted values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted1 <- compute(model1, train_data)$net.result[T]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And get the $\\operatorname R^2$ value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor(train_data$six1, fitted1)^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared value of the model on train data is 0.20, can be considered low.\n",
    "\n",
    "Now let's get the predicted values on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted1 <- compute(model1, test_data)$net.result[T]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And calculate the R-squared value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor(test_data$six1, predicted1)^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared value on the test set is 0.28, and higher than that of the train data. However it is still low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean squared error value on the train data is 0.019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(fitted1, train_data$six1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And mean squared error value on the test data is 0.014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(predicted1, test_data$six1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since R-squared value is not too low (even higher) on test data and mean squared error value is not too high (even lower) on the test data as compared to their values on the train data, we can say that the model can generalize well on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the variable importances. Note that the signed values are converted into absolute values in order to prevent a misunderstanding: The signs of importance values cannot be interpreted the sign of the relationship between the predictors and the response as we do in linear regression or logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(olden(model1, bar_plot = F))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most important variable is tonight1. If we compare with the bivariate plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.panels(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tonight1 is also the variable that has the highest absolute correlation with six1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Three Hidden Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run a more complex model with three hidden layers, with respective number of nodes as 6, 4 and 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(10)\n",
    "model2 <- neuralnet(six1 ~ study1 + they1 + tonight1,\n",
    "                    data = train_data,\n",
    "                    hidden = c(6,4,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 10, repr.plot.height = 10)\n",
    "plotnet(model2, cex_val = 1, line_stag = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get fitted values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted2 <- compute(model2, train_data)$net.result[T]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And get the R-squared on train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor(train_data$six1, fitted2)^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R-squared on train data is 0.435 and is much higher as compared to the value we got in the simpler model with only one hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get the predicted values on test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted2 <- compute(model2, test_data)$net.result[T]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the R-squared value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor(test_data$six1, predicted2)^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the R-squared on test data is 0.07 and is much lower as compared to the value of 0.435 that we got on the train data and also the R-squared value of 0.28 on the test data with the simpler model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean squared error on train data is 0.013, much lower than 0.018 we got in the simpler model (the lower the MSE, the better the fit we get):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(fitted2, train_data$six1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However mean squared error on test data is 0.036, much higher than 0.013 above and also 0.014 we got on the test data with the simpler model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(predicted2, test_data$six1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can surely say that, while the more complex model fits the train data better, it cannot generalize well on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
