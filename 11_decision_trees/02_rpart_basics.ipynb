{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dca0857-3f2a-49e0-b62b-cd0682ace5fb",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b>RECURSIVE PARTIONING TREES: BASICS</b></font>\n",
    "\n",
    "<font size=\"5\"><b>Serhat Ã‡evikel</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af46a7a3-3fc4-48f9-9d4c-c73d0cc81a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(data.table)\n",
    "library(MASS) # for generating random samples from multivariate normal distribution\n",
    "library(rethinking) # for generating random correlation matrix from LKJ distribution\n",
    "library(rpart) # for recursive partioning trees\n",
    "library(rpart.plot) # for plotting recursive partioning trees\n",
    "library(visNetwork) # for better plotting recursive partioning trees\n",
    "library(igraph) # for creating graphs from data.table's\n",
    "library(vip) # for visualizing variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0713512-973f-4d18-ac83-73fb5123db07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options(repr.matrix.max.rows=20, repr.matrix.max.cols=15) # for limiting the number of top and bottom rows of tables printed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdb2977-d5e5-41f4-8af8-a82236a8a888",
   "metadata": {},
   "source": [
    "![xkcd](../imagesba/map_age_guide_large.png)\n",
    "\n",
    "(https://xkcd.com/1688/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f805f7f8-92e4-45ea-9023-c3b6ead3065a",
   "metadata": {},
   "source": [
    "This session will be about another approach to classification problems: Decision trees, or more specifically, recursive partioning trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0832d895-8646-4d0a-ab8c-09e4c1b740c3",
   "metadata": {},
   "source": [
    "Recursive partitioning is a statistical method for multivariable analysis.Recursive partitioning creates a decision tree that strives to correctly classify members of the population by splitting it into sub-populations based on several dichotomous independent variables. The process is termed recursive because each sub-population may in turn be split an indefinite number of times until the splitting process terminates after a particular stopping criterion is reached.\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Recursive_partitioning)\n",
    "\n",
    "A continuous feature can also be treated as a dichotomous (two-valued or binary) variable by discretizing from a cut point. Similarly a multi category variable can be treated as binary by considering multiple catergories in one value and remaining categories in the other value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4328d06-d577-4e5f-a464-e5f8074407ef",
   "metadata": {},
   "source": [
    "A simple decision tree based on Titanic data may look as follows:\n",
    "\n",
    "![tree1](../imagesba/titanic_tree.png)\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Recursive_partitioning)\n",
    "\n",
    "Here in each decision node, data is split in two based on a value or cut point of a selected variable. That split creates a subtree until all decisions do not result in further trees but ends up in leaf nodes. Each leaf node predicts a binary class. In this example, the leaf nodes classify the Titanic passengers as either \"died\" or \"survived\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11159f52-07b0-4dbd-b8e8-7d337e3f6408",
   "metadata": {},
   "source": [
    "Let's see the geometric meaning of decision trees with another example. Here we have two continuous variables X1 an X2 to predict a feature:\n",
    "\n",
    "![tree2](../imagesba/dectree2.png)\n",
    "\n",
    "(https://link.springer.com/article/10.1007/s10044-014-0399-1)\n",
    "\n",
    "(https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10044-014-0399-1/MediaObjects/10044_2014_399_Fig1_HTML.gif)\n",
    "\n",
    "In a two dimensional setting, with each decision node the responses are further split into partitions by adding new vertical or horizontal decision boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89fc4f1-88e7-4c3f-bddd-b7921a4ba5cb",
   "metadata": {},
   "source": [
    "How is the split made in the decision node? It is done so that node impurity is minimized. So what is impurity?\n",
    "\n",
    "Gini impurity measures how often a randomly chosen element of a set would be incorrectly labeled if it were labeled randomly and independently according to the distribution of labels in the set. It reaches its minimum (zero) when all cases in the node fall into a single target category.\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Decision_tree_learning)\n",
    "\n",
    "![impurity](../imagesba/impurity.png)\n",
    "\n",
    "(https://www.baeldung.com/cs/impurity-entropy-gini-index)\n",
    "\n",
    "(https://www.baeldung.com/wp-content/uploads/sites/4/2022/06/impurity.png)\n",
    "\n",
    "Here the node at the left has high level of impurity: The node is comprised of equal portion of both classes. The impurity is lower in the middle node comprised mostly of the red class observations and only few blue class observations. The right node has zero impurity: All observations are of red class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2509cb01-31b1-4698-b78e-427990e2782c",
   "metadata": {},
   "source": [
    "When is logistic regression or recursive partioning tree approaches more suitable for a classification problem?\n",
    "\n",
    "![tree3](../imagesba/8_7.png)\n",
    "\n",
    "(Garreth et al. 2023. An Introduction to Statistical Learning with Applications in R, Second Edition, Corrected Printing, p.339)\n",
    "\n",
    "(https://www.amazon.com/Introduction-Statistical-Learning-Applications-Statistics/dp/3031387465)\n",
    "\n",
    "(https://www.statlearning.com/resources-second-edition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438e8a68-3524-426e-be3a-7b4dd059e757",
   "metadata": {},
   "source": [
    "In the top row, the true decision boundary is linear and an approach like logistic regression can be successful in separating the classes (top left) while decision tree approach (top right) which can only draw a line that fixes only one dimension at a time from a cutting point is not very successful.\n",
    "\n",
    "In the bottom row, the true decision boundary is non-linear, hence a linear model such as logistic regression (bottom left) cannot capture the separation between classes very successfully. However, a decision tree approach (bottom right) is more successful in this setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185a4e06-a4b0-453c-b783-982d5475ac6e",
   "metadata": {},
   "source": [
    "# Recursive Partitioning Tree Algorithm on a Toy Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b68ab93-4d2c-4d60-a363-0c5dab0e1dfb",
   "metadata": {},
   "source": [
    "We will simulate a toy dataset to demonstrate decision tree algorithm for classification:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d6cb72-973e-4934-aa42-8fb3c1ff5103",
   "metadata": {},
   "source": [
    "We will sample continous values from multivariate normal distribution and then discretize them to get factor variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76b4528-91a5-416f-89c1-2b9a4bbfce0c",
   "metadata": {},
   "source": [
    "# Data generation and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4ed749-30ea-43a1-81a5-9653103a2328",
   "metadata": {},
   "source": [
    "Let's first create a random correlation matrix using the relevant LKJ distribution.\n",
    "And let's sample some correlated random values from multivariate normal distribution.\n",
    "\n",
    "First column will be the response variable, others are independent variables. All variables are discretized into factors of \"yes\" and \"no\" values for simplicity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9869daba-2c04-4f41-adfc-d234d70cc095",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "matcor <- rlkjcorr(1, 3, 0.1)\n",
    "set.seed(1)\n",
    "vals <- mvrnorm(2e2, rep(0, 3), matcor)\n",
    "vals_dt <- as.data.table(vals)\n",
    "setnames(vals_dt, c(\"dep\", \"ind1\", \"ind2\"))\n",
    "vals_dt <- vals_dt %>% mutate_all(cut, c(-Inf, 0, Inf), c(\"no\", \"yes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1535a55-8523-46cf-a9fb-5c15704f9f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(vals_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44988b53-2cbc-43c5-b4e0-11638b36d628",
   "metadata": {},
   "source": [
    "Check the correlation among classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2dfc92-2e55-44cb-85df-3e1b0254c79a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cor(vals_dt %>% mutate_all(as.integer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac6e186-1e86-45c6-ab0e-d4d66a635728",
   "metadata": {},
   "source": [
    "Let's visualize the possible splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05414151-86d1-4483-bb63-7b9ddef7da35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vals_dt %>%\n",
    "mutate_at(c(\"ind1\", \"ind2\"), as.integer) %>%\n",
    "ggplot(aes(x = ind1, y = ind2, col = dep)) +\n",
    "geom_jitter() +\n",
    "geom_hline(yintercept = 1.5) +\n",
    "geom_vline(xintercept = 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2643dc-fdf4-4b2c-b61d-d3805dd7f333",
   "metadata": {},
   "source": [
    "## Entropy/impurity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db60f0d2-dabe-4e61-8cab-311a01f122ac",
   "metadata": {},
   "source": [
    "Either Shannon entropy or Gini impurity measures can be used in order to assess the class imbalance in each of the nodes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2ba04e-7091-49f0-9e79-0f1f937177a7",
   "metadata": {},
   "source": [
    "Let's formalize this through entropy measure:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bca7ff-e583-4476-a498-dfe6969f5966",
   "metadata": {},
   "source": [
    "${\\displaystyle \\mathrm {H} (X):=-\\sum _{x\\in {\\mathcal {X}}}p(x)\\log p(x),}$\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Entropy_(information_theory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c74cdee-feb7-4be4-8166-e7b5e44a3af1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entrop <- function(x)\n",
    "{\n",
    "    props <- prop.table(table(as.character(x)))\n",
    "    sum(-props * log2(props))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d715bc-dbbb-430d-82c9-8a4bc9eb4644",
   "metadata": {},
   "source": [
    "And the gini impurity measure:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740f2c4b-25ae-4823-ba75-08d1f746807b",
   "metadata": {},
   "source": [
    "${\\displaystyle \\operatorname {I} _{G}(p)=1-\\sum _{i=1}^{J}p_{i}^{2}.}$\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec97d36e-77d7-4865-ad50-b293941f5eaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ginix <- function(x)\n",
    "{\n",
    "    props <- prop.table(table(as.character(x)))\n",
    "    1- sum(props^2)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d262d9-fcc2-48c9-bd8d-c62384b25026",
   "metadata": {},
   "source": [
    "Now let's make a digression to understand entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfff33e1-def6-4475-b744-14f952671624",
   "metadata": {},
   "source": [
    "For two class case, entropy value for different percentages of a case is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed38f34-9add-4567-86da-d53414d54b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ps <- seq(0, 1, 0.1) %>% pmax(1e-22) %>% pmin(1-(1e-16))\n",
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d0fee-8e74-4365-a627-7b70ddf9c555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "psdt <- data.table(ps)\n",
    "psdt[, ent := sapply(ps, function(x) -sum(c(x, 1-x) * log2(c(x, 1-x))))]\n",
    "psdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd47133-bdeb-41ef-bdd2-7ec4cfe28be1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "psdt %>%\n",
    "ggplot(aes(x = ps, y = ent)) +\n",
    "geom_line()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799dd72d-b278-400c-af4b-043bdeeadcf9",
   "metadata": {},
   "source": [
    "The entropy is at a maximum at ps = 0.5, so we have equal share of cases. What does that mean?\n",
    "\n",
    "One interpretation of entropy is uncertainty, disorderliness or impurity.\n",
    "\n",
    "But why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2415d93e-084f-43eb-80ad-5dfd1e0d687a",
   "metadata": {},
   "source": [
    "Let's assume we toss a fair coin 10 times and calculate the counts of heads we get.\n",
    "\n",
    "What are the probabilities of getting each count?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1451ee-d1c9-4fd9-9db9-d81daca6b9df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.table(count = 0:10, prob = dbinom(0:10, 10, 0.5)) %>%\n",
    "ggplot(aes(x = count, y = prob)) +\n",
    "geom_line()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384be5dd-b597-4176-b6fb-7e27105c3bc9",
   "metadata": {},
   "source": [
    "A very similar figure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc5771e-6dc9-4b47-88d2-02ed8c52f43f",
   "metadata": {},
   "source": [
    "What is the probability of getting a certain sequence of head or tail values for each count of heads?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdddd29-8339-4895-9746-2964b30eb99f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "0.5^(0:10) * 0.5^(10:0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da74d6b2-b1f5-42e9-995a-a2308bb31031",
   "metadata": {},
   "source": [
    "Because of the symmetric probabilities of each side, all sequences or configurations have the same probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ea6c70-dcdb-4775-956d-576489446260",
   "metadata": {},
   "source": [
    "How many configurations we may have? Size of power set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ff4b27-9b78-4547-b350-0c66ad145c8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "2^10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aa2dfc-c1a7-43fe-bdd6-cd08bfa7488a",
   "metadata": {},
   "source": [
    "Total probability is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882f5610-b671-4bdf-b456-19a485189dd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "0.5^10 * 2^10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6ca7f3-156c-4cc7-88ed-468c1fb7d20e",
   "metadata": {},
   "source": [
    "Quite obvious:\n",
    "\n",
    "$$(0.5 * 2)^{10} = 1^{10} = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ac2a42-70cd-45e5-b8ad-e1887f8ff947",
   "metadata": {},
   "source": [
    "Now have many configurations or sequences yield each of the head counts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c7786b-c0ca-4ceb-adbd-03d9b491dbb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "choose(10, 0:10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8ce30a-abd3-4db9-b5e3-5c61dc99aa34",
   "metadata": {},
   "source": [
    "Or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d2d8d5-7dff-40aa-a16e-b38aaeaaa61e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "factorial(10) / (factorial(10 - 0:10) * factorial(0:10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd36d21-f600-4ac1-9ae9-f0f5c31c5ea5",
   "metadata": {},
   "source": [
    "And let's multiply this number of different ways to get a certain count and the probabilities of each configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cd9e22-f4e3-4640-ba45-92d9d5d7417d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.table(count = 0:10, prob = choose(10, 0:10) * 0.5^(0:10) * 0.5^(10:0)) %>%\n",
    "ggplot(aes(x = count, y = prob)) +\n",
    "geom_line()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5f30a9-c3c1-4045-aa48-f40df1b31236",
   "metadata": {},
   "source": [
    "That's the same figure we get from dbinom, because we used the same formulation for dbinom:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3e6f14-547e-4a36-bfce-a9f02bba1766",
   "metadata": {},
   "source": [
    "$${\\displaystyle f(k,n,p)=\\Pr(X=k)={\\binom {n}{k}}p^{k}(1-p)^{n-k}}$$\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Binomial_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d07106-a6ae-45e5-907f-39724d0f38a4",
   "metadata": {},
   "source": [
    "Basically we have a higher probability to get values near the middle in this distribution because **we have more ways - or combinations - to get those count of head values**.\n",
    "\n",
    "Probability is basically number of ways of counting things."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f63c16-fbf2-4b75-86ff-b894945f78d0",
   "metadata": {},
   "source": [
    "## Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd16c98d-6be3-48d9-9310-3313d068abe0",
   "metadata": {},
   "source": [
    "Select the independent variables to split across:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2e58fa-20ee-4c5b-99b2-06c38cc27e77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vars <- c(\"ind1\", \"ind2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188d1e46-a728-4c38-8b66-c2e0912bf55e",
   "metadata": {},
   "source": [
    "See the weighted entropy values of the response for each two variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e22cfd-ed19-4d35-a101-ee2bd0a0992c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ents <- sapply(vars, function(x) vals_dt[, .(N = .N, en = entrop(dep)), by = get(x)][, sum(N * en)/sum(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a421b1b-7c31-4773-a274-2f0a751cdcce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59894193-2c8a-422d-bbae-0b4e068dd62a",
   "metadata": {},
   "source": [
    "Let's understand the steps behind this calculation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc770c70-df85-4d7d-b5f6-72318f140b58",
   "metadata": {},
   "source": [
    "In the first step, the entropy of the response variable is calculated for each class label of the first and second predictor variables, along with their respective counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a94569-6e11-46e6-925b-9689726669fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ents1 <- lapply(vars, function(x) vals_dt[, .(N = .N, en = entrop(dep)), by = get(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49cb538-3c31-48eb-988b-97f5304bbcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ents1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05da07f1-3943-48c5-9f9e-815dda4631c0",
   "metadata": {},
   "source": [
    "Then the entropy for each predictor variable is weighted by the respective counts of each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3524811-e15f-4895-a3d9-9886d626620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sapply(ents1, function(x) x[, sum(N * en)/sum(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bf60fb-e38f-4afd-96c8-e77fec231f9a",
   "metadata": {},
   "source": [
    "Now let's recalculate using gini impurity values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea65baa8-e45a-4d54-8497-b64a83d5e5bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ginis <- sapply(vars, function(x) vals_dt[, .(N = .N, en = ginix(dep)), by = get(x)][, sum(N * en)/sum(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fdab8a-0af0-4522-89c1-3c5fa8b5332c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ginis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa8eda1-5ac6-4b09-af5d-1cb6022b03a6",
   "metadata": {},
   "source": [
    "They are parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c4c6be-a528-4293-a8c3-af3e198808f1",
   "metadata": {},
   "source": [
    "Select the variable that cause the lower entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ba3f2a-5a70-436d-a1f5-e576de3e84c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "splitvar1 <- names(ents[which.min(ents)])\n",
    "splitvar1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e758d28-066c-4186-9208-8d0d883b7e4a",
   "metadata": {},
   "source": [
    "Split the data.table across this variable's class values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32afffe-ed09-4db6-a5cf-c2a48d0aaaa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vals_dt_l1 <- split(vals_dt, f = vals_dt[, .(get(splitvar1))])[c(\"no\", \"yes\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090fab72-dfa4-46c7-9944-c2c0ed3221fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lapply(vals_dt_l1, head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824bc070-3dcf-4cd3-9a1c-f48a0d67b054",
   "metadata": {},
   "source": [
    "And repeat the entropy calculation for both splits across the other variable (there is only one variable left, anyway, nothing to compare):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311e986d-d997-4154-8dea-6b3db6b8a8ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lapply(vals_dt_l1, function(y)\n",
    "    {\n",
    "    sapply(setdiff(vars, splitvar1), function(x) y[, .(N = .N, en = entrop(dep)), by = get(x)][, sum(N * en)/sum(N)])\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1d2f1a-071b-4be1-94c4-aa7a55df2c6a",
   "metadata": {},
   "source": [
    "Now let's see the information gain, the reduction in entropy, at the beginning and after each split:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78debcbe-e0b0-43b9-9c9a-b6079c00b030",
   "metadata": {},
   "source": [
    "First at the root:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c779f32-a268-4bb1-86ff-a12b2a9f4885",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counts_dt0 <- vals_dt[, .N, by = c(\"dep\")][, prop := N / sum(N)][]\n",
    "setorder(counts_dt0, dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4400e2c2-0d63-46f5-b161-bb3a27e2b178",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_dt0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f698a3-ed56-4ff0-bb57-78538918ab35",
   "metadata": {},
   "source": [
    "Let's visualize our tree as a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bfdfcb-7d72-4665-936d-8a6dabfd3e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1 <- make_empty_graph()\n",
    "v1_lab <- counts_dt0[, paste(paste(dep, N, sep = \": \"), collapse = \"\\n\")]\n",
    "tree2 <- tree1 %>% add_vertices(1, attr = list(label = v1_lab, size = 40))\n",
    "plot(tree2, layout = layout_as_tree(tree2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0476b6-4cff-4834-b799-650a9755891e",
   "metadata": {},
   "source": [
    "Get the entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d73463-a4ad-4850-9bb6-0c9f0276680e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ent0 <- counts_dt0[, sum(-setdiff(prop, 0) * log2(setdiff(prop, 0)))]\n",
    "ent0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da17e407-04f8-4777-9bb5-719152b570ca",
   "metadata": {},
   "source": [
    "And the error rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc219d7-b85b-4d34-8aa7-5082b8312703",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "er0 <- counts_dt0[, sum((N != max(N))*N) / sum(N)]\n",
    "er0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b02bb67-e0c9-49ef-8197-b38c44c22e58",
   "metadata": {},
   "source": [
    "Now, after the first split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7ae203-6229-40f7-990e-61d1930252df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counts_dt1 <- vals_dt[, .N, by = c(\"dep\", splitvar1)][, prop := N / sum(N), by = splitvar1][]\n",
    "setorder(counts_dt1, ind1, dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09371911-9e91-4b8f-b40a-0837042abf08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counts_dt1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9d7b12-832b-4058-8c4e-bcdfe7b51664",
   "metadata": {},
   "source": [
    "Update our tree and visualize again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db58c40-88f6-482a-8b6d-0d8cb5452dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_lab <- counts_dt1[, paste(paste(dep, N, sep = \": \"), collapse = \"\\n\"), by = ind1]\n",
    "e2_lab <- paste(splitvar1, v2_lab[, get(splitvar1)], sep = \"\\n=\\n\")\n",
    "tree3 <- tree2 %>% add_vertices(2, attr = list(label = v2_lab$V1, size = 40)) %>%\n",
    "add_edges(c(1,2,1,3), attr = list(label = e2_lab))\n",
    "plot(tree3, layout = layout_as_tree(tree3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ab4d02-e110-4e4c-9756-753c66833954",
   "metadata": {},
   "source": [
    "The entropy value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f89638-a86a-4fdb-b5a2-5d64d5b3ba54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ent1 <- counts_dt1[, .(N = sum(N), ent = sum(-setdiff(prop, 0) * log2(setdiff(prop, 0)))), by = splitvar1][, sum(N * ent) / sum(N)]\n",
    "ent1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c30cf1-4032-4899-aa65-54711c62057e",
   "metadata": {},
   "source": [
    "Entropy is reduced by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b105cd7-8244-4d96-9a87-4b130f0d4673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ent0 - ent1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e7e153-9502-4948-822c-e8eb742c1459",
   "metadata": {},
   "source": [
    "The error rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11839519-340b-4c8d-82cc-a51215e1f529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "er1 <- counts_dt1[, sum((dep != ind1) * N) / sum(N)]\n",
    "er1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1b738e-f50b-4063-b095-069ad3a2f256",
   "metadata": {},
   "source": [
    "And relative decrease in error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bba34b4-34db-4bb0-8705-b50e88df680e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "1 - er1 / er0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9418106d-2272-4850-b9e5-2d917b5c9e23",
   "metadata": {},
   "source": [
    "Keep that value in mind!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43fa731-e782-4f32-be31-e1d3ad8d4a0f",
   "metadata": {},
   "source": [
    "Now the second split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9565678-8a6a-47b9-99e0-da7e4f1d4027",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counts_dt2 <- vals_dt[, .N, by = c(\"dep\", vars)][, prop := N / sum(N), by = vars][]\n",
    "setorder(counts_dt2, ind1, ind2, dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4255dd2b-9b3e-4069-ae5f-114d803f8e8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counts_dt2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8ecebe-8d24-4f6c-98bd-fc67d7d2ad4c",
   "metadata": {},
   "source": [
    "Again let's update our tree and visualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17279a1-6aee-4e4c-899f-881ea1fedaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "v3_lab <- counts_dt2[, paste(paste(dep, N, sep = \": \"), collapse = \"\\n\"), by = c(\"ind1\", \"ind2\")]\n",
    "e3_lab <- paste(\"ind2\", v3_lab[, ind2], sep = \"\\n=\\n\")\n",
    "tree4 <- tree3 %>% add_vertices(4, attr = list(label = v3_lab$V1, size = 40)) %>%\n",
    "add_edges(c(2,4,2,5,3,6,3,7), attr = list(label = e3_lab))\n",
    "plot(tree4, layout = layout_as_tree(tree4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27430b0-d3bd-4ab6-8e65-0859c1875bc0",
   "metadata": {},
   "source": [
    "Let's look at the error rate for each split:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe389b31-9183-40bd-9adb-00fdf9d3f5e9",
   "metadata": {},
   "source": [
    "When ind1 = \"yes\" condition is not split further: (labels for the splitting variable are determined such that classification error is minimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32da403-ff47-4e74-89ed-86d393896182",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min(\n",
    "counts_dt2[ind1 == \"yes\"][, sum((dep == ind1) * N) / sum(N)],\n",
    "counts_dt2[ind1 == \"yes\"][, sum((dep != ind1) * N) / sum(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c588204e-6ad1-4a8a-8094-af598367618e",
   "metadata": {},
   "source": [
    "And when the node is split further by ind2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f358ffb-199c-4693-8d38-f2f840660707",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min(\n",
    "counts_dt2[ind1 == \"yes\"][, sum((dep == ind2) * N) / sum(N)],\n",
    "counts_dt2[ind1 == \"yes\"][, sum((dep != ind2) * N) / sum(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537b8606-247d-4462-8670-69e53a5a7e94",
   "metadata": {},
   "source": [
    "So the error rate increases with further split on the second variable for the ind1 == \"yes\" split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49f0cea-6491-4711-9c7f-f0709a9fafc5",
   "metadata": {},
   "source": [
    "Now let's repeat it for ind1 == \"no\" split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a386f68-0368-4b05-9738-295e933368ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min(\n",
    "counts_dt2[ind1 == \"no\"][, sum((dep == ind1) * N) / sum(N)],\n",
    "counts_dt2[ind1 == \"no\"][, sum((dep != ind1) * N) / sum(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4394beeb-9109-4c8a-8928-e1b8504a79bd",
   "metadata": {},
   "source": [
    "And when the node is split further by ind2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3a863f-d62b-44cb-82ca-361da472dc09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min(\n",
    "counts_dt2[ind1 == \"no\"][, sum((dep == ind2) * N) / sum(N)],\n",
    "counts_dt2[ind1 == \"no\"][, sum((dep != ind2) * N) / sum(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b1c791-db89-4411-b194-abbd6cb9cf00",
   "metadata": {},
   "source": [
    "The error rate decreases for that split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea66323-03b3-4f12-b88f-a23457bd8337",
   "metadata": {},
   "source": [
    "Let's delete the second level split on the ind1 == \"yes\" node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ab17cf-4e40-499d-9e86-d5be7b894ff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counts_dt2b <- copy(counts_dt2)\n",
    "counts_dt2b[ind1 == \"yes\", ind2 := NA]\n",
    "counts_dt2b <- counts_dt2b[, .(N = sum(N)), by = c(\"dep\", \"ind1\", \"ind2\")][, prop := N / sum(N), by = vars][]\n",
    "setorder(counts_dt2b, ind1, ind2, dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520e6ee5-629e-4c58-a460-afc642560e22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counts_dt2b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227bec73-060d-48f5-b9e2-eefee42ecf7d",
   "metadata": {},
   "source": [
    "And visualize the tree again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99e2e99-2384-4f50-82ca-98153872d22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "v3b_lab <- counts_dt2b[!is.na(ind2), paste(paste(dep, N, sep = \": \"), collapse = \"\\n\"), by = c(\"ind1\", \"ind2\")]\n",
    "e3b_lab <- paste(\"ind2\", v3b_lab[, ind2], sep = \"\\n=\\n\")\n",
    "tree4b <- tree3 %>% add_vertices(2, attr = list(label = v3b_lab$V1, size = 40)) %>%\n",
    "add_edges(c(2,4,2,5), attr = list(label = e3b_lab))\n",
    "plot(tree4b, layout = layout_as_tree(tree4b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee5407a-e423-48ff-b52c-e591d1c18120",
   "metadata": {},
   "source": [
    "Calculate the entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcdb1ea-1fa0-4e32-aa8a-8e81ebcc20f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ent2b <- counts_dt2b[, .(N = sum(N), ent = sum(-setdiff(prop, 0) * log2(setdiff(prop, 0)))), by = vars][, sum(N * ent) / sum(N)]\n",
    "ent2b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc89971f-e95f-4c55-be2d-1a88de4a7252",
   "metadata": {},
   "source": [
    "Entropy is reduced by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5aa69c-4f36-4448-b514-ce5b9f3c8e75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ent1 - ent2b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7f8282-83dc-48c1-b901-e1276c6e2ef6",
   "metadata": {},
   "source": [
    "So for short, **as long as the relative classification error decreases sufficiently**, at each node, next variable for split is chosen so that entropy is reduced most"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baef48d-ab55-463d-8c43-856c83d099b8",
   "metadata": {},
   "source": [
    "# rpart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3385591a-8493-4e7f-94f5-17cd5ee7fcc1",
   "metadata": {},
   "source": [
    "Now let's make `rpart` function from `rpart` package: do the heavy lifting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b5bdba-7f8a-4285-ae55-aab314579470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rptree <- rpart(dep ~ ., data = vals_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2621b2-32e6-4bda-8961-f676ce56b5d4",
   "metadata": {},
   "source": [
    "How the splits are done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ede0934-8ec3-4d6a-b866-7d33def9d465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rptree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363ba572-8893-4bea-ad0c-0d00ab12d15e",
   "metadata": {},
   "source": [
    "Node numbers follow a breadth first search order: The nodes on the same level are scanned first then passing on to the next level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15257ae-7bb8-458f-9a19-afcaccb36763",
   "metadata": {},
   "source": [
    "Note the order of the labels in the dep column of the input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27b839d-b44a-4745-a173-a6f73a96bca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "levels(vals_dt$dep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5851a83-9abc-409f-8ec8-bf055cb9f400",
   "metadata": {},
   "source": [
    "Dissecting the first row:\n",
    "\n",
    "- 1): Node number\n",
    "- root: split name, either the root or the decision rule\n",
    "- 200: Total number of values at the node\n",
    "- 97: Misclassification losses when the majority class is taken as the basis\n",
    "- yes: majority class (yvalue)\n",
    "- (0.48 0.515): Probabilities of classes. Follows the order of the classes in the factor variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226bfdd2-9e4a-49ae-b1c2-e53f52e65d36",
   "metadata": {},
   "source": [
    "And we can compare the first line with the initial data.table of the root node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1d0975-2bea-42e7-922a-cc922853afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_dt0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8aa237-7736-42e6-9b61-9228d566e36b",
   "metadata": {},
   "source": [
    "Nodes 2 and 3 are in line with the next level table created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902357eb-e6ed-4d1b-81be-950bc9401fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_dt1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fea312-d216-43d9-838d-c721c375be4b",
   "metadata": {},
   "source": [
    "And Nodes 4 and 5 can be compared with the last table created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc54437a-a795-4e64-b06a-1685c19b6a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "na.omit(counts_dt2b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31c944-7ded-4f4c-81f5-0ff1221f0a28",
   "metadata": {},
   "source": [
    "Variable importance measure is computed based on the reduction in predictive accuracy when the variable at question is removed\n",
    "\n",
    "(https://stats.stackexchange.com/a/6485)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aba8db7-72b5-44c0-be14-4f49e4f88839",
   "metadata": {},
   "outputs": [],
   "source": [
    "rptree$variable.importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc13101-69a2-4e1e-a297-8e83f748a953",
   "metadata": {},
   "source": [
    "With `vip` package, we can extract the variable importance values as a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e430e0e0-4958-4f5d-92ee-b7ea6b842f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "vi(rptree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d154b2-5b31-474f-b513-379e485970aa",
   "metadata": {},
   "source": [
    "Or visualize those values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f951020-688e-4bb2-8535-58d7275d3b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "vip(rptree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae06e929-a9a0-49f8-95bc-dd23ea652e28",
   "metadata": {},
   "source": [
    "We see that ind1 is more important than ind2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0f8dec-0bce-430c-9fb3-d5441a359ae9",
   "metadata": {},
   "source": [
    "Summary of complexity parameters (CP) table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5449e085-f56f-4abb-8991-311c86535112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "printcp(rptree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baa4ece-fc01-4a1a-81d7-880b4df1957a",
   "metadata": {},
   "source": [
    "Remember the first value in the CP column: The decrease in relative error we calculated before.\n",
    "\n",
    "Relative error is the error at the depth level divided by the error at the root node (before any splits)\n",
    "\n",
    "xerror is cross validation error: The data is internally split into 10 parts, where one split is left for out-of-sample testing for each of the 10 runs. Cross validation error is also in relative terms, normalized with the cross validation error at the root node. The idea is that, when a tree gets too deep and complicated, there is an increasing risk of being inflexible and increased variance in the prediction accuracy of unseen data. xstd is the standard deviation of the xerror (conducted on 10 different test folds)\n",
    "\n",
    "While rel_error always decreases (as long as the algorithm continues to create new nodes decreasing the train error), the cross validation error (test error) may start to increase again after a minimum level. In order to simplify the tree, the tree can be pruned at the point where xerror is at a minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc773f0-a230-4032-831c-9489441f0d4c",
   "metadata": {},
   "source": [
    "We can plot the relative cross validation error along with its standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cca838-839e-4170-bbc5-9fc477e1dd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotcp(rptree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9f4c25-c51b-48ab-9a74-d5604eef37ab",
   "metadata": {},
   "source": [
    "Let's extract the CP table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf770544-6d40-4bac-95eb-d0a205a923ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpdt <- rptree$cptable %>% as.data.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aead36-0164-4da7-83b5-53999ea107d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cpdt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e8886d-fdf0-4476-95e8-8c9c0d789007",
   "metadata": {},
   "source": [
    "Complexity parameter (CP) is the change in relative error if further splits are made, divided by the increase in number of splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f49339d-d4e0-44a2-84af-085f95daa030",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cpdt[, -diff(`rel error`) / diff(nsplit)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd86a888-a2e0-44ea-88e7-ad1c1dd9eadf",
   "metadata": {},
   "source": [
    "So while more splits decrease the relative error, increase in number of nodes penalize this error cut in complexity parameter calculation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c609db-955b-416b-af20-aed38bfa55b8",
   "metadata": {},
   "source": [
    "Let's visualize the tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1086c891-38bd-4914-a4a0-14ab1193071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpart.plot(rptree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0295818a-910e-4e92-9981-00a765bcd3a3",
   "metadata": {},
   "source": [
    "or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5669eb34-2a39-407a-91f5-c61c8a985376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visTree(rptree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270c1a16-735a-42fa-9347-72ccad1b56c0",
   "metadata": {},
   "source": [
    "Quite similar to our own tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab5f41b-df9e-49b2-8087-b5e2f56da392",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(tree4b, layout = layout_as_tree(tree4b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293421bf-bb9f-4112-b51d-93a4f298be7a",
   "metadata": {},
   "source": [
    "While we don't need to prune this tree, since xerror always decreases, let's try pruning for demonstration purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c90a578-76f1-4357-b8e2-c66798c050a3",
   "metadata": {},
   "source": [
    "Let's say we want to prune the tree from the second split. Let's get the complexity parameter at that split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3a2c5c-4309-49b4-99dc-598cb445eb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "prunecp <- rptree$cptable[2, \"CP\"]\n",
    "prunecp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633bfd8e-4470-4bd6-b35b-bee1dcfbe8ab",
   "metadata": {},
   "source": [
    "Let's prune the tree by setting the cp parameter to the CP value of second row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdea29d-c72e-45d5-843b-c7bbbd3fc7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.tree <- prune(rptree, cp = prunecp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb290090-f4ab-4e7c-adb3-e32da96f3ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78465a4-260e-4e12-a4d3-8b459ad8d04d",
   "metadata": {},
   "source": [
    "We have a simpler tree now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdad7450-ba22-4267-bf36-dc8677dd2cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpart.plot(prune.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57956e97-e85e-4dec-994e-17dbccef5044",
   "metadata": {},
   "source": [
    "or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facc0f07-1d90-492c-a177-90081ca826b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "visTree(prune.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66357f0-8e05-45c5-a6ab-f9343beb6967",
   "metadata": {},
   "source": [
    "# Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81908d37-9c1a-4f42-ae9d-ac0512f94aa6",
   "metadata": {},
   "source": [
    "- Lantz 2015, Machine Learning with R, Second Edition, Ch. 5\n",
    "- Garreth et al. 2023, An Introduction to Statistical Learning with Applications in R, Second Edition, Corrected Printing, Ch. 8\n",
    "- Nokeri 2021, Data Science Revealed, Ch. 8\n",
    "- Yu-Wei 2015, Machine Learning with R Cookbook, Ch. 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.2"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
