{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b>RECURSIVE PARTIONING TREES: EXAMPLE</b></font>\n",
    "\n",
    "<font size=\"5\"><b>Serhat Ã‡evikel</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(data.table)\n",
    "library(tidyverse)\n",
    "library(plotly)\n",
    "library(modeldata) # for churn data\n",
    "library(rpart) # for recursive partioning trees\n",
    "library(rpart.plot) # for plotting recursive partioning trees\n",
    "library(visNetwork) # for better plotting recursive partioning trees\n",
    "library(caret) # for a better confusion matrix\n",
    "library(vip) # for variable importance plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.matrix.max.rows=20, repr.matrix.max.cols=15) # for limiting the number of top and bottom rows of tables printed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath <- \"~/databa\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![xkcd](../imagesba/tree.png)\n",
    "\n",
    "(https://xkcd.com/835/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session we will explore recursive partioning tree method for classification on a dataset for churn rate of telecom customers.\n",
    "\n",
    "Example adapted from Machine Learning with R Cookbook: Analyze data and build predictive models by AshishSingh Bhatia, Yu-Wei, Chiu (David Chiu) Chapter 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data(mlc_churn, package = \"modeldata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlc_churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get information on the data:\n",
    "\n",
    "`churn` column holds the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?modeldata::mlc_churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn <- mlc_churn %>% as.data.table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now first let's say, I want to get the unique levels of each factor column in a concise and simple way\n",
    "\n",
    "We use the purrr package for that in order to iterate through fields:\n",
    "\n",
    "keep, selects only those columns that satisfied the condition, and map works like \"lapply\" to apply the function to each selected column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn %>% purrr::keep(is.factor) %>% purrr::map(levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have the histograms for factor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_factors <- churn %>% purrr::keep(is.factor) %>% # select factor columns\n",
    "    tidyr::gather() %>% # convert into long format for faceting\n",
    "    ggplot(aes(x = value)) + # plot value\n",
    "    facet_wrap(~ key, scales = \"free\") + # divide into separate plots by key\n",
    "    geom_bar()\n",
    "\n",
    "plotly::ggplotly(churn_factors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So:\n",
    "\n",
    "- Most frequent area code is 415\n",
    "- 707 out of 5000 observations have a churn\n",
    "- 4527 does not have an international plan\n",
    "- Data is nearly evenly distributed across states\n",
    "- 3677 does not gave a voice mail plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For numeric variables, it is good to have five point summaries easily as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn %>% purrr::keep(is.numeric) %>% sapply(quantile) %>% t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can have density plots for numeric variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn %>% purrr::keep(is.numeric) %>% # select columns\n",
    "    tidyr::gather() %>% # reshape into long format in columns \"key\" and \"value\"\n",
    "    ggplot(aes(value)) + # plot value\n",
    "        facet_wrap(~ key, scale = \"free\" ) + # divide into separate plots by key\n",
    "        geom_density(fill = \"green\")  # get density plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1863)\n",
    "train_ind <- churn[,sample(.I, 0.7 * .N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_train <- churn[train_ind]\n",
    "churn_test <- churn[-train_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get information on rpart model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?rpart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Recursive Partitioning and Regression Trees\n",
    "Description\n",
    "Fit a rpart model\n",
    "\n",
    "Usage\n",
    "rpart(formula, data, weights, subset, na.action = na.rpart, method,\n",
    "      model = FALSE, x = FALSE, y = TRUE, parms, control, cost, ...)\n",
    "Arguments\n",
    "formula\t\n",
    "a formula, with a response but no interaction terms. If this a a data frame, that is taken as the model frame (see model.frame).\n",
    "\n",
    "data\t\n",
    "an optional data frame in which to interpret the variables named in the formula.\n",
    "\n",
    "...\n",
    "\n",
    "cost\t\n",
    "a vector of non-negative costs, one for each variable in the model. Defaults to one for all variables. These are scalings to be applied when considering splits, so the improvement on splitting on a variable is divided by its cost in deciding which split to choose.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn.rp <- rpart::rpart(churn ~ ., data = churn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn.rp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- split is the condition for split,\n",
    "- n is the total number of cases at node\n",
    "- loss is the misclassification cost\n",
    "- yval is the fitted value for the node (yes or no)\n",
    "- and the yprob is the probabilities of yes and no (those reaching yes on the left and no the right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for the \"yes\" and \"no\" order is the order of the levels of the response variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels(churn_train$churn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we stop at the root without any classification and predict all cases as \"No\", we would have a total misclassification of 491 - the total number of \"yes\" cases in the train sample.\n",
    "\n",
    "After one step of partioning according to whether total_day_minutes >= 265.75, # of misclassified cases is down to 83+358 = 441"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's examine the complexity parameter.\n",
    "\n",
    "Complexity parameter serves as a penalty to control the size of the tree. The greater the CP value, the fewer the number of splits there are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printcp(churn.rp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that out of 19 variables only 9 are used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can plot the cost complexity parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotcp(churn.rp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot variable importance values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vip(churn.rp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most important variables are total_day_minutes, today_day_charge and number_customer_service_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple way to visualize a rpart tree is the base plot function with text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(churn.rp, , uniform = F, branch=0.6, margin = 0)\n",
    "text(churn.rp, all = T, use.n = T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does not work well with larger trees\n",
    "\n",
    "A better option is the rpart.plot function from the rpart.plot package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpart.plot(churn.rp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better option is to use the visTree function from the JS powered visNetwork package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visTree(churn.rp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how well the model can fit the classes of the response variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_train <- predict(churn.rp, churn_train, type = \"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtrain1 <- caret::confusionMatrix(table(fitted = fitted_train, actual = churn_train$churn))\n",
    "cmtrain1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy rate is 96% with misclassified cases of 142 out of 3500\n",
    "\n",
    "Kappa value of 0.79 can also be considered as good:\n",
    "\n",
    "- Poor agreement = less than 0.20\n",
    "- Fair agreement = 0.20 to 0.40\n",
    "- Moderate agreement = 0.40 to 0.60\n",
    "- Good agreement = 0.60 to 0.80\n",
    "- Very good agreement = 0.80 to 1.00\n",
    "\n",
    "(Lantz 2015, Machine Learning with R, Ch 10, p.323)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive power of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see whether our model can do as well on unseen data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test <- predict(churn.rp, churn_test, type = \"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtest1 <- caret::confusionMatrix(table(predicted = predictions_test, actual = churn_test$churn))\n",
    "cmtest1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictive accuracy is 94.3%, quite good! Kappa is 0.73, still good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may remove sections not so powerful in classification in order to avoid over-fitting and to improve accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remember the model cost parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printcp(churn.rp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the (relative) cross validation error with the standard deviation of the errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotcp(churn.rp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's find the minimum cross-validation error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(churn.rp$cptable[,\"xerror\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And locate the row of that minimum value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minrow <- which.min(churn.rp$cptable[,\"xerror\"])\n",
    "minrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the cost complexity parameter at that row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn.cp <- churn.rp$cptable[minrow, \"CP\"]\n",
    "churn.cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prune the tree by setting the cp parameter to the CP value of the record with minimum cross-validation error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.tree <- prune(churn.rp, cp = churn.cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And visualize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpart.plot(prune.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visTree(prune.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification performance of the pruned tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assess the classification performance on train data with the pruned tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train_pruned <- predict(prune.tree, churn_train, type = \"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtrain2 <- caret::confusionMatrix(table(fitted = predictions_train_pruned, actual = churn_train$churn))\n",
    "cmtrain2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lower accuracy and kappa values for the train set.\n",
    "\n",
    "How about predictive power?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive power of the pruned tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see the classification performance on the test set with pruned tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_pruned <- predict(prune.tree, churn_test, type = \"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtest2 <- caret::confusionMatrix(table(predicted = predictions_test_pruned, actual = churn_test$churn))\n",
    "cmtest2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictive power is also slightly lower, however we have a less complex tree and some split conditions that may cause over-fitting are eliminated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before pruning, the kappa of test set is 6% lower than that of train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtest1$overall[\"Kappa\"] - cmtrain1$overall[\"Kappa\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After pruning, the kappa of test set is only 1.5% lower than that of train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtest2$overall[\"Kappa\"] - cmtrain2$overall[\"Kappa\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So while pruning increased the bias, the variance decrease so the performance can be generalized better to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Generating Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_id <- 2025000000\n",
    "library(tidyverse)\n",
    "library(data.table)\n",
    "library(PearsonDS) # for Pearson distribution\n",
    "library(rethinking) # for LKJ distribution\n",
    "library(caret) # for confusion matrix\n",
    "library(rpart) # for recursive partioning trees\n",
    "library(rpart.plot) # for plotting recursive partioning trees\n",
    "library(vip) # for variable importance plots\n",
    "set.seed(floor((student_id %% 1e8) * 1.1))\n",
    "nvar <- 4\n",
    "sampsize <- 1e3\n",
    "etax <- 10\n",
    "train_ratio <- 0.7\n",
    "matx <- rlkjcorr(1, nvar, etax)\n",
    "sampx <- rmvnorm(1e3, sigma = matx)\n",
    "sampx <- pnorm(sampx)\n",
    "means <- rnorm(nvar)\n",
    "vars <- rexp(nvar, 1)\n",
    "kurts <- rexp(nvar, 1) + 3\n",
    "skews <- (rbeta(nvar, 3, 3) - 0.5)*2\n",
    "colnamesx <- paste(sample(words, nvar + 1), \"1\", sep = \"\")\n",
    "sampx_dt <- as.data.table(sampx)\n",
    "sampx_dt <- as.data.table(mapply(function(x, a, b, c, d) qpearson(x, moments = c(a, b, c, d)), sampx_dt,\n",
    "                                 means, vars, skews, kurts))\n",
    "mm <- model.matrix(as.formula(paste(\"V0\", sprintf(\"(%s)^4\", paste(colnames(sampx_dt), collapse = \" + \")), sep = \" ~ \")), cbind(V0 = 1, sampx_dt))\n",
    "paramst <- as.matrix(runif(ncol(mm), -5, 5))\n",
    "errx <- as.matrix(rnorm(sampsize, 0, sqrt(rexp(1, 0.02))))\n",
    "responsex <- mm %*% paramst + errx\n",
    "posrate <- runif(1, 0.2, 0.4)\n",
    "cutp <- quantile(responsex, 1 - posrate)\n",
    "responsex <- factor(ifelse(responsex > cutp, 1, 0))\n",
    "sampx_dt <- cbind(responsex, sampx_dt)\n",
    "setnames(sampx_dt, colnamesx)\n",
    "train_indices <- sampx_dt[,sample(.I, .N * train_ratio), by = c(colnamesx[1])]$V1\n",
    "train_data <- sampx_dt[train_indices]\n",
    "test_data <- sampx_dt[-train_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get variable names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 10, repr.plot.height = 10)\n",
    "train_data %>%\n",
    "  pivot_longer(-\"encourage1\") %>%\n",
    "  ggplot(aes(y = value, x = \"\", group = encourage1)) +\n",
    "  geom_boxplot() +\n",
    "  facet_wrap(~ name, scales = \"free_y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that no single variable can discriminate well across the response values: The interquartile ranges mostly overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 <- rpart::rpart(encourage1 ~ level1 + bar1 + record1 + young1, data = train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the probabilities are reported in the order of 0 and 1 since this is the order of levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels(train_data$encourage1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the root node the predicted class is 0 since it is the majority class and misclassification cost of 168 is the count of 1 values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(train_data$encourage1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpart.plot(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is hard to interpret all of the leaf nodes in the tree however we can interpret an arbitrarily selected leaf node, for example node 4:\n",
    "\n",
    "- When record1 < -0.77 and young1 >= -0.94 the response variable is predicted as 0 (negative class) which makes up 90% of the values at that leaf node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot variable importances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vip(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "level1 is the most important variable, followed by record1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the complexity parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printcp(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot the cross validation errors across cp values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotcp(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get fitted values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_train <- predict(model1, type = \"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtrain1 <- confusionMatrix(table(fitted = fitted_train, actual = train_data$encourage1), positive = \"1\")\n",
    "cmtrain1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kappa value is 0.4629, shows moderate aggreement:\n",
    "\n",
    "- Poor agreement = less than 0.20\n",
    "- Fair agreement = 0.20 to 0.40\n",
    "- Moderate agreement = 0.40 to 0.60\n",
    "- Good agreement = 0.60 to 0.80\n",
    "- Very good agreement = 0.80 to 1.00\n",
    "\n",
    "(Lantz 2015, Machine Learning with R, Ch 10, p.323)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's get prediction performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test <- predict(model1, test_data, type = \"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtest1 <- confusionMatrix(table(predicted = predictions_test, actual = test_data$encourage1), positive = \"1\")\n",
    "cmtest1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kappa value is lower now, at 0.3812, fair agreement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prune the tree to have a simpler structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locate the row of that minimum xerror (relative cross validation error) value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minrow <- which.min(model1$cptable[,\"xerror\"])\n",
    "minrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the cost complexity parameter at that row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.cp <- model1$cptable[minrow, \"CP\"]\n",
    "model1.cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prune the tree by setting the cp parameter to the CP value of the record with minimum cross-validation error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.tree <- prune(model1, cp = model1.cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And visualize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpart.plot(prune.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification performance of the pruned tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the classification performance using the pruned tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_train_pruned <- predict(prune.tree, type = \"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtrain2 <- confusionMatrix(table(fitted = fitted_train_pruned, actual = train_data$encourage1), positive = \"1\")\n",
    "cmtrain2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kappa value of 0.2967 is quite lower now with fair agreement.\n",
    "\n",
    "How about predictive power?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive power of the pruned tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the prediction performance on test set with pruned tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_pruned <- predict(prune.tree, test_data, type = \"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtest2 <- confusionMatrix(table(predicted = predictions_test_pruned, actual = test_data$encourage1), positive = \"1\")\n",
    "cmtest2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, predictive power of the pruned tree on test set is better than its performance on train set! Kappa value is at 0.3836, still fair.\n",
    "\n",
    "And this performance is also better than the prediction performance of the full tree.\n",
    "\n",
    "So while pruning caused the fitting performance worse as expected, the prediction performance is better now, the model can generalize well on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
