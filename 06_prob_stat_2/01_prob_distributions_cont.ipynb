{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d37f78dc-d8d8-4b7f-8340-c4519fa12c6e",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b>BASIC PROBABILITY DISTRIBUTIONS: CONTINUOUS DISTRIBUTIONS</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0229fa88-d109-4d5c-8d0d-e277dcfbb18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(data.table)\n",
    "library(tidyverse)\n",
    "library(plotly)\n",
    "library(psych) # for pairwise scatter plots\n",
    "library(estimators) # for theoretical moments\n",
    "library(moments) # empirical moments\n",
    "library(miscTools) # for ddnorm, derivative of normal distribution curve\n",
    "library(MASS) # for multivariate normal distribution\n",
    "#library(GGally) # for pairwise scatter plots\n",
    "library(BBmisc) # for standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43734fa2-5eec-4eb8-bde9-f0c99fcd9b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.matrix.max.rows=20, repr.matrix.max.cols=15) # for limiting the number of top and bottom rows of tables printed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716036f0-a0d7-478e-8462-7f2da0a759fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(htmlwidgets_embed=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e0a02a-e711-40cc-810d-1a9d6e335940",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(knitr.kable.max_rows = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e54b741-8c8b-4abf-be5a-c41e04aecca2",
   "metadata": {},
   "source": [
    "![xkcd](../imagesba/normal_distribution.png)\n",
    "\n",
    "(https://xkcd.com/2118/)"
   ]
  },
  {
   "attachments": {
    "19c7cfcc-e7e1-4c64-b5b7-b8ffb22d2f5d.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAACMAAAAWCAIAAADFDLIQAAAA5klEQVR4AeSTMQqEMBBF1yDiBawtbPaCroVgp8IexN7egyzYWgjaiEmXZHfASjLDkggi+AkW3/k+54vse5bY4yzdkDQMw2cvIYRb32R7Wuu6rouieO9VluWyLA4wkjTPc9/35hPHcayqqsXUdR3n3IxsDklSSm0T5nWaJgzUNk2T57mU0oyAQ5LgnsNZ1xXKQIMkCX5oNPDXhA+MzpAkdPqIeQGSc3vU3hfYiXo1Z/9WO/m+71YUFSTbi6IojmNbWJIkEERTJIkxlmXZy1JpmnqeZ0eC6TAMn5YKggCC6CF3QqePmD8AAAD//42aV1MAAAAGSURBVAMAzcD1xFYo2KQAAAAASUVORK5CYII="
    },
    "59f65417-a59d-4016-bc05-07b80a568ba9.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFcAAAAfCAIAAAAdocY6AAABY0lEQVR4AeyXvWoCQRCADwMhEJKAIY1FYpcfSMoEUqVImzxBmvTW2ilYCAp24gP4ChYWWmhjYSsodleJP1iJoiKeMxbjsZyNsI7uzbFz7N5wt/N9N8VdwJHDcQKWHJYlFrALxIJYQAMYai9U2uPPTCcUa5o9gBFIUcAmVAvxYtceLTYpk0/ACKREqFqANOXMnrhJVQtmk++iEwtoRiwch4X38OV98Bxr4Qv+Xij8P/x9BPkM4M78FrAK7hAL+AZOwwJWqjMYLPy+3XTTrzSuL84iX3e0bCVedPJ6P5vBQqc/z1YGNBZLp2FPaJmrDr0r1XmVxcIsW+7TmC1XDXtKy3zNHxZ0vtQ9n83QC3tWqvM2sYB2+S08JVqpUg9r4Qt+C3zs253FAroQC14WwrfMP7lY1EHCTar2QvIn5E4fpB6GTYARSGlj1cL381U9+khf9aZOgBFId1qghK8mai/4Cp5g1wAAAP//wSp5HgAAAAZJREFUAwAn/0tYQyKHDAAAAABJRU5ErkJggg=="
    },
    "ea8cd5d8-ffdb-40c2-bb70-8207eed5cbee.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "bee346d3-0103-480d-be59-6545ac0c99a8",
   "metadata": {},
   "source": [
    "**Note:** For the interactive applications, please:\n",
    "\n",
    "- Select file browser from the side bar through the symbol: ![image.png](attachment:19c7cfcc-e7e1-4c64-b5b7-b8ffb22d2f5d.png)\n",
    "\n",
    "- Open the Launcher by hitting the button: ![image.png](attachment:59f65417-a59d-4016-bc05-07b80a568ba9.png)\n",
    "\n",
    "- Hit \"Shiny\" button from the Launcher:\n",
    "\n",
    "  ![image.png](attachment:ea8cd5d8-ffdb-40c2-bb70-8207eed5cbee.png)\n",
    "\n",
    "- Navigate to 05_prob_stat_1/apps/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d37137-c068-41d3-a60f-8c1fc2e8a54f",
   "metadata": {},
   "source": [
    "Continuous probability distribution can take real values on the supported portion of the continuum. For Beta distribution the supported domain is the interval (0,1), while for the exponential and gamma distributions the supported domain is (0, $\\infty$). For normal and Student's t distribution the supported domain is the whole continuum ($-\\infty, \\infty$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9501a5c6-399a-47a8-bbba-8cea6cddb469",
   "metadata": {},
   "source": [
    "For both discrete and continuous distributions, the range of cumulative distribution function is between 0 and 1 and cumulative distribution function is monotonically increasing between 0 and 1. \n",
    "\n",
    "However, for discrete distributions, the probability mass function can take on probabilities between 0 and 1 for discrete values.\n",
    "\n",
    "For continuous distributions, any single point has a zero probability of occurence since the domain is the supported portion of the continuum. The probability density function show the instantenous change in the cumulative probability and can take on any positive values and can be above 1.\n",
    "\n",
    "Both probability mass and probability density functions can have negative and positive slopes across their domains, so they don't have to be monotonically increasing functions.\n",
    "\n",
    "So the cumulative distribution function is the integral of probability density function and probability density function is the derivative of the cumulative distribution function.\n",
    "\n",
    "We can compare the cases of selected discrete and continuous distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7681e3-f16e-4cf6-9de0-ce44c30f3ce8",
   "metadata": {},
   "source": [
    "As an example of a discrete distribution, we can create two vertical subplots for the probability mass function and cumulative distribution function for binomial distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3419e8b5-0e32-495d-9df2-c2a50e7ae702",
   "metadata": {},
   "outputs": [],
   "source": [
    "qvals1 <- 0:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d570fa5-ad98-4184-aa11-604574fb7513",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 <- plot_ly(x = qvals1, y = dbinom(qvals1, 10, 0.3), type = \"scatter\", mode = \"lines\") %>%\n",
    "  layout(\n",
    "    xaxis = list(\n",
    "      showspikes = TRUE, \n",
    "      spikemode = \"across\", \n",
    "      spikesnap = \"cursor\", \n",
    "      spikethickness = 1.5,\n",
    "      spikecolor = \"red\"\n",
    "    ),\n",
    "    yaxis = list(showspikes = FALSE)\n",
    "  )\n",
    "\n",
    "p2 <- plot_ly(x = qvals1, y = pbinom(qvals1, 10, 0.3), type = \"scatter\", mode = \"lines\") %>%\n",
    "  layout(\n",
    "    xaxis = list(\n",
    "      showspikes = TRUE, \n",
    "      spikemode = \"across\", \n",
    "      spikesnap = \"cursor\", \n",
    "      spikethickness = 1.5,\n",
    "      spikecolor = \"red\"\n",
    "    ),\n",
    "    yaxis = list(showspikes = FALSE)\n",
    "  )\n",
    "\n",
    "subplot(p1, p2, nrows = 2, shareX = TRUE) %>%\n",
    "  layout(\n",
    "      title = \"Binomial Distribution for p = 0.3 and n = 10\",\n",
    "    hovermode = \"x unified\",\n",
    "      annotations = list(\n",
    " list(y = 0.9, text = \"Probability Mass Function\", showarrow = F, xref='paper', yref='paper'),\n",
    "  list(y = 0.3, text = \"Cumulative Distribution Function\", showarrow = F, xref='paper', yref='paper'))\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add553b4-044c-44b6-a23d-9ea1f81f4212",
   "metadata": {},
   "source": [
    "As you see the probability mass function takes on values up to 1, cumulative distribution function is the cumulative sum of those discrete values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2ebde1-5688-4afa-9d22-ed24e02aadc7",
   "metadata": {},
   "source": [
    "Now as an example of continuous distributions, we can create two vertical subplots for the probability density function and cumulative distribution function for beta distribution and we will see in the next section what beta distribution is all about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e705015e-4663-4477-bac9-9604e2fd0ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "qvals2 <- seq(0, 1, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3421780-d8c3-4a54-9030-c4f3e8b86786",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 <- plot_ly(x = qvals2, y = dbeta(qvals2, 0.3, 0.3), type = \"scatter\", mode = \"lines\") %>%\n",
    "  layout(\n",
    "    xaxis = list(\n",
    "      showspikes = TRUE, \n",
    "      spikemode = \"across\", \n",
    "      spikesnap = \"cursor\", \n",
    "      spikethickness = 1.5,\n",
    "      spikecolor = \"red\"\n",
    "    ),\n",
    "    yaxis = list(showspikes = FALSE)\n",
    "  )\n",
    "\n",
    "p2 <- plot_ly(x = qvals2, y = pbeta(qvals2, 0.3, 0.3), type = \"scatter\", mode = \"lines\") %>%\n",
    "  layout(\n",
    "    xaxis = list(\n",
    "      showspikes = TRUE, \n",
    "      spikemode = \"across\", \n",
    "      spikesnap = \"cursor\", \n",
    "      spikethickness = 1.5,\n",
    "      spikecolor = \"red\"\n",
    "    ),\n",
    "    yaxis = list(showspikes = FALSE)\n",
    "  )\n",
    "\n",
    "subplot(p1, p2, nrows = 2, shareX = TRUE) %>%\n",
    "  layout(\n",
    "      title = \"Beta Distribution for Shape Parameters α = 0.3 and β = 0.3\",\n",
    "    hovermode = \"x unified\",\n",
    "      annotations = list(\n",
    " list(y = 0.8, text = \"Probability Density Function\", showarrow = F, xref='paper', yref='paper'),\n",
    "  list(y = 0.3, text = \"Cumulative Distribution Function\", showarrow = F, xref='paper', yref='paper'))\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57648180-c259-4c75-a267-0da793b315a5",
   "metadata": {},
   "source": [
    "Here, the probability density function can take values above 1. When the slope of probability density function is negative, cumulative distribution function is concave, its slope is decreasing. When the slope of the probability density function positive, cumulative distribution function convex, its slope is increasing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f889db48-7f43-4132-8959-b38d37af5fdd",
   "metadata": {},
   "source": [
    "# Beta distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409f1105-cd56-4ff2-b17e-c8e051bab126",
   "metadata": {},
   "source": [
    "Under binomial distribution, we calculated the probabilities of having $k$ successes in $n$ trials in which probability of success is $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe11c739-15f0-4dd7-ac01-a9276df74072",
   "metadata": {},
   "source": [
    "Now let's take $k$ and $n$ as given, and calculate the probabilities of having $k$ successes in $n$ trials for different $p$ values:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aaf6c6-c139-46fe-8084-4e7329fcb910",
   "metadata": {},
   "source": [
    "Let's divide the whole domain of possible $p$ values between 0 and 1 into intervals of 0.001:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f102d43-972c-4ea8-83c5-4b1eb9f22c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals <- seq(0, 1, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d52c78-b43e-4fdb-a8f0-ceb1ec773148",
   "metadata": {},
   "source": [
    "Let's select some arbitrary $k$ and $n$ values.\n",
    "\n",
    "Foe example we can say, we tossed a coin only one time and got a head. So what is the likelihood of this data given different bias values. And repeat the same calculation when we have 2 and 3 tosses but still have only one head:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e27eef-f74f-4c9f-ad2d-d87a9395087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvals0 <- prop.table(dbinom(0, 0, pvals)) * length(pvals)\n",
    "dvals1 <- prop.table(dbinom(1, 1, pvals)) * length(pvals)\n",
    "dvals2 <- prop.table(dbinom(1, 2, pvals)) * length(pvals)\n",
    "dvals3 <- prop.table(dbinom(1, 3, pvals)) * length(pvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d5989-ff88-4656-8502-5c88a0da10f2",
   "metadata": {},
   "source": [
    "Plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5dcaf1-3ea6-418c-9dde-9a9a5fae25f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(pvals, dvals0, type = \"l\", ylim = c(0, 2.5), col = \"green\")\n",
    "lines(pvals, dvals1, col = \"red\")\n",
    "lines(pvals, dvals2, col = \"blue\")\n",
    "lines(pvals, dvals3, col = \"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89661bd0-671f-44ec-bb9a-56f1ae73dff9",
   "metadata": {},
   "source": [
    "- <span style=\"font-weight:bold;color:green;\">Green</span> line shows the relative plausibilities of the bias values in the domain between 0 and 1 when no tosses has been conducted yet. Without any tosses yet, all bias values has the same flat probability. So we can be totally ignorant about the bias value before any experiment provided that we have no prior belief.\n",
    "- <span style=\"font-weight:bold;color:red;\">Red</span> line shows the relative plausibilities of different bias values while the data we have is 1 head in 1 toss. Bias values closer to 1 have more relative plausibility.\n",
    "- <span style=\"font-weight:bold;color:blue;\">Blue</span> line shows the updated plausibilities when we have a second toss which is tail, so at that time we have 1 head in 2 tosses. Now the bias values closer to 0.5 are more plausible, with a bump in the middle and the relative plausibilities decreasing towards to 0 and 1 extremes.\n",
    "- <span style=\"font-weight:bold;color:black;\">Black</span> line shows the situation when we have three tosses and still only one head. Now the plausibilities of bias values closer to 1 decreased further while, values closer to 0 became more plausible, with the bump shifting left."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fddf01e-70df-4837-8db9-782d3274eda1",
   "metadata": {},
   "source": [
    "The above simulation shows a discrete version of beta distribution the PDF of which is:\n",
    "\n",
    "${\\displaystyle P(p;\\alpha ,\\beta )={\\frac {p^{\\alpha -1}(1-p)^{\\beta -1}}{\\mathrm {B} (\\alpha ,\\beta )}}.}$\n",
    "\n",
    "The domain of the beta distribution can be viewed as a probability, and in fact the beta distribution with shape parameters $\\alpha$ and $\\beta$ is often used to describe the distribution of a probability value p for a binomial distribution of $\\alpha - 1$ successes in $\\alpha + \\beta - 2$ trials.\n",
    "\n",
    "The beta function, ${\\displaystyle \\mathrm {B} }$, is a normalization constant to ensure that the total probability is 1. The binomial coefficient which appears in binomial distribution is a constant as ${\\displaystyle {\\binom {\\alpha+\\beta-2}{\\alpha-1}}}$ so in the PDF of beta it can be considered to be a part of the beta function, the normalization constant.\n",
    "\n",
    "The expected value or mean is:\n",
    "\n",
    "${\\displaystyle \\mu =\\operatorname {E} [X]={\\frac {\\alpha }{\\alpha +\\beta }}}$\n",
    "\n",
    "The variance is:\n",
    "\n",
    "${\\displaystyle \\operatorname {var} (X)={\\frac {\\alpha \\beta }{\\left(\\alpha +\\beta \\right)^{2}\\left(\\alpha +\\beta +1\\right)}}}$\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Beta_distribution)\n",
    "\n",
    "Note that the parameters for success and failures are incremented in $\\alpha$ and $\\beta$ parameters of beta distribution. Let's repeat the above simulation with beta distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8c48aa-b083-43c7-9c4c-d40820d8450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbetax <- function(a, b, x) x^(a-1)*(1-x)^(b-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f7d78d-a283-46ae-8c7d-8b59eb2ce926",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvals0b <- dbeta(pvals, 1, 1)\n",
    "dvals1b <- dbeta(pvals, 2, 1)\n",
    "dvals2b <- dbeta(pvals,2, 2)\n",
    "dvals3b <- dbeta(pvals, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a61711-8138-4813-b01f-9f5f859b7278",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(pvals, dvals0b, type = \"l\", ylim = c(0, 2), col = \"green\")\n",
    "lines(pvals, dvals1b, col = \"red\")\n",
    "lines(pvals, dvals2b, col = \"blue\")\n",
    "lines(pvals, dvals3b, col = \"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b09272e-6f2d-47df-898a-31ff32facadf",
   "metadata": {},
   "source": [
    "The previous simulation was a discrete version sum of the values of which are normalized to 1, so can be considered as a probability mass function. The second simulation above is the PDF of continuous beta distribution so the range is not capped at 1. And the parametrization is different, the k and N parameters of the first simulation using binomial distribution are equal to $\\alpha-1$ and $\\alpha+\\beta-2$ using the parameters of beta distribution.\n",
    "\n",
    "This change of scale and the reparametrization are the only differences. Other than that the shapes are the same:\n",
    "\n",
    "- <span style=\"font-weight:bold;color:green;\">Green</span> flat line reflects the case where we have no success or failures so any $p$ value is equally probable. That is in fact the uniform distribution that we will see later.\n",
    "- <span style=\"font-weight:bold;color:red;\">Red</span> line is the case with 1 success and 0 failure. Density of $p$ values linearly increase in the domain from 0 to 1.\n",
    "- <span style=\"font-weight:bold;color:blue;\">Blue</span> line is the case with 1 success and 1 failure. Density is higher in the middle one for $p$ values closer to 0.5.\n",
    "- <span style=\"font-weight:bold;color:black;\">Black</span> line is the case with 1 success and 2 failures. Density now shifts to lower $p$ values.\n",
    "\n",
    "And fact this progression shows one of the simplest case of Bayesian inference and the classical use case of beta distribution:\n",
    "\n",
    "As you may recall, Bayes rule is basically:\n",
    "\n",
    "${\\displaystyle P(B | A) = \\frac{P(B)P(A | B)}{P(A)}}$\n",
    "\n",
    "Hidden behind these symbols, the true meaning can be understood as such:\n",
    "\n",
    "- Let B be some hypothesis we want to test the probability of. We cannot directly observe hypothesis so we have to make an inference about it. For example the event of raining tomorrow may be an hypothesis, we cannot directly observe tomorrow's rain today.\n",
    "- Let A be some evidence or data related to the hypothesis. We directly observe and measure the evidence, such as the meteorological conditions today\n",
    "\n",
    "So the Bayes's rule in plain English is:\n",
    "\n",
    "${\\displaystyle\\begin{align}\n",
    "The\\ (posterior)\\\\\n",
    "probability\\ of\\ hypothesis\n",
    "\\\\ given\\ evidence\n",
    "\\end{align} =\n",
    "\\frac{\n",
    "\\begin{align}\n",
    "The\\ prior\\ probability && * && The\\ likelihood\\ of\\ evidence\\\\\n",
    "of\\ hypothesis && && given\\ the\\ hypothesis\n",
    "\\end{align}}{\\mathit{The\\ probability\\ of\\ evidence}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8310a6eb-0479-47b3-b417-0a67c477b872",
   "metadata": {},
   "source": [
    "Beta distribution can be used as a conjugate prior probability distribution for Bernoulli/binomial likelihood. But what is a conjugate prior?\n",
    "\n",
    "In Bayesian probability theory, if, given a likelihood function ${\\displaystyle p(x\\mid \\theta )}$, the posterior distribution ${\\displaystyle p(\\theta \\mid x)}$ is in the same probability distribution family as the prior probability distribution ${\\displaystyle p(\\theta )}$, the prior and posterior are then called conjugate distributions with respect to that likelihood function and the prior is called a conjugate prior for the likelihood function ${\\displaystyle p(x\\mid \\theta )}$.\n",
    "\n",
    "A conjugate prior is an algebraic convenience, giving a closed-form expression for the posterior; otherwise, numerical integration may be necessary. Further, conjugate priors may clarify how a likelihood function updates a prior distribution.\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Conjugate_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da9a4e2-e6af-4a8d-a7aa-34f5250b3d76",
   "metadata": {},
   "source": [
    "That explanation may seem to abstract, but we can clarify it with a concrete example.\n",
    "\n",
    "The question is,\n",
    "\n",
    "- We have a certain coin of a currency, denomination and vintage year.\n",
    "- We have prior knowledge of certain number of tosses resulting in $\\alpha - 1$  successes and $\\beta - 1$ failures, which can be used to model as a prior distribution of biases.\n",
    "- Now we collect new data with new tosses of the same coin, a total of $N$ tosses resulting in $z$ successes.\n",
    "- What is the posterior distribution of the biases?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae8e262-3174-4892-8f81-8d7874670ae3",
   "metadata": {},
   "source": [
    "The model will be as follows:\n",
    "\n",
    "- Let's model the prior distribution of biases $\\theta$ as a beta distribution: ${\\displaystyle beta(\\theta|\\alpha, \\beta)}$\n",
    "- The likelihood of the data for the range of bias values will be modeled by binomial distribution, normalized by the probability of data:\n",
    "  ${\\displaystyle \\frac {binom(z, N|\\theta)}{p(z,N)}}$\n",
    "- And the magic happens: The posterior distribution ${\\displaystyle beta(\\theta|\\alpha, \\beta)\\frac {binom(z, N|\\theta)}{p(z,N)}}$ is equal to\n",
    "${\\displaystyle beta(\\theta|\\alpha + z, \\beta + N - z)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b372f49-1b80-489e-a2dc-6b89f6c65dbd",
   "metadata": {},
   "source": [
    "So by using beta distribution as a conjugate prior distribution, to go from the prior to the posterior, we add $z$ to the $\\alpha$ parameter and\n",
    "$N - z$ to the $\\beta$ parameter of the prior distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cd655a-0d9c-45a7-93d3-05bf1d20580e",
   "metadata": {},
   "source": [
    "Let's confirm it by simulation. Let:\n",
    "- $\\alpha = 2$\n",
    "- $\\beta = 3$\n",
    "- $N = 4$\n",
    "- $z = 3$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b232cd1-c543-4b4b-889c-4665d4233b82",
   "metadata": {},
   "source": [
    "Get prior values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b43228-83e2-4225-8912-da4cd8fdf0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dprior <- dbeta(pvals, 2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abf874b-814a-4737-a08c-d54171ebfd4c",
   "metadata": {},
   "source": [
    "Get likelihood values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5480f7c2-e655-4fc7-88d2-8e8f52f59bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlhood <- prop.table(dbinom(3, 4, pvals)) * length(pvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f807e2-9225-467b-b217-4d88af8281ee",
   "metadata": {},
   "source": [
    "Get posterior values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0078c0-ab1b-480b-b73d-0c0c8376b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dposterior <- dbeta(pvals, 2+3, 3+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ccd880-3662-44ff-a736-737f51d13038",
   "metadata": {},
   "source": [
    "Plot priors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005a1d9d-a3f6-4622-aa60-86e9b02e81e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(pvals, dprior, type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d30d3e5-ff4c-4352-ae23-031aff405a5a",
   "metadata": {},
   "source": [
    "Plot likelihood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2793de-2584-463f-af40-a9ee698da402",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(pvals, dlhood, type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b530ee4b-3a00-4c40-9abc-c7ff38ca3e0d",
   "metadata": {},
   "source": [
    "And confirm the shape with $likelihood=posterior/prior$ identiy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73350b49-048e-4c70-8859-1d7f9bd4c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(pvals, dposterior/dprior, type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a9eb86-1eb2-4ec2-8db7-0104025357b5",
   "metadata": {},
   "source": [
    "Plot the posterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f007dd7-5da8-40bd-97f8-291bb5ff37fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(pvals, dposterior, type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432952ff-624f-41c7-bfa5-43a86d0642e0",
   "metadata": {},
   "source": [
    "Let's plot them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18426da-e834-4167-bc0f-49d557de020f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(pvals, dprior, type = \"l\", col = \"blue\", ylim = c(0, 2.5))\n",
    "lines(pvals, dlhood, col = \"red\")\n",
    "lines(pvals, dposterior, col = \"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a63364-5504-4749-84e1-cb69c7b7ed78",
   "metadata": {},
   "source": [
    "See that the <span style=\"font-weight:bold;color:black;\">posterior</span> is a compromise\n",
    "between <span style=\"font-weight:bold;color:blue;\">prior</span> and\n",
    "<span style=\"font-weight:bold;color:red;\">likelihood</span> \n",
    "\n",
    "So we start with a prior belief and update it with our new evidence to arrive at our posterior, the basis of Bayesian inference. Note that the posterior can serve as the prior for the next Bayesian updating with new evidence (e.g. new coin tosses).\n",
    "\n",
    "(Kruschke 2015, Doing Bayesian Data Analysis: A Tutorial with R, JAGS and STAN, p. 126-134)\n",
    "\n",
    "You can also play with the interactive app **Beta conjugate and binomial likelihood** under 06_prob_stat_2/apps with Shiny interface to simulate Bayesian updating with beta conjugate prior distribution. That is a very simple introduction to Bayesian modeling, which itself is based on simple main ideas. The beauty of this simplicity is very well summarized by Aubrey Clayton:\n",
    "\n",
    "> No professional hand-holding is necessary for Bayesian inference, outside \n",
    "of perhaps advising on what sorts of probability models might apply to cer-\n",
    "tain data-gathering procedures and what distributions would represent vari-\n",
    "ous states of knowledge. Once those are determined, the inferential process is \n",
    "automatic and simply consists of using Bayes’ theorem, as Jaynes and Richard \n",
    "Cox showed was required by the rules of consistent logical reasoning when \n",
    "expressed in probabilities. Because the frequentist methods sometimes violate \n",
    "these rules, they will necessarily sometimes produce illogical results.\n",
    "> ...\n",
    "> So, with one tool, we can handle \n",
    "these basic examples as well as the pathological ones, plus anything in between.\n",
    "But where do the problems facing working scientists actually fall on this\n",
    "\n",
    "(Clayton 2021, Bernoulli's Fallacy: Statistical Logic and the Crisis of Modern Science, p.239)\n",
    "\n",
    "and Ed Jaynes:\n",
    "\n",
    "> What the orthodox literature invariably fails to recognize is that all of these difficulties are\n",
    "resolved effortlessly by the uniform application of the single Bayesian method. In fact, once\n",
    "the Bayesian analysis has shown us the correct answer, one can often study it, understand\n",
    "intuitively why it is right, and, with this deeper understanding, see how that answer might\n",
    "have been found by some ad hoc device acceptable to orthodoxy.\n",
    "We shall illustrate this in later chapters by giving the solution to the aforementioned\n",
    ">\n",
    "> Our derivation showed that, from the standpoint of logic, the product rule (and therefore Bayes’\n",
    "theorem) expresses simply the associativity and commutativity of Boolean algebra. This is what\n",
    "gives us that greater freedom of action in calculations, leading in later chapters to the unrestricted\n",
    "use of Bayes’ theorem, in which we have complete freedom to move propositions back and forth\n",
    "between the left and right sides of our probability symbols in any way permitted by the product and\n",
    "sum rules. This is a superb computational device – and by far the most powerful tool of scientific\n",
    "inference – yet it is completely missing from expositions of probability theory based on the KSP (Kolmogorov System of Probability)\n",
    "work (which do not associate probability theory with information or inference at all).\n",
    "\n",
    "(Jaynes 2003, Probability Theory: The Logic of Science, p. 551,654)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3a935b-f490-4b1c-9d1f-07fff4963f16",
   "metadata": {},
   "source": [
    "# Higher moments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688bf933-b46b-49cc-8f21-e7953fa4d1dd",
   "metadata": {},
   "source": [
    "In probability theory and statistics, a central moment is a moment of a probability distribution of a random variable about the random variable's mean; that is, it is the expected value of a specified integer power of the deviation of the random variable from the mean.\n",
    "\n",
    "For a continuous univariate probability distribution with probability density function f(x), the n-th central moment of a real-valued random variable $X$ about the mean ($\\mu$) is:\n",
    "\n",
    "${\\displaystyle \\mu _{n}=\\operatorname {E} \\left[{\\left(X-\\operatorname {E} [X]\\right)}^{n}\\right]=\\int _{-\\infty }^{+\\infty }(x-\\mu )^{n}f(x)\\,\\mathrm {d} x.}$\n",
    "\n",
    "A standardized moment of a probability distribution is a moment (often a higher degree central moment) that is normalized, typically by a power of the standard deviation, rendering the moment scale invariant. The shape of different probability distributions can be compared using standardized moments.\n",
    "\n",
    "The standardized moment of degree n is ${\\displaystyle \\mu _{n}/\\sigma ^{n}}$ that is, the ratio of the n-th moment about the mean $\\mu _{n}$ to the n-th power of the standard deviation,:\n",
    "\n",
    "${\\displaystyle \\sigma ^{k}=\\mu _{2}^{k/2}=\\operatorname {E} \\!{\\left[{\\left(X-\\mu \\right)}^{2}\\right]}^{k/2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff94587e-0b1c-46ec-a632-8e8c6649add5",
   "metadata": {},
   "source": [
    "Moments are useful to define the shape of distributions.\n",
    "\n",
    "- Zeroth central moment and standardized moment are 1  since $x^0=1$\n",
    "- First central moment and standardized moment are by definition zero (average distance to mean is zero)\n",
    "- Second central moment is variance and second standardized moment is by definition 1 since central moment variance is divided by $\\sigma^2$ which is itself variance\n",
    "- Third and fourth moments are calculated as standardized moments and are denoted by $\\tilde {\\mu _n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e6e797-06ee-4f76-b255-4f7c9e3bf3e3",
   "metadata": {},
   "source": [
    "Third standardized moment is skewness, a measure of the asymmetry of the probability distribution of a real-valued random variable about its mean:\n",
    "\n",
    "${\\displaystyle {\\tilde {\\mu }}_{3}={\\frac {\\mu _{3}}{\\sigma ^{3}}}={\\frac {\\operatorname {E} \\left[(X-\\mu )^{3}\\right]}{\\left(\\operatorname {E} \\left[(X-\\mu )^{2}\\right]\\right)^{3/2}}}}$\n",
    "\n",
    "There are two kinds of skewness a distribution can have:\n",
    "\n",
    "- Negative skew: The left tail is longer; the mass of the distribution is concentrated on the right of the curve. The distribution is said to be left-skewed, left-tailed, or skewed to the left, despite the fact that the curve itself appears to be skewed or leaning to the right; left instead refers to the left tail being drawn out and, often, the mean being skewed to the left of a typical center of the data. A left-skewed distribution usually appears as a right-leaning curve.\n",
    "\n",
    "- Positive skew: The right tail is longer; the mass of the distribution is concentrated on the left of the figure. The distribution is said to be right-skewed, right-tailed, or skewed to the right, despite the fact that the curve itself appears to be skewed or leaning to the left; right instead refers to the right tail being drawn out and, often, the mean being skewed to the right of a typical center of the data. A right-skewed distribution usually appears as a left-leaning curve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a022dd-34e9-4ba8-9344-59178bce6c6e",
   "metadata": {},
   "source": [
    "Fourth standardized moment is kurtosis, the degree of “tailedness” in the probability distribution of a real-valued random variable. It is related to the tails of the distribution, not its peak. Higher kurtosis corresponds to greater extremity of deviations (or outliers), and not the configuration of data near the mean:\n",
    "\n",
    "${\\displaystyle {\\tilde {\\mu }}_{4}={\\frac {\\mu _{4}}{\\sigma ^{4}}}={\\frac {\\operatorname {E} \\left[(X-\\mu )^{4}\\right]}{\\left(\\operatorname {E} \\left[(X-\\mu )^{2}\\right]\\right)^{4/2}}}}$\n",
    "\n",
    "There are three types of kurtosis:\n",
    "\n",
    "- Distributions with zero excess kurtosis are called **mesokurtic**, or mesokurtotic. The most prominent example of a mesokurtic distribution is the normal distribution family, regardless of the values of its parameters.\n",
    "\n",
    "- A distribution with positive excess kurtosis is called **leptokurtic**, or leptokurtotic. A leptokurtic distribution has fatter tails. (\"Lepto-\" means \"slender\", originally referring to the peak. Examples of leptokurtic distributions include the Student's t-distribution, Rayleigh distribution, Laplace distribution, exponential distribution, Poisson distribution and the logistic distribution. Such distributions are sometimes termed super-Gaussian.\n",
    "\n",
    "- A distribution with negative excess kurtosis is called **platykurtic**, or platykurtotic. A platykurtic distribution has thinner tails. (\"Platy-\" means \"broad\", originally referring to the peak. Examples of platykurtic distributions include the continuous and discrete uniform distributions, and the raised cosine distribution. The most platykurtic distribution of all is the Bernoulli distribution with p = 1/2 (for example the number of times one obtains \"heads\" when flipping a coin once, a coin toss), for which the excess kurtosis is −2.\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Central_moment)\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Standardized_moment)\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Skewness)\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Kurtosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa547018-7569-48b6-a716-9843d206be19",
   "metadata": {},
   "source": [
    "We can calculate empirical moment values from the data using the above definitions or theorerical moments from the distribution parameters using their closed formed formulas.\n",
    "\n",
    "For example, for beta distribution, skewness is defined as:\n",
    "\n",
    "${\\displaystyle \\gamma _{1}={\\frac {\\operatorname {E} \\left[\\left(X-\\mu \\right)^{3}\\right]}{\\left(\\operatorname {var} (X)\\right)^{3/2}}}={\\frac {2\\left(\\beta -\\alpha \\right){\\sqrt {\\alpha +\\beta +1}}}{\\left(\\alpha +\\beta +2\\right){\\sqrt {\\alpha \\beta }}}}.}$\n",
    "\n",
    "And, excess kurtosis, defined as kurtosis minus 3, is defined as:\n",
    "\n",
    "${\\displaystyle {\\begin{aligned}{\\text{excess kurtosis}}&={\\text{kurtosis}}-3\\\\&={\\frac {\\operatorname {E} [(X-\\mu )^{4}]}{(\\operatorname {var} (X))^{2}}}-3\\\\&={\\frac {6[(\\alpha -\\beta )^{2}(\\alpha +\\beta +1)-\\alpha \\beta (\\alpha +\\beta +2)]}{\\alpha \\beta (\\alpha +\\beta +2)(\\alpha +\\beta +3)}}.\\end{aligned}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b982c8-e1b3-4a99-8ae5-09e16d9a1e36",
   "metadata": {},
   "source": [
    "## Skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ee486b-d7b6-4b0d-abff-97d3af7f25a4",
   "metadata": {},
   "source": [
    "Let's first explore beta distributions with different skewness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5857003b-4ef1-4ad7-951f-b94d1b1353c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qvals2 <- seq(0, 1, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9f5779-cad6-469f-b3c0-2fbeff6ca0ac",
   "metadata": {},
   "source": [
    "### Positive skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3190d418-2d22-4931-be25-bd6b0958efef",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 <- 3\n",
    "b1 <- 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d33f7-ec4b-4623-b87b-dead83b2c384",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(qvals2, dbeta(qvals2, a1, b1), type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c70fbf-9250-4bed-933b-5214728ae927",
   "metadata": {},
   "source": [
    "The distribution is right-skewed or positive skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3804bf-bce1-4151-8763-b0148abac78d",
   "metadata": {},
   "source": [
    "The theoretical skewness value is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4eb53b-5041-4f03-b936-3cfa39b44c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(2*(b1-a1)*sqrt(a1+b1+1)) / ((a1+b1+2)*sqrt(a1*b1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3540fc20-5fcf-4867-9ba2-c9f0905d23c4",
   "metadata": {},
   "source": [
    "Or easier by using `estimators` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfae7a47-e244-4ea1-876c-52b5b7a19367",
   "metadata": {},
   "outputs": [],
   "source": [
    "db1 <- Beta(a1,b1)\n",
    "skew(db1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc08116-aa17-4190-bb9b-dfc483c30a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew(db1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02832a82-db99-44a4-a284-a9e467e93b85",
   "metadata": {},
   "source": [
    "Let's create a sample and calculate empirical skewness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0b7237-a27d-45e5-8850-8fbb470f7137",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssize <- 1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf4be97-864a-4460-8aa9-06dddf4484a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "sampb1 <- rbeta(ssize, a1, b1)\n",
    "hist(sampb1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f16ac2-ed9b-41a2-9e14-cbb0ed942be7",
   "metadata": {},
   "source": [
    "Mean and (population) standard deviation reversed for Bessel correction are calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb3c332-59c0-462e-b11b-9650a0d9be5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanb1 <- mean(sampb1)\n",
    "sdb1 <- sd(sampb1)*sqrt((ssize - 1)/ssize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987113e4-3d06-45f0-b52a-168d1ac40b11",
   "metadata": {},
   "source": [
    "The skewness is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30afba07-cac4-4318-8a42-1034fc058825",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean((sampb1 - meanb1)^3) / (sdb1)^3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed9aa57-fbf1-4b20-8f07-679b038dee16",
   "metadata": {},
   "source": [
    "Or easier by using `moments` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2e7fd3-9e3b-458f-a67d-c8e4d8121e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness(sampb1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde3083a-633a-45d1-89b1-8e2c26c7755c",
   "metadata": {},
   "source": [
    "The skewness value is positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331452a9-cfb7-4859-9a7b-084d1f06be9d",
   "metadata": {},
   "source": [
    "### Negative skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de4d408-86f5-4730-82b9-bb531e8a08a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 <- 10\n",
    "b2 <- 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9eb394-15b4-4600-9bbd-4fa622867e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(qvals2, dbeta(qvals2, a2, b2), type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34993c2c-684f-44cb-878e-f911a6a4b7b3",
   "metadata": {},
   "source": [
    "The distribution is left-skewed or negative skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e81986c-980e-49a7-8c0b-af09bfa1e2dd",
   "metadata": {},
   "source": [
    "The theoretical skewness value is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14375dd7-57ba-481b-aa43-44575dc3739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(2*(b2-a2)*sqrt(a2+b2+1)) / ((a2+b2+2)*sqrt(a2*b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db333aae-351d-44a5-a255-26874b3884d2",
   "metadata": {},
   "source": [
    "Or easier by using `estimators` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8131f714-07c5-42fd-bb16-f6f925823a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "db2 <- Beta(a2,b2)\n",
    "skew(db2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e43c3d-f9aa-4933-a178-0d4fb4aaaf01",
   "metadata": {},
   "source": [
    "Let's create a sample and calculate empirical skewness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cb24be-f305-4c5f-b576-2199df3c4dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssize <- 1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26a113e-2f70-4f8e-85d9-99963a50d563",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "sampb2 <- rbeta(ssize, a2, b2)\n",
    "hist(sampb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb77ed9-1461-407e-a73e-10b52ee3c1c4",
   "metadata": {},
   "source": [
    "Mean and (population) standard deviation reversed for Bessel correction are calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b436d10e-3f1e-4a80-be96-f6ee2c53eabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanb2 <- mean(sampb2)\n",
    "sdb2 <- sd(sampb2)*sqrt((ssize - 1)/ssize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbd1154-c9b0-4653-897f-e94fb0e6727c",
   "metadata": {},
   "source": [
    "The skewness is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db2bb89-ceed-4c3d-ae69-8d5305df9b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean((sampb2 - meanb2)^3) / (sdb2)^3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a47e717-a31d-4fb8-8490-dffb2af19d69",
   "metadata": {},
   "source": [
    "Or easier by using `moments` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b9bc23-c08d-44ca-a39f-40210f6ee701",
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness(sampb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b87b46e-c961-4353-af84-a591d7fcb1e4",
   "metadata": {},
   "source": [
    "The skewness value is negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2a9449-3f7a-4248-a5a7-dad114ecaf20",
   "metadata": {},
   "source": [
    "## Kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cfd0ca-24f4-495b-a010-e506909aaedc",
   "metadata": {},
   "source": [
    "### Leptokurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad92a010-ce81-4390-b1a2-5a96b275fdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a3 <- 50\n",
    "b3 <- 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbed794f-0964-4bbf-80e9-1263bb55d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(qvals2, dbeta(qvals2, a3, b3), type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb658977-b019-4174-8834-0f67acc4285c",
   "metadata": {},
   "source": [
    "The distribution is leptokurtic, more extreme values in the tails, compared to the standard deviation of the distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e7fb3a-1c0c-424b-8693-c9036051caa5",
   "metadata": {},
   "source": [
    "The theoretical excess kurtosis value is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4e4f47-25f5-423a-97b0-c6e5f9cd84e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "6*((a3 - b3)^2 * (a3 + b3 + 1) - a3*b3 * (a3 + b3 + 2)) / (a3 * b3 * (a3 + b3 + 2) * (a3 + b3 + 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7abcc93-2dde-4d2e-910f-a8becbd92641",
   "metadata": {},
   "source": [
    "Let's create a sample and calculate empirical kurtosis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0860ee8-569c-43f7-9cfa-89d8cbe14a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssize <- 1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42a41e2-e658-4813-b1f2-f108cc76490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "sampb3 <- rbeta(ssize, a3, b3)\n",
    "hist(sampb3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6a60e7-0ead-42e7-b43e-30adc21fda78",
   "metadata": {},
   "source": [
    "Mean and (population) standard deviation reversed for Bessel correction are calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2d43aa-6a01-4707-a12b-bf19cbf6ac5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanb3 <- mean(sampb3)\n",
    "sdb3 <- sd(sampb3)*sqrt((ssize - 1)/ssize)\n",
    "meanb3\n",
    "sdb3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcda46a9-4bef-4912-8387-bd00feb8b290",
   "metadata": {},
   "source": [
    "The highest values that contribute to the kurtosis are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7555043c-e6a8-43ef-8f98-2c53bc9facfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort((sampb3 - meanb3)^4, decreasing = T)[1:10] / (sdb3)^4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce59b545-ad83-4d47-9b07-232296a1f9e4",
   "metadata": {},
   "source": [
    "The excess kurtosis value is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e166a37e-0055-4547-8473-e992e400ef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean((sampb3 - meanb3)^4) / (sdb3)^4 - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eced0ad8-11ea-41cc-976e-897f2404e430",
   "metadata": {},
   "source": [
    "Or easier by using `moments` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de17c56-f564-4889-bdf2-ffd1e754adf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kurtosis(sampb3) - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3ad5d5-ec3f-4999-af43-3ddb46e97194",
   "metadata": {},
   "source": [
    "The excess kurtosis is positive, distribution has fatter tails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b674a58e-a06b-4587-8329-741218c6f957",
   "metadata": {},
   "source": [
    "### Platykurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0bcfea-5719-4068-90d5-9200d41f453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a4 <- 1.5\n",
    "b4 <- 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6e72ec-434e-430f-806a-b6f298e5bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(qvals2, dbeta(qvals2, a4, b4), type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d29445e-c9d5-4e42-affb-07a2a3a4bbff",
   "metadata": {},
   "source": [
    "The distribution is platykurtic, less extreme values in the tails, compared to the standard deviation of the distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bda2ed-b890-4620-9e1b-18f2ef56355b",
   "metadata": {},
   "source": [
    "The theoretical excess kurtosis value is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdc1347-19a2-45f0-90c5-688cec2290f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "6*((a4 - b4)^2 * (a4 + b4 + 1) - a4*b4 * (a4 + b4 + 2)) / (a4 * b4 * (a4 + b4 + 2) * (a4 + b4 + 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fb3117-d81a-430c-a07f-623e16011428",
   "metadata": {},
   "source": [
    "Let's create a sample and calculate empirical kurtosis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a0d508-4aa2-48cd-87cf-f7b78c082adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssize <- 1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce43fa92-39ea-469f-9566-15fd3b9af926",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "sampb4 <- rbeta(ssize, a4, b4)\n",
    "hist(sampb4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af1d68b-11fd-4723-88d6-e1b7dae0a023",
   "metadata": {},
   "source": [
    "Mean and (population) standard deviation reversed for Bessel correction are calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fd2b73-61c5-41d0-8296-7a48bc3665e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanb4 <- mean(sampb4)\n",
    "sdb4 <- sd(sampb4)*sqrt((ssize - 1)/ssize)\n",
    "meanb4\n",
    "sdb4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050ed799-69f0-462c-b146-999a2b69e673",
   "metadata": {},
   "source": [
    "The highest values that contribute to the kurtosis are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea869df-b7c3-40c3-9252-b500f43845aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort((sampb4 - meanb4)^4, decreasing = T)[1:10] / (sdb4)^4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6ec352-9cb8-4576-a810-e30c26f82ebe",
   "metadata": {},
   "source": [
    "The excess kurtosis value is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a463f80-b36c-4338-a91c-9af075e8bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean((sampb4 - meanb4)^4) / (sdb4)^4 - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eda733f-f4ad-45fe-9f38-a006813bc79c",
   "metadata": {},
   "source": [
    "Or easier by using `moments` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa5d60f-61af-4515-82bd-bfd401d99e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "kurtosis(sampb4)  - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bce0570-cbfc-4cc2-b31a-9bdadb93e5d7",
   "metadata": {},
   "source": [
    "The excess kurtosis is negative, the distribution has flatter tails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82c80ed-4780-4c04-bca8-7aa561912015",
   "metadata": {},
   "source": [
    "You can also play around with **Higher Moments of Beta Distribution** app under 06_prob_stat_2/apps with Shiny interface to see how skewness and kurtosis changes with different $\\alpha$ and $\\beta$ parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a74254-7673-4f4a-8561-ef36178f3034",
   "metadata": {},
   "source": [
    "# Uniform distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9a5e35-465d-4571-bc5c-16763f83ff00",
   "metadata": {},
   "source": [
    "The two basic physical tools that we simulated at the beginning of the probability sessions are coin and dice. Provided that they are fair, all possible values in the sample space has the same probability, and hence they are equiprobably:\n",
    "\n",
    "- Each side to a fair coin has a 1/2 probability of occuring\n",
    "- Each side to a fair die has a 1/6 probability of occuring\n",
    "\n",
    "If we increase the number of the sides to a fair die - still keeping it fair - we will have more possible values $n$ each with a probability of $1/n$. In the limit we will have a perfect sphere dropped on a perfectly flat surface, so that any one of the $\\infty$ points on the sphere has the same equal probability of $1/\\infty=0$ while the total sample space $\\Omega$ has a probability of 1. So the equiprobable discrete distribution converges to a continuous distribution.\n",
    "\n",
    "Uniform distribution describes an experiment where there is an arbitrary outcome that lies between certain bounds. The bounds are defined by the parameters, ${\\displaystyle a}$ and \n",
    "${\\displaystyle b,}$ which are the minimum and maximum values. The difference between the bounds defines the interval length; all intervals of the same length on the distribution's support are equally probable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a28d1-17e3-46c2-aa29-c64b88e6e0c1",
   "metadata": {},
   "source": [
    "The probability density function for uniform distribution is:\n",
    "\n",
    "${\\displaystyle f(x)={\\begin{cases}{\\dfrac {1}{b-a}}&{\\text{for }}a\\leq x\\leq b,\\\\[8pt]0&{\\text{for }}x<a\\ {\\text{ or }}\\ x>b.\\end{cases}}}$\n",
    "\n",
    "Expected value is:\n",
    "\n",
    "${\\displaystyle \\operatorname {E} [X]={\\frac {b+a}{2}}}$\n",
    "\n",
    "Variance is:\n",
    "\n",
    "${\\displaystyle \\operatorname {Var} [X]={\\frac {(b-a)^{2}}{12}}}$\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Continuous_uniform_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9739fc5a-d110-4357-b9c0-2564c6ea3dfa",
   "metadata": {},
   "source": [
    "Let's get some samples from the standard uniform distribution with a support in the open interval (0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74c4bff-6939-4f5c-8b15-3f8299b18532",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(70)\n",
    "unisamp <- runif(1e4, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e54ad9-a33c-404d-9ee0-8bcff886445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(unisamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f089cc-5771-49fd-9121-35530443640c",
   "metadata": {},
   "source": [
    "Theoretical mean is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72fddcf-26a4-43b8-b8e7-e569eeb208d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(0+1)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c783b9-05ac-4a66-a526-63c5238b74ca",
   "metadata": {},
   "source": [
    "While the sample mean is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c42764-5df7-47e1-8c98-f540e5349e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(unisamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e805d47b-dcdd-4475-8c16-9ffc1ef9e90d",
   "metadata": {},
   "source": [
    "Theoretical variance is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d820e73-2d47-4b8e-b6fd-65e4e00014f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 - 0)^2 / 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4703d6d-c821-4599-9a54-d0f3dd904184",
   "metadata": {},
   "source": [
    "While the sample variance is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319db8c9-ad6f-4fd8-990c-0392ef0057fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(unisamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3525cc-de26-4fad-9b75-5e36060c34db",
   "metadata": {},
   "source": [
    "A useful aspect of standard uniformly distributed sample is that it can be used to be converted to samples of any distribution using the quantile functions, since basically every probability distributions CDF lies between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e34aff-1d6f-430d-9c6c-16ea5ffd88b6",
   "metadata": {},
   "source": [
    "So for example the standard uniform sample can be converted to a sample of beta values with parameters 0.5 and 0.5 (which is known as Jeffrey's prior from Harold Jeffrey):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a304202-4bd3-4f2d-848c-8c34664ab545",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(qbeta(unisamp, 0.5, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292d72df-26d4-41e3-a3fe-053b008631e4",
   "metadata": {},
   "source": [
    "Confirm with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4dd864-620d-4e41-97da-db93a77a260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(75)\n",
    "hist(rbeta(1e4, 0.5, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5d034e-7d44-475c-814d-51db3e582af4",
   "metadata": {},
   "source": [
    "Poisson with a rate of 20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e3cb45-37a4-4a57-b521-d14608d3e999",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(qpois(unisamp, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61a778a-64ac-480c-a76a-929bdebd7016",
   "metadata": {},
   "source": [
    "Confirm with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1b3e6c-aca1-42cd-ad59-7f7c552616d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(76)\n",
    "hist(rpois(1e4, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775f2466-08a0-4d56-b60a-c5a9b72e2d91",
   "metadata": {},
   "source": [
    "We will use uniform distribution to demonstrate central limit theorem later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379a0e97-ab48-44d9-b75a-8f61289182df",
   "metadata": {},
   "source": [
    "# Exponential distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b1cb37-95c0-4634-83c4-b87f20f15933",
   "metadata": {},
   "source": [
    "The exponential distribution is the probability distribution of the distance between events in a Poisson point process, i.e., a process in which events occur continuously and independently at a constant average rate.\n",
    "\n",
    "The distance parameter could be any meaningful mono-dimensional measure of the process, such as time between production errors, or length along a roll of fabric in the weaving manufacturing process.\n",
    "\n",
    "It is the continuous analogue of the geometric distribution, and it has the key property of being memoryless.\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Exponential_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ce3879-baba-4fb5-9905-ed9e845ff700",
   "metadata": {},
   "source": [
    "As you may recall from geometric distribution, the probabilities of successive discrete values in the probability mass function decay at a constant rate: The ratio between two successive values is always the same.\n",
    "\n",
    "Since exponential distribution is the continuous analogue of geometric distribution, the rate of change between the probabilities of equally spaced values in probability density fuction is always the same. To illustrate let's make the log transformation because log transformation converts the division in rate of change calculation to a difference operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ffdeb4-a18d-464e-8f84-c138469679d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff(log(dexp(0:10, 1/2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e6618e-e565-4036-a6ea-884623ef817e",
   "metadata": {},
   "source": [
    "The density is plotted as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea58132-4d12-4daf-a829-d2b5fdd10ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(dexp(seq(0, 10, 0.1), 1/2), type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d522b26-fdb5-4fad-b093-944c88ad017d",
   "metadata": {},
   "source": [
    "While the log density is a linear shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4b33c5-1f04-4b80-8d8f-6dff0b5fb127",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(log(dexp(seq(0, 10, 0.1), 1/2)), type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18a790c-8487-486a-b5cf-702064910a61",
   "metadata": {},
   "source": [
    "Which is quite obvious since logarithm is the inverse of exponentiation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de3fbaa-802c-497b-a5a8-182f62d8ee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log(exp(0:10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18496d8b-654f-413f-9c10-4ac2b38a412c",
   "metadata": {},
   "source": [
    "The mean or expected value of an exponentially distributed random variable $X$ with rate parameter $\\lambda$ is given by:\n",
    "\n",
    "${\\displaystyle \\operatorname {E} [X]={\\frac {1}{\\lambda }}}$\n",
    "\n",
    "The variance of $X$ is given by\n",
    "\n",
    "${\\displaystyle \\operatorname {Var} [X]={\\frac {1}{\\lambda ^{2}}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4158c4-8e57-4c15-8d97-2e0ae1835cad",
   "metadata": {},
   "source": [
    "We will first simulate a disrete version of a Poisson point process with Bernoulli trials to show that the geometric waiting times between consecutive successes converge to an exponential distribution.\n",
    "\n",
    "And then do the reverse, sample waiting times from an exponential distribution and show that the event counts form a Poisson point process and obey the Poission distribution.\n",
    "\n",
    "Exponential distribution is useful for describing wealth distribution inequalities. We will make a simple agent-based simulation of fair trade in an economy and see how laws of nature drive the wealth distribution towards inequality in the form of an exponential distribution.\n",
    "\n",
    "Exponential distribution is also a critical tool in survival analysis cases where the hazard rate is assumed to be constant. So in the end of the section, we will simulate a hypothetical living population with a constant mortality rate and show that the life expectancy obeys an exponential distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2eca5c-f537-49dd-8094-e486b6fb4eca",
   "metadata": {},
   "source": [
    "## Poisson process simulation from Bernoulli trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7c74a1-4f9e-4411-80ce-31f97432fc28",
   "metadata": {},
   "source": [
    "We know that when the number of trials is large and the probability of success is low, binomial distribution converges to Poisson distribution. For this reason, we will simulate 1e7 Bernoulli trials with a success probability of 0.5%. To show convergence to Poisson, we will treat each 1e3 trials as a unit interval so the expected rate of success is 5.\n",
    "\n",
    "So these 1e7 trials are supposed converge to 1e4 Poisson samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641e79a9-4adf-46f1-8ec4-071d9d6ae9a6",
   "metadata": {},
   "source": [
    "1e7 Bernoulli trials with a success probability of 0.5%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cc0f96-f1fb-4ee5-905f-c1bd85133068",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2)\n",
    "bernpois <- rbinom(1e7, 1, 5/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06832cc8-b895-4565-98fa-cc3e6f48bb1f",
   "metadata": {},
   "source": [
    "Check total number of successes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b01d666-cd79-4e3e-87c3-a680b2cc6206",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(bernpois)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa43ca8-dfa5-4463-8d97-85cf515ece33",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fee06cee-7023-48a7-b805-24a9b499a0ea",
   "metadata": {},
   "source": [
    "Since each 1e3 trial is considered an interval, we assume to have sampled 1e4 Poisson counts with a rate of 5.\n",
    "\n",
    "Let's check whether two distributions converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8945c25e-71bd-4c1f-a8e1-941318713d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(3)\n",
    "samppois <- rpois(1e4, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f282d22-ec45-4d03-bdba-e9f2f6d1ecb3",
   "metadata": {},
   "source": [
    "Check the number of successes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61719023-1150-4c3c-a958-1e47c5c7e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(samppois)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5df46a8-ba8a-426e-a3df-40114ed32220",
   "metadata": {},
   "source": [
    "And the historgram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52b2213-d430-4f28-8d88-cb2c9504d976",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(samppois)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9132d267-a59f-45ba-a1ec-932039e669b5",
   "metadata": {},
   "source": [
    "Now let's treat 1e7 trials as a matrix of 1e3 columns (for each interval) and 1e4 samples, and get the counts for each interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20009629-812e-4f69-a0d9-774acde604d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "samppois2 <- rowSums(matrix(bernpois, ncol = 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18c6333-33e5-434a-be17-d6c6697bdcfb",
   "metadata": {},
   "source": [
    "And see the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4aaec2-6f38-4f83-b67c-4ccc31d34477",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(samppois2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7cc660-eea9-4c4f-a15b-eafb2fea2187",
   "metadata": {},
   "source": [
    "Histograms reveal convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376d43e7-f9e1-4948-80b7-dbd6dac9b64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(prop.table(table(samppois2)), type = \"l\", col = \"red\")\n",
    "lines(0:20, dpois(0:20, 5), col = \"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5600beb9-e402-427f-a550-0125a8c09e97",
   "metadata": {},
   "source": [
    "Line plots of relative counts also confirm the convergence: Our discrete Bernoulli trials, compressed into 1000 trial intervals converge to Poisson distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4856efb1-5e90-444a-a347-e11836d29181",
   "metadata": {},
   "source": [
    "Poisson point process is the sequence of events arrival times of which are exponentially distributed.\n",
    "\n",
    "To see that discrete geometric arrival times converge to continuous exponential distribution, we will treat the sequence of discrete Bernoulli trials as a continuous Poisson point process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6106e98f-1833-4a78-af56-e2698161baec",
   "metadata": {},
   "source": [
    "Now, in order to calculate the failure lengths or arrival times, we will compress the data in the run lengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4513fbec-08b6-4511-b8fa-690a4ed7f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernpoisrl <- rle(bernpois)\n",
    "setDT(bernpoisrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b09a7e1-747c-437a-9aa4-a2af461f08f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernpoisrl %>% head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b99e3a-b9bc-483d-8640-65732778bc39",
   "metadata": {},
   "source": [
    "Get the non-zero waiting times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4df3a6-c651-431f-b116-1ee446dc5061",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernpois_wt <- bernpoisrl[values == 0, lengths]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd5d2a1-23cf-4bb3-82ad-d8f6c2900936",
   "metadata": {},
   "source": [
    "And calculate the total number of zero waiting times as sum of decremented run lengths of successes. So if there is a run length of 3 successes, we have 2 zero length waiting times in between:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62c8b03-cb08-4519-87a7-b49db30d40a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nzero <- bernpoisrl[values == 1, sum(lengths - 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b33fcb-510d-47f3-acad-785f671de408",
   "metadata": {},
   "source": [
    "We combine all zero and non-zero waiting times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c03e48-1dee-4e8d-a6e9-b30cba4c168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernpois_wt2 <- c(bernpois_wt, rep(0, nzero))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f62eb5-c13a-4a65-a8a8-9e8f107008de",
   "metadata": {},
   "source": [
    "And convert the discrete waiting times to continuous ones such that 1000 trials make up an interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5f12b4-3606-444b-a401-f7e489461634",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernpois_wt3 <- bernpois_wt2 / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f48967-3d6c-491d-8002-e29e02ef77bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "length(bernpois_wt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0386de-e8fe-4b4c-9b2f-3ab7273eec15",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(bernpois_wt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce12d72-b5b9-4757-929f-98d2c4dda615",
   "metadata": {},
   "source": [
    "See the distribution of waiting times extracted from discrete Bernoulli trials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7ffcc4-a02d-4e24-8ec2-b3303df0d638",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(bernpois_wt3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93695ef3-8033-4ed2-9b07-391353fae870",
   "metadata": {},
   "source": [
    "Variance is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53611176-c534-4238-8050-dc2fe6b6c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(bernpois_wt3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6564ea-05b4-4123-8dcb-2ee733f11e7a",
   "metadata": {},
   "source": [
    "Mean is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1038e8ad-453d-4327-8859-1b71c13a3d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(bernpois_wt3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184f542d-548e-42c1-8576-096a94e413f1",
   "metadata": {},
   "source": [
    "Now let's sample 5e4 values from an exponential distribution with a rate of 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1044b7f4-3deb-49a6-9807-e83ab08aca05",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(3)\n",
    "sampexp <- rexp(5e4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412bfb6b-b1da-4427-ba60-bb4dc7c040a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(sampexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47589752-8402-46bf-8718-540cbe6bf479",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(sampexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a72a9f-5753-47f4-b919-dad42df3991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(sampexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9590f029-69c9-4c08-b96c-786df7942394",
   "metadata": {},
   "source": [
    "Theoretical mean of geometric distribution with a p of 5/1000 and converted from a count to a rate by dividing by 1000 is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5004be38-d198-42c8-89aa-95013ade82a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "((1 - 5/1000) / (5 / 1000))/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ae011d-7459-43ab-b2d0-146d8e9bda77",
   "metadata": {},
   "source": [
    "Theoretical variance of geometric distribution with a p of 5/1000 and converted from the scale of counts to the scale of rates by dividing by 1000^2 is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33142536-bede-43d8-b946-6ada70341994",
   "metadata": {},
   "outputs": [],
   "source": [
    "((1 - 5/1000) / (5 / 1000)^2)/1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0399d5c0-2a6e-4616-85d7-0c5df6c528cc",
   "metadata": {},
   "source": [
    "The theoretical mean of exponential distribution with a rate of 5 is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d304d1df-7be8-492b-b09f-aed6706256b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "1/5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9031cda0-eca7-4349-8113-27c4d23be00a",
   "metadata": {},
   "source": [
    "And the theoretical variance is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc3cc73-5314-4347-b6f6-6fdf8807ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "1/5^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb05de33-1422-42e6-8b60-f4f7d7c23945",
   "metadata": {},
   "source": [
    "And last, let's compare the densities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97247140-6613-4513-8181-110c67fadc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpd <- density(bernpois_wt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e29a294-62e7-4494-b0cb-8e7b318b1ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpd2 <- density(sampexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0993c7-cae1-46a9-b60a-c73df10db239",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpd_s <- as.data.table(bpd[c(\"x\", \"y\")])[x >= 0.03]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fae585-323d-4f08-a174-dac8640348c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpd2_s <- as.data.table(bpd2[c(\"x\", \"y\")])[x >= 0.03]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7f81c7-0c49-45ca-bfdf-4f1cd4ee32fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(bpd_s, type = \"l\", col = \"blue\")\n",
    "lines(bpd2_s, col = \"red\")\n",
    "lines(seq(0, 2, length.out = 101), dexp(seq(0, 2, length.out = 101), 5), col = \"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b501e7a5-900c-49cb-b07d-0291d190d309",
   "metadata": {},
   "source": [
    "The empirical densities we get\n",
    "\n",
    "- From Bernoulli trials with a p of 0.5% and 1000 trials compressed into an interval\n",
    "- From simulations from exponential distribution with a rate of 5\n",
    "- And theoretical exponential distribution with a rate of 5\n",
    "\n",
    "all overlap perfectly!\n",
    "\n",
    "So we see that exponential distribution can be derived empirically from simple discrete Bernoulli trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca737b8-5cc7-4bd0-b0c1-1ea4e545a2d1",
   "metadata": {},
   "source": [
    "## Poisson process simulation from exponential distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826f5949-da4a-40c4-8b2c-277783582634",
   "metadata": {},
   "source": [
    "We have demonstrated that, Bernoulli trials with a low probability and high trial number converge to a Poisson distribution and the discrete waiting times with geometric distribution converge to exponential distribution.\n",
    "\n",
    "Now we will do the continuous analogue from the other way around: We will sample continuous waiting times for a Poisson point process from an exponential distribution and show that the counts form a Poisson distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d747af0-2ca3-4949-8063-d4fa6392a8db",
   "metadata": {},
   "source": [
    "We reuse the same code to create the exponentially distributed sample from previous section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d582e1bd-c97f-498f-9c1d-7938f2ac663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(3)\n",
    "sampexp <- rexp(5e4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b774fa-0a08-414d-9c70-03e77a512d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(sampexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1174dc08-3f52-430c-8c4b-bf5baadf7120",
   "metadata": {},
   "source": [
    "Variance and mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3652e9b-bab6-4b4c-bddb-1d133014cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(sampexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9696190d-99a3-4e2b-a41a-7414b4e362fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(sampexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ed5f06-5690-4d21-aba4-8e6833c52636",
   "metadata": {},
   "source": [
    "And total time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb510687-7ca4-4995-814e-3943f1d33c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(sampexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98553a1-d195-48f7-aeb2-91ce1b433496",
   "metadata": {},
   "source": [
    "We first get the cumulative sum of waiting times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a64b01a-6ab1-4c21-8e73-a002490935c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampexpc <- cumsum(sampexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832a9c8c-4550-40b6-9dd3-4953c03405fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(sampexpc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c610adf5-f954-4842-9da5-9552c312a2ec",
   "metadata": {},
   "source": [
    "Then we wrangle the data to get the distribution of the number of events per 1 interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6f28d4-2564-495c-80fe-00815ce075c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts1 <- sapply(split(sampexpc, round(sampexpc)), length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda2d8b2-9790-40dc-8430-c062bb14019b",
   "metadata": {},
   "source": [
    "Confirm the sum of counts is equal to the number of points created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3183906-2c25-42c5-afe8-525ea25a0a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(counts1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcde51a-50af-4264-ad9a-f7640196676d",
   "metadata": {},
   "source": [
    "Get the time intervals with no points until:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd5b83c-0060-4243-bbe9-dad10583d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(max(sampexpc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4492f6f-a2b7-4d73-aeec-038f0fd959dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "zerocounts <- setdiff(0:round(max(sampexpc)), as.integer(names(counts1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e01c26f-8032-482b-8c8c-b3f074ad3fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "zerocounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e7ebe9-d4ff-4c8a-a9ed-29bced3b6911",
   "metadata": {},
   "source": [
    "Augment the counts with zero count intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be26d0-09c3-4e0c-8f09-c7e17fc7cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts1b <- c(counts1, rep(0, length(zerocounts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75897d1e-3886-4708-b3c7-060a0aeefd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "length(counts1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b275b0-d3ef-44c8-b500-d3423a5a6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(counts1b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ab966-7253-4b59-8b56-df73e84b1f96",
   "metadata": {},
   "source": [
    "The contingency table of counts itself reveals a Poisson distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4498b26-e197-43be-8219-fdb7536538b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "countst1 <- table(counts1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851adf3b-b6e0-41db-9db2-121839388d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "countst1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b58e4c-d32c-4828-890b-c968733e5beb",
   "metadata": {},
   "source": [
    "And also the histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34a8c10-c0ea-474a-bd9a-2d09fa813a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(counts1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd8dac5-786b-4311-9e39-3fb5cf6e2cdf",
   "metadata": {},
   "source": [
    "And compare the PMF of the simulated counts and Poisson distribution with a rate of 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51bde95-2679-4eb1-9bd1-fc4480c563f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(prop.table(countst1), type = \"l\", col = \"blue\")\n",
    "lines(0:20, dpois(0:20, 5), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea75a89c-6659-4ac6-97f7-62322a2e3d6f",
   "metadata": {},
   "source": [
    "They almost totally overlap! So the Poisson point process with waiting times from an exponential distribution with a rate of 5 events per unit interval results in a count distribution from a Poisson distribution with a rate of 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a6f404-1492-4018-9f78-d48433f99012",
   "metadata": {},
   "source": [
    "The empirical mean and variance of the count distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdc4bc2-866a-420f-9e1b-3232b3ed0d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(counts1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f3f318-6346-4735-8ab2-ace9db15f1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(counts1b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f37528-06a2-4c0a-a8be-7882a0c9ed2a",
   "metadata": {},
   "source": [
    "Is in line with theoretical mean and variance of a Poisson distribution with rate 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b30221b-dea4-4eaa-bbd6-46a476eb4b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(Pois(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f901a1-dd4e-434f-9df2-3b5bf34bb337",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(Pois(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06733463-9448-48fa-9d8c-8a1d20712399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80828bb6-f8ff-4c78-a8bd-f4cf3dc98efc",
   "metadata": {},
   "source": [
    "Now let's use the same waiting times to get the counts of successes or events per 10 time interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c94f24-ed68-48b8-a9c8-0853ef2d88ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampexpc10 <- sampexpc / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cda16f7-6579-4d69-a3dd-2637eb027ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts10 <- sapply(split(sampexpc10, round(sampexpc10)), length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be513a7-1771-43f9-8948-d0f9f88badf7",
   "metadata": {},
   "source": [
    "Confirm the sum of counts is equal to the number of points created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b7f1c0-4de2-4030-a04d-cf06e69dbaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(counts10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeeef05-e3c0-4db5-8354-4a6f5932e4a6",
   "metadata": {},
   "source": [
    "Get the time intervals with no points until:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138b2003-cf99-4a56-95bc-2e4433183da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(max(sampexpc10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25164835-bd2b-4e03-9eae-62870785f399",
   "metadata": {},
   "outputs": [],
   "source": [
    "zerocounts10 <- setdiff(0:round(max(sampexpc10)), as.integer(names(counts10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9fdea7-d84c-4385-a883-dcc4322bc6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "zerocounts10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c8a7ad-4ea8-42bc-95ef-4f8ac99e1e8b",
   "metadata": {},
   "source": [
    "No 10 unit intervals with zero counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870a7e20-87bb-408c-95c2-2f2585b0b3ea",
   "metadata": {},
   "source": [
    "Anyway, augment the counts with zero \"zero\" count intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e2ef0a-c0f6-4cbf-923a-40bce859b481",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts10b <- c(counts10, rep(0, length(zerocounts10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d4b711-6205-4aad-a187-126f30fa1123",
   "metadata": {},
   "outputs": [],
   "source": [
    "length(counts10b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4052a6a3-47ad-4b7a-b2f5-0c56f7e9a83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(counts10b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d203f72-61da-407e-bfae-28bc5f54b0fa",
   "metadata": {},
   "source": [
    "The contingency table of counts itself reveals a Poisson distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42b1ac6-65fd-45ee-b9c4-211389c76b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "countst10 <- table(counts10b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb6a2db-793b-4015-9a2a-dc8060b42209",
   "metadata": {},
   "outputs": [],
   "source": [
    "countst10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09115da-ccc8-40cc-a07b-8112ae097e07",
   "metadata": {},
   "source": [
    "And also the histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8713946-cbea-42de-bde0-c7346daca878",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(counts10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21325a5-053c-41ff-82f8-281cbf64da4a",
   "metadata": {},
   "source": [
    "Get the density of count data to smooth out wigglyness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a438800e-a2e3-4ae3-bd4b-83156e4fd95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts10d <- density(counts10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490b892a-49b8-4355-8a7e-6f6e334d2aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts10dt <- as.data.table(counts10d[c(\"x\", \"y\")])[x >= 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8321228-d371-4f04-9d50-be7127260ee8",
   "metadata": {},
   "source": [
    "And compare the PMF of the simulated counts and Poisson distribution with a rate of 50:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167f3209-50da-437d-b057-2f14d8ed708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(counts10dt, type = \"l\", col = \"blue\")\n",
    "lines(0:75, dpois(0:75, 50), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e16d75e-73bc-4417-8cd6-ef7aa9fea9c4",
   "metadata": {},
   "source": [
    "They almost totally overlap again! So the Poisson point process with waiting times from an exponential distribution with a rate of 5 events per 1 unit interval results in a count distribution from a Poisson distribution with a rate of 50 when the count data for ten interval groups are aggregated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e125875c-1ad4-4a22-abfe-df35d7d3902e",
   "metadata": {},
   "source": [
    "The empirical mean and variance of the count distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78333a7d-18fa-4bf6-b346-4085ea8ef28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(counts10b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6dc737-906b-40c3-bf7d-91fa89d132b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(counts10b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e4c671-2a07-4ffc-a94c-244de8c1a30f",
   "metadata": {},
   "source": [
    "Is in line with theoretical mean and variance of a Poisson distribution with rate 50:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19292d5a-1bf6-4520-8de3-2a4c12d8bd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(Pois(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a97633e-d572-4f83-b5d2-86f6d859d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(Pois(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea713df-a466-46f8-af29-109b5e77dce0",
   "metadata": {},
   "source": [
    "That's the beauty of Poisson distribution: We can stretch or contract the time intervals to get a new count data and it will conform to a Poission distribution with a rate multiplied by the number of intervals!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379f315e-2a56-4c70-b728-06f77deae86b",
   "metadata": {},
   "source": [
    "In this case we could get a Poisson distributed count data with a rate of 50 events per 10 time interval by aggregating Poisson distributed count data with a rate of 5 events per time interval by compressing the data of 10 consecutive intervals into one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d12f12-fe0a-46ae-b4ec-cddb177b689c",
   "metadata": {},
   "source": [
    "## Wealth distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06314305-32ba-423c-a3c0-3465e8d4c81c",
   "metadata": {},
   "source": [
    "Now let's simulate financial transactions among the participants in a small economy using agent-based simulation.\n",
    "\n",
    "The idea is simple: All participants start out with the same wealth. In every iteration (period), all agents are matched and 1 unit is exchanged randomly from one side to the other.\n",
    "\n",
    "The probability of giving or taking does not depend on the size of current wealth. So we can assume that the rules of trade are completely fair. The only restriction is that noone is allowed to go below zero wealth. And to ensure that zero wealth agents are not excluded out of further trade, at the beginning of each iteration each zero wealth agents receive 1 unit randomly from a separate non-zero wealth agent.\n",
    "\n",
    "So in each iteration a single agent can give or receive at most 1 units.\n",
    "\n",
    "We create 1e3 agents, each with 20 units of initial wealth. And see what happens after 5e3 iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a99e04-8c5f-4f81-8988-59c5daec59db",
   "metadata": {},
   "outputs": [],
   "source": [
    "nagent <- 1e3\n",
    "niter <- 5e3\n",
    "initw <- 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fa2126-b322-48b2-8567-f1b448519cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(80)\n",
    "wealth_dt <- data.table(wealth = rep(initw, nagent), match = rep(0, nagent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9eff89-16cc-4918-8269-9470a90e87af",
   "metadata": {},
   "source": [
    "Check the starting total wealth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fa05df-3092-4f85-a33f-18beb9c5425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wealth_dt[, sum(wealth)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb55bc8-ae3c-4cac-acef-b781d0d9f7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(90)\n",
    "for (i in 1:niter)\n",
    "{\n",
    "    zerow <- wealth_dt[wealth == 0, .N]\n",
    "    wealth_dt[, wealthnew := wealth]\n",
    "    wealth_dt[wealth == 0, wealthnew := 1]\n",
    "    wealth_dt[wealth > 0, match := sample(c(rep(-1, zerow), rep(0, .N - zerow)))]\n",
    "    wealth_dt[match == -1, wealthnew := wealth - 1]\n",
    "    wealth_dt[wealth > 0 & match != -1, match := sample(.N) - 1]\n",
    "    wealth_dt[wealth > 0 & match != -1, wealthnew := wealth + sample(c(-1,1), .N), by = match %/% 2]\n",
    "    wealth_dt[, wealth := wealthnew]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facf8fd4-3148-44fe-a1c8-49f22164dec8",
   "metadata": {},
   "source": [
    "Check the ending total wealth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aa44fa-5b06-408d-8eaa-d1a3f5497b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "wealth_dt[, sum(wealth)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439a3f5b-2e7e-4427-94e5-5f45180123f4",
   "metadata": {},
   "source": [
    "See the histogram of ending wealth distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7910adb1-8650-4471-936c-043a8c262b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(wealth_dt[, wealth], breaks = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076a7f15-a8e4-40b1-8795-6e5eda21fb3b",
   "metadata": {},
   "source": [
    "See the largest wealth values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e83a215-5e43-4ebb-b403-706e1c3826e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wealth_dt[, sort(wealth, decreasing = T)][1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968bc87d-c141-4362-b0e8-476ab5a1dbc0",
   "metadata": {},
   "source": [
    "Now let's sample values from exponential distribution with a rate of reciprocal of initial wealth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa4d625-c682-44f1-9fe6-d15f1065a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(95)\n",
    "wealth_exp <- rexp(nagent, 1/initw)\n",
    "round(sort(wealth_exp, decreasing = T))[1:10]\n",
    "hist(wealth_exp, breaks = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4978c00-a63a-458c-80b9-a644a1c303ff",
   "metadata": {},
   "source": [
    "The extreme values from the simulation and sampled exponential values are quite close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb0da02-df41-4cd1-84a0-d454e3ee985d",
   "metadata": {},
   "source": [
    "Calculate the density of simulated wealths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924d0a27-4743-4ec3-a193-13229a575460",
   "metadata": {},
   "outputs": [],
   "source": [
    "wealth_dens <- density(wealth_dt[wealth > 0, wealth])[c(\"x\", \"y\")]\n",
    "setDT(wealth_dens)\n",
    "maxx <- wealth_dens[, max(x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2434c2-768b-4239-a727-85f61cbf6449",
   "metadata": {},
   "source": [
    "And compare with theoretical density with a rate of reciprocal of initial wealth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f5e208-9a98-4819-94e8-9fc0faf0993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(wealth_dens[x > 10], type = \"l\", col = \"blue\")\n",
    "lines(10:maxx, dexp(10:maxx, 1/initw), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4334c1cd-fa30-4384-ab5f-4e27a37af824",
   "metadata": {},
   "source": [
    "The densities almost perfectly overlap. So even fair laws of nature result in wealth inequality with an exponential distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b61cc2c-f615-421b-a84e-5643d2807153",
   "metadata": {},
   "source": [
    "## Life expectancy with constant hazard rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370b8701-6f4c-4277-a44b-f851d7905f27",
   "metadata": {},
   "source": [
    "Exponential distribution is also useful in survival analysis where the hazard rate is constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e2f91b-640f-418f-944f-6daf897787cb",
   "metadata": {},
   "source": [
    "Let's create a new born population of 1e4 people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5925f631-1623-4dc1-8646-b122c5b98ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "life_dt <- data.table(dead = rep(0, 1e4), life = rep(0, 1e4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24180de4-5b80-4c83-a82a-624405a5a35d",
   "metadata": {},
   "source": [
    "And set the hazard rate - proportion of still alive population to die in the period - to 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9d9789-638d-41a6-9570-4c3658b8234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate <- 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5472e417-a85a-4dfa-becd-ee049bc8757e",
   "metadata": {},
   "source": [
    "Initialize the period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96030d2c-13d7-4161-8eb7-c0eef02bb9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "periodx <- 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dec4de6-f1e5-4074-9026-da582fac47e4",
   "metadata": {},
   "source": [
    "Randomly sample from live population using Bernoulli trials with a bias of 0.1 and record the age (period) of each individual when they die.\n",
    "\n",
    "Continue until no one stays alive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf00645-75a5-45c7-b6de-544ac5bf6b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(5)\n",
    "while(life_dt[dead == 0, .N] > 0)\n",
    "{\n",
    "    periodx <- periodx + 1\n",
    "    life_dt[dead == 0, dead := rbinom(.N, 1, rate)]\n",
    "    life_dt[dead == 1 & life == 0, life := periodx]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452e37d4-be66-40cd-9d9b-9b33fcb79a22",
   "metadata": {},
   "source": [
    "Check the inidivuduals who die at the oldest age:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b52042f-1d31-4a02-8d9f-abb5e5b71555",
   "metadata": {},
   "outputs": [],
   "source": [
    "life_dt[, sort(life, decreasing = T)][1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7194f644-d15e-436f-b83a-bbad9ee538c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "periodx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b8679d-015b-4889-acb8-b921eb8801d3",
   "metadata": {},
   "source": [
    "Histogram of simulated life expectancies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a87ea7b-ab00-4952-8bdd-2c985ca24943",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(life_dt$life)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d34add7-2428-477d-a98d-9de991a11cfd",
   "metadata": {},
   "source": [
    "The mean life expectancy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c444fff-397c-4700-9690-d05fe9c650ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "life_dt[, mean(life)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bf19e0-2f2f-4db0-8db0-20e0643eefba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d8e1892-fd62-4968-8309-86186d445d9b",
   "metadata": {},
   "source": [
    "Simulate from exponential distribution with the same hazard rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191530a4-02ae-4109-b466-95bb1cfc257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(5)\n",
    "leexp <- rexp(1e4, rate)\n",
    "hist(leexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02474ec-acb4-4470-9029-1ca94dad97c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(sort(leexp, decreasing = T)[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e23cff-381e-45da-bebe-4dfb93c25d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "life_dens <- density(life_dt[, life])[c(\"x\", \"y\")]\n",
    "setDT(life_dens)\n",
    "maxx <- life_dens[, max(x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed52f016-0b72-4788-972f-e667a12d0d80",
   "metadata": {},
   "source": [
    "And compare with theoretical density with a rate of reciprocal of initial wealth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74089817-b4fc-45d7-ba5c-20c2e44de77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(life_dens[x > 10], type = \"l\", col = \"blue\")\n",
    "lines(10:maxx, dexp(10:maxx, rate), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b51b6f-d40a-46bd-bc10-2d5da3032ddf",
   "metadata": {},
   "source": [
    "And the densities almost perfectly overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12820e93-3bdb-4992-9c56-aca006b5a577",
   "metadata": {},
   "source": [
    "We saw that, exponential distribution occurs in different areas that are governed by simple laws of nature, like Bernoulli trials with a bias, totally random and fair equal sized transactions and demographics with a fixed mortality rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0856b84-186b-4e76-bc8a-6011eff7502f",
   "metadata": {},
   "source": [
    "# Normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c96779-045e-40fb-94e5-86479db87417",
   "metadata": {},
   "source": [
    "There are some famous bells in history ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2606fdc9-7877-4ceb-a7f2-1c24a7ffb06f",
   "metadata": {},
   "source": [
    "Cowbell of İnek Şaban:\n",
    "\n",
    "<video src=\"../imagesba/cowbell2.mp4\"  \n",
    "       controls width=\"500\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b8208e-58d2-4cd7-8332-0ae497c40648",
   "metadata": {},
   "source": [
    "School bell of Hafize Ana:\n",
    "\n",
    "<video src=\"../imagesba/hazife_ana2.mp4\"  \n",
    "       controls width=\"500\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67e5b8a-3303-4066-8828-907daebca96c",
   "metadata": {},
   "source": [
    "Bell of the Notre-Dame de Paris:\n",
    "\n",
    "<img src=\"../imagesba/notredame.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ad7fae-2540-4db8-8467-37506c061e36",
   "metadata": {},
   "source": [
    "And the bell curve of normal distribution:\n",
    "\n",
    "<img src=\"../imagesba/galtonboard2.jpg\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21724fd7-8496-4304-90f8-80927c5bf4f3",
   "metadata": {},
   "source": [
    "The formula that generates the above curve is as such:\n",
    "\n",
    "$${\\huge\n",
    "{\\bf\n",
    "f(x)={\n",
    "\\frac\n",
    "{1}{\\sqrt {2\\pi \\sigma ^{2}}\n",
    "}\n",
    "}e^\n",
    "{\n",
    "{-{\\frac {(x-\\mu )^{2}}{2\\sigma ^{2}}\n",
    "}\n",
    "}\n",
    "}\n",
    "}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66ed398-de13-4933-935c-5019499b5a55",
   "metadata": {},
   "source": [
    "It seems like quite an ugly and complicated formula. But we can always simplify a complicated thing to its basic constituents:\n",
    "\n",
    "<video src=\"../imagesba/connery4.mp4\"  \n",
    "       controls width=\"1000\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94256009-2fd6-41e0-973e-a96cc934c8f1",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<th> So let's simplify Sean Connery: </th>\n",
    "<th> Into İbrahim Abi: </th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "<img src=\"../imagesba/connery.jpg\" width=\"200\"/>\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "<img src=\"../imagesba/ibrahim_abi.jpg\" width=\"200\"/>\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08226124-f096-440d-8278-8e7628ee11aa",
   "metadata": {},
   "source": [
    "The <span style=\"font-weight:bold;color:red;\">red</span> part is just a normalizing constant so that the integral of the formula or the area under the curve sums up to 1:\n",
    "\n",
    "$${\\huge\n",
    "{\\bf\n",
    "{\n",
    "\\color{red}\n",
    "{\n",
    "\\frac\n",
    "{1}{\\sqrt {2\\pi \\sigma ^{2}}\n",
    "}\n",
    "}}e^\n",
    "{\n",
    "\\color{blue}\n",
    "{\n",
    "{-{\\frac {(x-\\mu )^{2}}{2\\sigma ^{2}}\n",
    "}\n",
    "}\n",
    "}\n",
    "}\n",
    "}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d263c4c-ee06-4475-bc8e-85155eadf0eb",
   "metadata": {},
   "source": [
    "Let's get rid of that part:\n",
    "\n",
    "$${\\huge\n",
    "{\\bf\n",
    "e^\n",
    "{\n",
    "\\color{blue}\n",
    "{\n",
    "{-{\\frac {(x-\\mu )^{2}}{2\\sigma ^{2}}\n",
    "}\n",
    "}\n",
    "}\n",
    "}\n",
    "}\n",
    "}\n",
    "$$\n",
    "\n",
    "The <span style=\"font-weight:bold;color:blue;\">blue</span> part centers and scales $x$ so that we always get a similar curve, centered on 0 and with the same width. Let's assume $\\mu=0$ and $\\sigma=1$. We can also get rid of the 2 in the denominator, so the formula boils down to:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7212ab8d-471e-4c24-9601-35e2741f9324",
   "metadata": {},
   "source": [
    "$${\\huge\n",
    "{\\bf\n",
    "e^{-x^2}\n",
    "}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdad6a14-11d6-4628-9a6f-730d135efa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals <- seq(-3, 3, 0.001)\n",
    "plot(xvals, exp(-(xvals^2)), type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6337d2-c402-41bd-b376-f8fb7621f000",
   "metadata": {},
   "source": [
    "Now we confirm that the simple form $\\bf {e \\text{ \\bf to the power of minus squared } x}$ creates the famous bell shape.\n",
    "\n",
    "Let's see why that shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4a3f18-6ba0-4c8d-b3a5-f15f17582d6f",
   "metadata": {},
   "source": [
    "## Error curve: From Simpson and Laplace to Gauss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c45a3f-2ae0-449b-8f29-1f333afa3aaf",
   "metadata": {},
   "source": [
    "The historical accounts and proofs here are mostly taken from Stahl 2006, The Evolution of Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64837c7-957e-4325-92c8-8c267d644464",
   "metadata": {},
   "source": [
    "Chronographically the first idea of a bell curve came from Abraham De Moivre in 1733 when he was searching for an approximation formula for binomial distribution of large N numbers. That was a practical need before the advent of electronic calculators.\n",
    "\n",
    "We will come to that normal approximation to binomial with simulation.\n",
    "\n",
    "The need to come up with a curve arose from errors in astronomical observations: If the observations about a celestial body are prone to measurement error, how should astronomers proceed to decide on a certain quantity from these observations.\n",
    "\n",
    "Thomas Simpson proposed the first error curves denoting the probability density of measurement errors. In 1774 Pierre Simon Laplace also came up with his version of an error curve with a different shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e23e5d-4656-4c9a-a122-afcc19ab1e28",
   "metadata": {},
   "source": [
    "Let's explore some different curves..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5c7d2e-aaab-4de9-8d62-4acf19900fcc",
   "metadata": {},
   "source": [
    "The values around zero, linearly, not so useful because their probabilities are not symmetric around zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4414a81a-804c-4d46-bdba-be954b52eecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(xvals, type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1b0cc3-dcf9-4441-a416-3c918041c1ed",
   "metadata": {},
   "source": [
    "The absolute value is symmetric but, the center value is not the tip of the curver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6e1860-b818-444d-82e9-9a40348ced72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(abs(xvals), type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f28cbb-c7f7-475a-8975-e1e81e99a945",
   "metadata": {},
   "source": [
    "Let's take its negative but the density is not too concentrated around the center, similar to Simpson's curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495a0e32-1d69-4d1c-a934-8529f57fe01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(-abs(xvals), type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f6d47c-ab15-4c8a-9e35-3361edd31b9e",
   "metadata": {},
   "source": [
    "Exponentiate it, now center is more concentrated but the tip is not curved but pointed, not differentiable. This is Laplace's first curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99901755-21bb-403f-9e9a-d085a9c4f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(exp(-abs(xvals)), type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6762078d-2672-4193-99b1-1e46dbddea02",
   "metadata": {},
   "source": [
    "And at last, when Giuseppe Piazzi discovered minor planet Ceres in 1801, it was occulted behind the Sun shortly after, leaving only a handful observations. There was a race towards guessing where Ceres should reappear.\n",
    "\n",
    "Carl Friedrich Gauss estimated an area in sky that did not agree with the estimations of others and he was right!\n",
    "\n",
    "He had three assumptions:\n",
    "\n",
    "- Small errors are more likely than large errors, hence curve has a maximum at 0\n",
    "- Curve is symmetric: likelihoods of $\\epsilon$ and $-\\epsilon$ are the same\n",
    "- The most likely value is the average of measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595a5b58-5040-4cc4-9edb-9cda17a27305",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(xvals, exp(-(xvals^2)), type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d6252d-6740-4f6c-a897-1c75c0026f68",
   "metadata": {},
   "source": [
    "Simplified proof of Gauss is as follows, without going into too much mathematical rigor:\n",
    "\n",
    "The density function is defined as $\\phi(x)$. The joint density function for the likelihood of data $M$ is:\n",
    "\n",
    "$\\large {\\Omega=\\prod_{i=1}^{n}\\phi(M_i - \\bar{M})}$\n",
    "\n",
    "where $\\bar{M}$ is the average of observations.\n",
    "\n",
    "In plain English: The product of the density or likelihood values for all errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b2cbbe-16d0-4ec8-875c-d3aabfa65e8d",
   "metadata": {},
   "source": [
    "with some omitted rigorous steps, we get that:\n",
    "\n",
    "$\\large {\\sum_{i=1}^{n}\\frac{\\phi'(M_i - \\bar{M})}{\\phi(M_i - \\bar{M})}} = 0$\n",
    "\n",
    "In plain English again: The sum of the ratios of the derivative of the likelihood function to the likelihood function itself for all data values is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36186c0-8b09-462a-98b7-f8ad6d1639bc",
   "metadata": {},
   "source": [
    "With again some omitted steps, we derive the following differential equation:\n",
    "\n",
    "$\\large {\\frac{\\phi'(x)}{\\phi(x)} = kx}$\n",
    "\n",
    "In plain English: The ratio of the derivative of the likelihood function to the likelihood function itself for a data value should be a constant times that data value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ffe8ae-0d84-46f1-a846-18a63b3ce9b5",
   "metadata": {},
   "source": [
    "And the solution to this differential equation suggests that, simplified version of our function has to be in the form of:\n",
    "\n",
    "$${\\huge\n",
    "{\\bf\n",
    "e^{-x^2}\n",
    "}\n",
    "}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "- the exponent ensures the bulge in the middle with thinner tails\n",
    "- squared power ensures that we have a symmetric curve with a smooth extreme in the middle\n",
    "- And negative of the power ensures that the extreme in the middle is a maximum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4350e12-54b5-4e11-ab7b-6d25c42cdd00",
   "metadata": {},
   "source": [
    "Now let's see whether Gauss was right in his proof.\n",
    "\n",
    "First get the density values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8699e236-9048-4d48-bc9c-56b9fa39d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdvals <- dnorm(xvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dc7473-15f9-4831-a03d-4de96bcf8e6e",
   "metadata": {},
   "source": [
    "Plot the ratio of the difference of densities to densities themselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c01b44-fb49-42c8-bc99-a17f30be4835",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(xvals[-1], diff(rdvals) / rdvals[-1], type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d0f950-c18d-450b-b384-197ec1d34445",
   "metadata": {},
   "source": [
    "Or better calculating the derivative of the normal distribution curve at the data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f18ce6d-d810-4f11-a7f4-e657e0c42f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "rddvals <- ddnorm(xvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8bf911-b6a6-4d20-ab98-02b6bba647da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(xvals, rddvals / rdvals, type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2fe6af-be48-4c88-ab08-168d69f207e3",
   "metadata": {},
   "source": [
    "We confirrm the negative constant multiplied by data values in line with:\n",
    "\n",
    "$\\large {\\frac{\\phi'(x)}{\\phi(x)} = kx}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977a854c-e7f9-4efa-9485-7c5c19b03879",
   "metadata": {},
   "source": [
    "And to confirm that:\n",
    "\n",
    "$\\large {\\sum_{i=1}^{n}\\frac{\\phi'(M_i - \\bar{M})}{\\phi(M_i - \\bar{M})}} = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0940525-baa9-4a7c-8f0d-27acc8edab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(rddvals / rdvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950386c4-d677-4004-8ff9-780a8aeb87e1",
   "metadata": {},
   "source": [
    "Quite close to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8cc2ea-4635-4c5c-b55a-625308a74d80",
   "metadata": {},
   "source": [
    "## Normal Approximation to Binomial: De Moivre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960b5f5b-8327-4174-a676-9dbaa804257c",
   "metadata": {},
   "source": [
    "In 1712 Willem 's Gravesande wanted to test the hypothesis that male and female are equally likely using birth data in London between 1629-1710.\n",
    "\n",
    "Taking the average of annual births as 11,429 and calculating the range of male birth ratios and multiplying with the average annual births he got the bounds for male births as between 5,745 and 6,128.\n",
    "\n",
    "For us the hypothesis is quite easy to test the hypothesis for a single year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d312006-9560-46fd-84e3-fcbecf6a2c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbinom(6128, 11429, 0.5) - pbinom(5744, 11429, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e28d37-7e7c-4b13-b398-db36c80e689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(dbinom(5745:6128, 11429, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4b3441-7c83-4865-b291-5448b7bbd62d",
   "metadata": {},
   "source": [
    "While 's Gravesande used the recursion of Newton:\n",
    "\n",
    "${\\displaystyle {\\binom {n}{x+1}}={\\binom {n}{x}}{\\frac {n-x}{x+1}}}$\n",
    "\n",
    "For a rational approximation, it was still quite a laborous task back in 1712.\n",
    "\n",
    "(Stahl 2006, The Evolution of Normal Distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029aeafa-8c22-4884-8e5a-243c6420a35b",
   "metadata": {},
   "source": [
    "In 1733, Abraham De Moivre proved that:\n",
    "\n",
    "${\\large {n \\choose k}\\,p^{k}q^{n-k}\\simeq {\\frac {1}{\\sqrt {2\\pi npq}}}\\,e^{-{\\frac {(k-np)^{2}}{2npq}}},\\qquad p+q=1,\\ p,q>0}$\n",
    "\n",
    "(https://en.wikipedia.org/wiki/De_Moivre%E2%80%93Laplace_theorem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df21a376-01aa-4f4b-ba3f-184cabc78a49",
   "metadata": {},
   "source": [
    "Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62b2c58-2049-410c-b900-0c5c60ab2134",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx <- 1000\n",
    "kx <- 318\n",
    "px <- 0.3\n",
    "qx <- 1 - px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa37f036-304b-47e2-a3a3-fdbd9b9a4112",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbinom(kx, nx, px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cdb23a-7d8d-4001-9c77-88c32a06c037",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1/sqrt(2*pi*nx*px*qx))*exp(-(kx - nx*px)^2 / (2*nx*px*qx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b76117-9b4d-409c-98d9-7435a8bd63e4",
   "metadata": {},
   "source": [
    "Note that, the function has the same basic form as the normal distribution curve:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb80acb-588e-4b37-a834-c867d6242dbc",
   "metadata": {},
   "source": [
    "$${\\huge\n",
    "{\\bf\n",
    "e^{-x^2}\n",
    "}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6591be98-88b1-4901-a742-648f0a5a35de",
   "metadata": {},
   "source": [
    "Now let's see how binomial distribution converges to normal distribution with large n:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655cf45d-ae1c-4332-bc01-1d861cad8206",
   "metadata": {},
   "source": [
    "Let's remember the mean and variance and binomial distribution:\n",
    "\n",
    "Expected value is:\n",
    "\n",
    "${\\displaystyle \\operatorname {E} [X]=np}$\n",
    "\n",
    "And variance is:\n",
    "\n",
    "${\\displaystyle \\operatorname {Var} (X)=npq=np(1-p)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953b70f5-ca60-4de0-ac13-dafe613f5d09",
   "metadata": {},
   "source": [
    "We write a function to plot the densities of both curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ef7b51-bf2b-42fc-80a5-c91679823cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "binnorm <- function(nx, bias)\n",
    "{\n",
    "    dbin <- dbinom(0:nx, nx, bias)\n",
    "    meanbin <- nx * bias\n",
    "    varbin <- nx * bias * (1 - bias)\n",
    "    sdbin <- sqrt(varbin)\n",
    "    dnor <- dnorm(0:nx, meanbin, sdbin)\n",
    "    plot(0:nx, dbin, type = \"l\", col = \"blue\", ylim = c(min(c(dbin, dnor)), max(c(dbin, dnor))))\n",
    "    lines(0:nx, dnor, col = \"red\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e59d160-2f55-44d7-a918-dd4dea4a4668",
   "metadata": {},
   "source": [
    "For $n = 2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748d4ba8-7adb-47f6-a8c3-9560b0d123ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "binnorm(2, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee44623-1b49-45f0-a829-881ab3665f7b",
   "metadata": {},
   "source": [
    "For $n = 5$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef053a7-1c41-401a-8a6c-085d668c2683",
   "metadata": {},
   "outputs": [],
   "source": [
    "binnorm(5, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df2c225-409b-4dcd-9555-0c0726b4769d",
   "metadata": {},
   "source": [
    "For $n = 10$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5446ae7e-1ec3-49c8-9adc-021ce181f90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "binnorm(10, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38a9890-e68d-4d96-ba82-66aaeda5d2ba",
   "metadata": {},
   "source": [
    "For $n = 20$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dae2c86-33b9-4daa-b6e2-93f67aa25d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "binnorm(20, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8620cc93-4381-45da-8da4-b6305c39eb49",
   "metadata": {},
   "source": [
    "You can also play around with the **Binomial to Normal Distribution** application under 06_prob_stat_2/apps with Shiny interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219f3e51-0fb1-4e3c-ae65-ce38cd21c13a",
   "metadata": {},
   "source": [
    "Galton Board, invented by Francis Galton, who coined the term regression, is an analogue simulation that demonstrates that binomial distribution converges to normal distribution with large $N$:\n",
    "\n",
    "<video src=\"../imagesba/galton.mp4\"  \n",
    "       controls width=\"300\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae33818-3f0b-4eed-b64c-e4a28138762b",
   "metadata": {},
   "source": [
    "## Normal Approximation to Poisson Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d522702-2375-4240-8513-4a7adb0092b7",
   "metadata": {},
   "source": [
    "Since Poisson distribution is a limiting case of binomial distribution, where N approaches infinity while p approaches 0, Poisson distribution converges normal distribution for large rate values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5325dbec-25cc-48fc-90f6-e9409201d3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisnorm <- function(nx, rate)\n",
    "{\n",
    "    dp <- dpois(0:nx, rate)\n",
    "    meanpois <- rate\n",
    "    varpois <- rate\n",
    "    sdpois <- sqrt(varpois)\n",
    "    dnor <- dnorm(0:nx, meanpois, sdpois)\n",
    "    plot(0:nx, dp, type = \"l\", col = \"blue\", ylim = c(min(c(dp, dnor)), max(c(dp, dnor))))\n",
    "    lines(0:nx, dnor, col = \"red\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36c6a1a-3837-4489-a26e-446f6cf98628",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisnorm(5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb985aae-24ec-4167-804c-3d149a26cc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisnorm(10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb1db5b-622b-4566-8940-4150915866be",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisnorm(20, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e648d062-fac7-41d4-8892-31fd857110e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisnorm(50, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19bb067-bab9-41e1-8229-e278b849ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisnorm(100, 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db38c5fd-e0f1-47e8-a936-7b195bb6f170",
   "metadata": {},
   "source": [
    "You can also play around with the **Poisson to Normal Distribution** under 06_prob_stat_2/apps with Shiny interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e22e1e-f6d9-4a95-9903-f52cf3b8448c",
   "metadata": {},
   "source": [
    "## Independent and Identically Distributed Random Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b19607f-0f4a-4a43-afc5-4c6fc884d6b3",
   "metadata": {},
   "source": [
    "A collection of random variables is independent and identically distributed (i.i.d., iid, or IID) if each random variable has the same probability distribution as the others and all are mutually independent.\n",
    "\n",
    "- Identically distributed means that there are no overall trends — the distribution does not fluctuate and all items in the sample are taken from the same probability distribution.\n",
    "- Independent means that the sample items are all independent events. In other words, they are not connected to each other in any way;[2] knowledge of the value of one variable gives no information about the value of the other and vice versa.\n",
    "\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c07cc9-7385-4503-a0d5-42ba0f109dbd",
   "metadata": {},
   "source": [
    "To show the concepts of identically distributed and/or independent variables, we will generate random variables from multivariate normal distribution and diagnose their distributions and correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16727cde-ef2c-4738-a1ca-6fa89c1ae683",
   "metadata": {},
   "source": [
    "Since the version of central limit theorem that we cover here requires the variable to be i.i.d, we first run simulations how independent/not-independent and identically/unidentically distributed variables are diagnosed:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e680e8-004f-43c6-9be3-de7b18fa4ee2",
   "metadata": {},
   "source": [
    "### Independent and Identically Distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644689b8-1425-422b-83ca-e6f0325bf486",
   "metadata": {},
   "source": [
    "First let's create 3 i.i.d variables, all with mean 0 and standard deviation 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04829055-a9e8-4d73-93ab-d68ddcd2f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "nv <- 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06911bd8-3cf6-4873-83c4-78404660db6b",
   "metadata": {},
   "source": [
    "Vector of fixed means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92832398-8577-4872-88a9-8622a313e239",
   "metadata": {},
   "outputs": [],
   "source": [
    "means <- rep(0, nv)\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed81422d-8a37-4afe-a5a9-8b59830947fe",
   "metadata": {},
   "source": [
    "Fixed standard deviations as a diagonal matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7d9846-b79c-48e6-8b2e-db242e6e349f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sds <- diag(rep(2, nv))\n",
    "sds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1d5a04-cdb0-4f88-8d4c-c442cdab71bf",
   "metadata": {},
   "source": [
    "Correlation matrix where all non-diagonal entries are zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2feece9-0298-4c37-a11c-4ebc26217070",
   "metadata": {},
   "outputs": [],
   "source": [
    "corm <- diag(rep(1, nv))\n",
    "corm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dfc07e-c2bb-48d4-a760-741e61ebcd66",
   "metadata": {},
   "source": [
    "The covariance matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7513af-265c-43d3-b06c-baf5b3085e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "covr <- sds %*% corm %*% sds\n",
    "covr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc61afb-2760-4547-94d2-f66022a742f3",
   "metadata": {},
   "source": [
    "Create the sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3357b96-dd51-4a60-bfc6-8f947033e6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(3)\n",
    "samp_iid <- mvrnorm(1e3, means, covr)\n",
    "samp_iid <- as.data.table(samp_iid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbf197a-b6c9-4bb9-97fd-87a80577a494",
   "metadata": {},
   "source": [
    "See their sd, mean and five point summaries, they are identical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94915843-5221-43f9-b867-01afc7bec7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_iid %>% lapply(function(x) c(SD = sd(x), as.list(summary(x)))) %>% rbindlist %>% round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5ca653-6742-4385-b1cd-1fe062f348b0",
   "metadata": {},
   "source": [
    "See their cross correlations, they are independent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb9aaed-259c-4c1d-82f0-cac2a6d692e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(cor(samp_iid), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babd6a34-c42d-42d8-b055-32b42ca918cb",
   "metadata": {},
   "source": [
    "Pairwise scatterplots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55159549-336c-4477-b4c2-c3ac31288992",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ggpairs(samp_iid)\n",
    "pairs.panels(samp_iid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0790854-f870-4510-95ba-7ca8e738e7e3",
   "metadata": {},
   "source": [
    "See that, scatter plots form clouds, with no apparent correlation and scales and distributions of the variables are identical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333e1169-1ce2-4ceb-8ce3-4291fb5ab3b1",
   "metadata": {},
   "source": [
    "### Independent but Not Identically Distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5712c46c-9ecb-4508-93fb-3dbfa66a7bf8",
   "metadata": {},
   "source": [
    "First let's create 3 variables, means and standard deviation of which are randomly drawn from respective distributions so that they are not identical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ffa2fc-aa00-41ad-8ec3-139c89cffb73",
   "metadata": {},
   "source": [
    "Means from normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304434c9-a863-4868-882c-ceabd2d0881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "means <- rnorm(nv, 0, 2)\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395fa1c1-0f64-4153-bb0d-de14c0709322",
   "metadata": {},
   "source": [
    "Standard deviations from exponential distribution, since they should always be positive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726c57e0-b70a-4485-9004-2ede0a07ee77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set.seed(2)\n",
    "sds <- diag(rexp(nv, 1/2))\n",
    "sds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98af5aeb-87a5-4041-8b7e-5912632ef6e9",
   "metadata": {},
   "source": [
    "Correlation matrix where all non-diagonal entries are zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973ad045-c309-493a-85d0-f9b939b5d340",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corm <- diag(rep(1, nv))\n",
    "corm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92a3f3c-bfe0-4306-9ee1-e3d8ffe748d2",
   "metadata": {},
   "source": [
    "The covariance matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb71a059-4d30-4e35-9125-414e0f89e3b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "covr <- sds %*% corm %*% sds\n",
    "covr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27edab83-70bd-4ecc-b1fb-ae2a09c92b63",
   "metadata": {},
   "source": [
    "Create the sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5eeb47-1537-497d-9802-b3632ff24860",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(4)\n",
    "samp_iid <- mvrnorm(1e3, means, covr)\n",
    "samp_iid <- as.data.table(samp_iid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929112bc-64f5-4187-bead-0abe12490333",
   "metadata": {},
   "source": [
    "See their sd, mean and five point summaries, they are unidentical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d874227-0352-4dd0-b425-2322a2e9c651",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_iid %>% lapply(function(x) c(SD = sd(x), as.list(summary(x)))) %>% rbindlist %>% round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb7d10c-c208-42e1-ac92-465ea4f37bbd",
   "metadata": {},
   "source": [
    "See their cross correlations, they are independent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a84978-28cb-47ed-a844-715ebb9eeac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(cor(samp_iid), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae4f818-aa02-40fb-b43b-6bcc118ee316",
   "metadata": {},
   "source": [
    "Pairwise scatterplots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ab81a8-b607-4eea-963e-74f6545efb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ggpairs(samp_iid)\n",
    "pairs.panels(samp_iid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8865870-e732-4f11-bd4d-c08382857513",
   "metadata": {},
   "source": [
    "See that, scatter plots form clouds, with no apparent correlation. However the scales and distributions of the variables are unidentical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4bf1e2-2602-4b12-bc87-67b97452518c",
   "metadata": {},
   "source": [
    "### Not Independent but Identically Distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006123d9-d071-4e68-8eba-9bab9695a6c7",
   "metadata": {},
   "source": [
    "Let's again create 3 identically distributed variables, all with mean 0 and standard deviation 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7276acf7-5cc7-48f6-96f7-65b9e0f8cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nv <- 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea706184-ad64-4f54-91bb-0320cf45972c",
   "metadata": {},
   "source": [
    "Vector of fixed means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a3a031-22c4-497a-86b2-bddd91c9821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "means <- rep(0, nv)\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2316ec-9311-4494-b3cf-1c59d5ba083f",
   "metadata": {},
   "source": [
    "Fixed standard deviations as a diagonal matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97eeba6-bbd6-42bb-bad1-252f7a76805f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sds <- diag(rep(2, nv))\n",
    "sds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a40eaed-cdd0-48b8-ba28-695c2afe67d8",
   "metadata": {},
   "source": [
    "Correlation matrix where non-diagonal entries are 0.6, so the variables are not independent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d931d122-c09b-4550-b11d-1adb15ab7861",
   "metadata": {},
   "outputs": [],
   "source": [
    "corm <- matrix(0.6, nrow = nv, ncol = nv)\n",
    "diag(corm) <- rep(1, nv)\n",
    "corm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136f7503-b6a9-4ab0-af06-0e93432e9c41",
   "metadata": {},
   "source": [
    "The covariance matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404db1eb-7f4d-45b8-8e3c-9580efd19561",
   "metadata": {},
   "outputs": [],
   "source": [
    "covr <- sds %*% corm %*% sds\n",
    "covr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6cd3f9-9434-4040-a74f-094b80c0b75f",
   "metadata": {},
   "source": [
    "Create the sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440e637c-abf0-4e12-a416-550a60559586",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(5)\n",
    "samp_iid <- mvrnorm(1e3, means, covr)\n",
    "samp_iid <- as.data.table(samp_iid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8314fc1-5143-4471-8768-8c4730d6bef4",
   "metadata": {},
   "source": [
    "See their sd, mean and five point summaries, they are identical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49297f2c-2346-45f9-9a03-a4db79b345a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_iid %>% lapply(function(x) c(SD = sd(x), as.list(summary(x)))) %>% rbindlist %>% round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0aa085-db79-45b7-96a4-a56b2915633d",
   "metadata": {},
   "source": [
    "See their cross correlations, they are not independent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6176aad0-1c41-4f2a-b031-5c794ff7ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(cor(samp_iid), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b76376-2680-4269-a961-48f10fae94d0",
   "metadata": {},
   "source": [
    "Pairwise scatterplots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ee1eae-b379-4bc3-9a0d-b565ce382c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ggpairs(samp_iid)\n",
    "pairs.panels(samp_iid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765fc0b1-d6ef-4c9d-aa8f-09b19dd38d9a",
   "metadata": {},
   "source": [
    "See that, scatter plots have clear elliptic shapes, showing positive cross corrrelations, however, scales and distributions of the variables are identical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd97d14-15c9-4853-9bf7-569c8276cddb",
   "metadata": {},
   "source": [
    "### Not Independent or Not Identically Distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a4b1e2-eee0-4262-8026-018487d17a29",
   "metadata": {},
   "source": [
    "Let's again create 3 variables, means and standard deviation of which are randomly drawn from respective distributions so that they are not identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a7e272-a027-4e19-a196-0ce717c2b0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nv <- 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc7df83-e4d2-4858-a0b4-18d9c1d159dc",
   "metadata": {},
   "source": [
    "Means from normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cf5e77-5721-4608-9757-59099771c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(6)\n",
    "means <- rnorm(nv, 0, 2)\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90544e7f-4007-46b8-867a-a0d0dfa1b433",
   "metadata": {},
   "source": [
    "Standard deviations from exponential distribution, since they should always be positive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49d1c81-1ecc-42d6-97b6-79db28f5fc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(7)\n",
    "sds <- diag(rexp(nv, 1/2))\n",
    "sds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3965088c-ca76-4160-88b7-be097761ab5d",
   "metadata": {},
   "source": [
    "Correlation matrix where non-diagonal entries are 0.6, so the variables are not independent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c0bf5d-1efd-4378-9605-3873f800ac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "corm <- matrix(0.6, nrow = nv, ncol = nv)\n",
    "diag(corm) <- rep(1, nv)\n",
    "corm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ea940e-8e06-41d6-9b1d-d3d34554be82",
   "metadata": {},
   "source": [
    "The covariance matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe21634d-d3f3-4c9f-b542-0f09ad67e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "covr <- sds %*% corm %*% sds\n",
    "covr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121a98ac-6a80-47a8-812b-407ef7c9c01b",
   "metadata": {},
   "source": [
    "Create the sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2039607-1c9c-41d6-b202-fe8b63a255c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(8)\n",
    "samp_iid <- mvrnorm(1e3, means, covr)\n",
    "samp_iid <- as.data.table(samp_iid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e183d72-f9f0-4f67-ae33-762e7f110be8",
   "metadata": {},
   "source": [
    "See their sd, mean and five point summaries, they are unidentical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0406c7c7-49fa-4d56-830e-e7764d727df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_iid %>% lapply(function(x) c(SD = sd(x), as.list(summary(x)))) %>% rbindlist %>% round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acdfcdf-2670-4131-9f22-49f99568b332",
   "metadata": {},
   "source": [
    "See their cross correlations, they are not independent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3122f345-c2d1-41c7-99d1-39834c52cd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(cor(samp_iid), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1037aa5f-2af1-48e9-acb9-5f8fea3846ee",
   "metadata": {},
   "source": [
    "Pairwise scatterplots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d556619a-d96a-400e-905a-15252d699654",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ggpairs(samp_iid)\n",
    "pairs.panels(samp_iid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b46b7eb-8f8e-4ede-a838-e58140dffc9f",
   "metadata": {},
   "source": [
    "See that, scatter plots have clear elliptic shapes, showing positive cross corrrelations, and, scales and distributions of the variables are unidentical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb479e8-3972-41b4-9199-47b5aa4a0623",
   "metadata": {},
   "source": [
    "## Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59145da-54fc-490e-b22e-8696a28de5af",
   "metadata": {},
   "source": [
    "We have demonstrated that, the standard deviation of the means of n-sized samples from a distribution with a standard deviation of $\\sigma$ is:\n",
    "\n",
    "${\\displaystyle \\sigma _{\\bar {x}}={\\sqrt {\\frac {\\sigma ^{2}}{n}}}={\\frac {\\sigma }{\\sqrt {n}}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12363e08-1fb8-40ae-885a-3e3c008e9a9d",
   "metadata": {},
   "source": [
    "Now we come back to the distribution of sample means for central limit theorem:\n",
    "\n",
    "Let \n",
    "${\\displaystyle X_{1},X_{2},\\dots ,X_{n}}$ denote a statistical sample of size \n",
    "${\\displaystyle n}$ from a population with expected value (average) \n",
    "${\\displaystyle \\mu }$ and finite positive variance \n",
    "${\\displaystyle \\sigma ^{2}}$, and let \n",
    "${\\displaystyle {\\bar {X}}_{n}}$ denote the sample mean (which is itself a random variable). Then the limit as \n",
    "${\\displaystyle n\\to \\infty }$ of the distribution of \n",
    "${\\displaystyle ({\\bar {X}}_{n}-\\mu ){\\sqrt {n}}}$ is a normal distribution with mean \n",
    "${\\displaystyle 0}$ and variance \n",
    "${\\displaystyle \\sigma ^{2}}$\n",
    "\n",
    "In other words, suppose that a large sample of observations is obtained, each observation being randomly produced in a way that does not depend on the values of the other observations, and the average (arithmetic mean) of the observed values is computed. If this procedure is performed many times, resulting in a collection of observed averages, the central limit theorem says that if the sample size is large enough, the probability distribution of these averages will closely approximate a normal distribution.\n",
    "\n",
    "The central limit theorem has several variants. In its common form, the random variables must be independent and identically distributed (i.i.d.). This requirement can be weakened; convergence of the mean to the normal distribution also occurs for non-identical distributions or for non-independent observations if they comply with certain conditions.\n",
    "\n",
    "The earliest version of this theorem, that the normal distribution may be used as an approximation to the binomial distribution, is the de Moivre–Laplace theorem that we saw above.\n",
    "\n",
    "The actual term \"central limit theorem\" was first used by George Pólya in 1920. Pólya referred to the theorem as \"central\" due to its importance in probability theory:\n",
    "\n",
    "> The occurrence of the Gaussian probability density $1 = e^{-x^2}$ in repeated experiments, in errors of measurements, which result in the combination of very many and very small elementary errors, in diffusion processes etc., can be explained, as is well-known, by the very same limit theorem, which plays a central role in the calculus of probability\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Central_limit_theorem)\n",
    "\n",
    "Here we will not go into rigorous proofs but show by simulation that sample means of i.i.d random variables from different distributions with finite means and variances converge to normal distribution as the sample size increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e707ab-1f41-47ee-b738-c3b0e07c9a45",
   "metadata": {},
   "source": [
    "### Distribution of sample means from uniform distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a15a8c9-48c4-49cc-b838-ede50d17c3bf",
   "metadata": {},
   "source": [
    "First let's start with uniform distribution.\n",
    "\n",
    "Take a large sample - a population - that we can draw smaller samples from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4bf235-d8b3-49f2-b01d-ea0b61a68da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampx <- runif(1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9ad861-a410-4dbd-9f9d-08ff91e798fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(sampx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12f651c-367e-4385-a5d0-7ae7c5331598",
   "metadata": {},
   "source": [
    "Let's get the theoretical statistics of the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7c651d-f664-464b-ba22-8ef6aa79d17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "distx <- Unif(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa916697-055d-42f9-9cce-83c8ab2808d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(distx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a5f635-af39-499a-869f-e94291fe1b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(distx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c304fc-b9c2-4b71-9097-488ba4ecb578",
   "metadata": {},
   "source": [
    "Simulate 1e4 samples of size 100 and get their means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e715eaf-9919-4bf7-aed9-74a9adc62270",
   "metadata": {},
   "outputs": [],
   "source": [
    "simx <- rowMeans(t(replicate(1e4, sample(sampx, 100))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c27231-8b27-4bac-9eb3-52f8089f2ab7",
   "metadata": {},
   "source": [
    "The shape is a bell curve but does it converge to normal distribution sufficiently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0a15b0-00e7-4307-b8cb-ed3672334474",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(simx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a511f3-9aab-44a3-a772-0afc3bd14408",
   "metadata": {},
   "source": [
    "Empirical statistics of the population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4034afcb-382d-44cb-915a-532fc11f51ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e31f70-1d82-4980-bf37-137758924580",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112707a3-d5e4-430a-a2a9-816dc1d2244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(sampx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e36120-996f-4305-b802-8d2f10d22e37",
   "metadata": {},
   "source": [
    "And empirical statistics of the sample means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971a0200-5c8c-4de4-af85-b294e0e11614",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9df076-6921-4907-84ac-964a03f545e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c9f4bd-2d05-4204-97ff-f287c3afd954",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(simx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ab12cc-7aaf-4eae-9098-60af84e5d9b9",
   "metadata": {},
   "source": [
    "Standard deviation obeys the square root law:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed17c51f-c721-4a91-af96-379bfcf9847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(distx)/sqrt(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf517b-459b-488e-8da5-c2f6cc98614b",
   "metadata": {},
   "source": [
    "Now get the density of the distribution of sample means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806fff40-2d3b-4d1a-b541-4c66e1dab9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "densx <- density(simx)[c(\"x\", \"y\")]\n",
    "setDT(densx)\n",
    "maxx <- densx[, max(x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4439d2d-45eb-477b-a5b5-9a8f000b50d0",
   "metadata": {},
   "source": [
    "And compare with theoretical density of the normal distribution with the mean of the population and sd of the population divided by square root of sample size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d51baf-76b3-4a1b-b95e-9970370b28e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(densx, type = \"l\", col = \"blue\")\n",
    "lines(densx$x, dnorm(densx$x, mean(distx), sd(distx)/sqrt(100)), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1735f906-d0bf-4107-8911-a322b48620ef",
   "metadata": {},
   "source": [
    "They almost perfectly overlap!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38d920f-2456-4dfd-bde8-862d716cb9aa",
   "metadata": {},
   "source": [
    "So means of i.i.d. samples drawn from uniform distribution converge to normal distribution as sample sizes converge to $\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b106979-715e-4628-83c2-ff445bee5efb",
   "metadata": {},
   "source": [
    "### Distribution of sample means from exponential distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d886ec3-2477-4ea7-ba06-a2f821a5d507",
   "metadata": {},
   "source": [
    "Repeat the same procedure for exponential distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6be8c94-836d-448b-8950-2a93401ffe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampx <- rexp(1e5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d39538-489e-4798-a752-e1d5de82b05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7749f527-5780-4b61-955d-ad3da420d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "distx <- Exp(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7327b932-e2c3-4dae-8c3c-71a69d397a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(distx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c1ffa9-e30a-4a9f-8620-8a0cb062346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(distx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b603ca31-a3c7-4712-a43a-e1e67a7e8e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "simx <- rowMeans(t(replicate(1e4, sample(sampx, 100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b021f59-7311-4d74-90e8-eecd5fc13ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99fde98-1be7-405a-b064-d9824d80c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a400165c-f357-42fb-bcd1-da562676b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dc7a45-4011-4ff2-9855-53ec418cd323",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c40d4f-f788-4997-9657-e9e2fbc8c42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d20add9-9696-489b-9068-a687939ffd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7078fa81-6df6-4ec4-bec7-781ec1729426",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e931d0af-c078-4471-86ac-c3925ff52284",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(distx)/sqrt(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e209bf8-ea13-440b-a20e-813c259d7c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "densx <- density(simx)[c(\"x\", \"y\")]\n",
    "setDT(densx)\n",
    "maxx <- densx[, max(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d055a9-fb64-4b02-813f-50b1fff486f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(densx, type = \"l\", col = \"blue\")\n",
    "lines(densx$x, dnorm(densx$x, mean(distx), sd(distx)/sqrt(100)), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96df8d52-0a7f-4169-ba46-52ec8c44d9da",
   "metadata": {},
   "source": [
    "They almost perfectly overlap!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ca5e9f-af46-4fa3-bd0d-cdbfe763f94e",
   "metadata": {},
   "source": [
    "So means of i.i.d. samples drawn from exponential distribution converge to normal distribution as sample sizes converge to $\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61e4ce7-098c-4575-aeac-64f57488dec5",
   "metadata": {},
   "source": [
    "### Distribution of sample means from beta distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd254c2-c935-4658-8280-381cf18f560b",
   "metadata": {},
   "source": [
    "And last, let's draw a large sample from the Jeffrey's Prior, beta distribution with $\\alpha = 0.5, \\beta = 0.5$ parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf52de0-7fa3-40f5-98ea-97afff3659b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampx <- rbeta(1e5, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7b5386-dfa3-4591-b65f-88f079cbffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da6b377-1ea7-471a-8dce-b822600e77b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "distx <- Beta(0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a05591-f062-4c0b-8c15-24ecb17072b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(distx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98ab2be-d9ad-460a-adfc-fee8a9c0fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(distx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f3daa2-aa3a-4a3e-9d57-42b4f7826233",
   "metadata": {},
   "outputs": [],
   "source": [
    "simx <- rowMeans(t(replicate(1e4, sample(sampx, 100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a457dbf4-7670-4937-b914-b11443d9e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c6c961-f155-46be-9afc-eaa852221471",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1631079b-bf3a-46d6-9398-cb184bdef59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac1bd13-a513-4e44-bde5-108fc5ec66d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c878d8ed-346e-4e4f-b019-11cec0811248",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a639ca4d-862a-44ef-97a6-feda9de11eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73592bf-5db5-4bc5-924c-935d3c93dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8aa55b-e9e2-49d9-996d-dee606ad74cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(distx)/sqrt(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9922580c-dfe8-4b0d-81f0-00e5aae3064a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7cfc2b-5443-4148-bdb4-482d9121dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "densx <- density(simx)[c(\"x\", \"y\")]\n",
    "setDT(densx)\n",
    "maxx <- densx[, max(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc70979f-7f12-4983-bddb-31240ec3781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(densx, type = \"l\", col = \"blue\")\n",
    "lines(densx$x, dnorm(densx$x, mean(distx), sd(distx)/sqrt(100)), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddafd1e6-4c1d-45a0-bdb9-cfa8961d1f43",
   "metadata": {},
   "source": [
    "They almost perfectly overlap!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6396d104-bcd1-488f-8a76-2b88548c2e5e",
   "metadata": {},
   "source": [
    "So means of i.i.d. samples drawn from beta distribution converge to normal distribution as sample sizes converge to $\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e568df5f-b770-477c-a90d-7aa62c126050",
   "metadata": {},
   "source": [
    "Sample means drom quite different distributions (with finite mean and variance) converge to normal distribution with larger sample sizes.\n",
    "\n",
    "You can also play around with the **CLT with Beta Distribution** under 06_prob_stat_2/apps with Shiny interface to see sample means from a population that obeys the Jeffrey's Prior converges to normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c65684-86ed-45b0-840d-6f421a77b6c5",
   "metadata": {},
   "source": [
    "### Distribution of sample means from gamma distribution (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865e938b-4913-496a-8161-1b6e856a667d",
   "metadata": {},
   "source": [
    "Now let's repeat the same steps with a population from gamma distribution and show that distribution of sample means converge to normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a3e527-d4fb-4cfc-9f7a-3f718169eab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampx <- rgamma(1e5, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f229c0-cc25-420f-91f6-e129544ded0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d490fe-e11e-4730-99b5-dd29b17b52c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "distx <- Gam(3, 1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a24c62d-90f4-4c77-ba0f-fd70df5b828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(distx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc815e2-b0da-4d44-96da-c26eff817a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(distx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898d76a7-dee9-4379-aa5c-a49969d4b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "simx <- rowMeans(t(replicate(1e4, sample(sampx, 100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ca4045-c066-465f-953d-2e5e5a53f518",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5a0afb-305f-48da-9af9-58234a2059b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc52142-5997-455b-bf47-bf31acf785aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e50f3b9-d2d0-4c4c-80f7-f63c7df75f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacff7bf-5ec4-4efc-8536-7f0313d2fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23962c76-90db-44d7-8b61-944f652280fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d982f01f-2c74-45e7-8b06-2354cc96e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ab784a-3e33-4b6b-84fc-7286038f057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(distx)/sqrt(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cf6b9f-a28a-4032-aefc-a0b28238b2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c3eb93-f35c-4e6e-a3e4-107b54d2d06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "densx <- density(simx)[c(\"x\", \"y\")]\n",
    "setDT(densx)\n",
    "maxx <- densx[, max(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2337bd84-a87a-45d1-b330-374c52af4b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(densx, type = \"l\", col = \"blue\")\n",
    "lines(densx$x, dnorm(densx$x, mean(distx), sd(distx)/sqrt(100)), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceefaf74-ff3d-4461-b5e0-9cdc35c0086c",
   "metadata": {},
   "source": [
    "They almost perfectly overlap!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4031976-657f-4344-aefa-5e64118b306b",
   "metadata": {},
   "source": [
    "So means of i.i.d. samples drawn from gamma distribution converge to normal distribution as sample sizes converge to $\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a63ed2-d253-42f2-9f31-4dca270dbb8e",
   "metadata": {},
   "source": [
    "### CLT with Correlated Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff8a705-82a6-458a-ae0f-03ee1bd03e6d",
   "metadata": {},
   "source": [
    "Now let's check whether means of samples from non-independent variables converge to normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0981c5-9bb5-43a1-a0c7-6b8fa8d0be1d",
   "metadata": {},
   "source": [
    "For this we will do an easy trick: We can draw random variables from multivariate normal distribution with any covariance structure.\n",
    "\n",
    "In order to convert the normally distributed variables to any distribution:\n",
    "\n",
    "- First we will get the p values corresponding to the normally distributed q values of the random samples\n",
    "- Then we will get the q values corresponding to the p values using any distribution we would like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b9d495-eeb0-42e5-b6e8-1f872f8cf30b",
   "metadata": {},
   "source": [
    "Let's first create the multivariate normal and identically distributed sample:\n",
    "\n",
    "Number of variables and the pairwise correlation, we will start with i.i.d variables with no correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21006a4-2643-491c-bd1b-0058da092184",
   "metadata": {},
   "outputs": [],
   "source": [
    "nv <- 100\n",
    "corx <- 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14052a43-3d5f-410f-aa77-db99a42cdd41",
   "metadata": {},
   "source": [
    "Means and sd's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a25de-5656-48ac-8adf-d77bca0ce650",
   "metadata": {},
   "outputs": [],
   "source": [
    "means <- rep(0, nv)\n",
    "sds <- diag(rep(1, nv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aec71a-84c5-49c7-b1fc-1d5f2e3f033d",
   "metadata": {},
   "source": [
    "Correlation and covariance matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f590f137-69fb-4105-9da3-f01653bc03c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corm <- matrix(corx, nrow = nv, ncol = nv)\n",
    "diag(corm) <- rep(1, nv)\n",
    "covr <- sds %*% corm %*% sds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208f18a7-3f64-469f-aba6-10143e3b3e51",
   "metadata": {},
   "source": [
    "And draw the normally distributed samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cf3429-88ec-4061-a14d-d279d557732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(5)\n",
    "samp_iidx <- mvrnorm(1e3, means, covr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110285f1-d7fd-4905-8f59-db4054a8c810",
   "metadata": {},
   "source": [
    "Let's try exponential distribution. Convert q values from normal distribution to distribution-agnostic p-values than to q-values from exponential distribution with just a single line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec9d7db-31f2-4bee-8963-61a1cb076776",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(rowMeans(qexp(pnorm(samp_iidx))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f2f5ac-dba9-4374-85d5-5acd1f1d3ce4",
   "metadata": {},
   "source": [
    "Sample means from i.i.d. variables converge to normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c6cb00-64a4-4576-b0ac-2ba95d221dcf",
   "metadata": {},
   "source": [
    "Now let's try different cross correlation values:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86169da-b97d-4ddb-b82d-1165703d3488",
   "metadata": {},
   "source": [
    "First wrap the steps into a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e53957-3a85-4310-a7fb-406e5e1a4905",
   "metadata": {},
   "outputs": [],
   "source": [
    "clt_exp <- function(corx, nv = 100, nsamp = 1e3)\n",
    "{\n",
    "    means <- rep(0, nv)\n",
    "    sds <- diag(rep(1, nv))\n",
    "    corm <- matrix(corx, nrow = nv, ncol = nv)\n",
    "    diag(corm) <- rep(1, nv)\n",
    "    covr <- sds %*% corm %*% sds\n",
    "    set.seed(5)\n",
    "    samp_iidx <- mvrnorm(nsamp, means, covr)\n",
    "    rowMeans(qexp(pnorm(samp_iidx)))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ba6220-cf33-4f9d-af1a-d21ebf5b87af",
   "metadata": {},
   "source": [
    "Than initiate a data.table with different correlation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75564ca3-ffe7-4976-bfca-87a1212ab571",
   "metadata": {},
   "outputs": [],
   "source": [
    "clt_sim <- data.table(corx = seq(0, 1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd04237c-9dc8-4ed0-ad33-5a0fef28a6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clt_sim2 <- clt_sim[, .(sampm = clt_exp(corx)), by = corx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70121998-2617-454e-85b2-5ecb65b67fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_clt <- clt_sim2 %>%\n",
    "plot_ly(x = ~sampm) %>%\n",
    "layout(yaxis = list(range = c(0, 100))) %>%\n",
    "add_trace(frame = ~corx, type = \"histogram\", nbinsx = 100) %>%\n",
    "animation_opts(\n",
    "    frame = 500, redraw = T, easing = \"linear\", mode = \"next\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5811d8f3-184b-4151-9fde-436bbe550c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_clt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf75eff-6940-49a1-be37-1e1888e8ca0b",
   "metadata": {},
   "source": [
    "We see that, at lower correlation levels, the variables become independent so the sample means converge to normal distribution.\n",
    "\n",
    "As the correlation among variables increase, the distribution of sample means converge closer to exponential distribution.\n",
    "\n",
    "So in order for the CLT to hold, the independence assumption is required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0827e097-3d62-4a52-971a-4cae367fbe80",
   "metadata": {},
   "source": [
    "### CLT and Information Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31de2787-7d52-48c3-899f-602ef3dda472",
   "metadata": {},
   "source": [
    "These simulations show **HOW** sample means converge to normal distribution.\n",
    "\n",
    "In order to understand the **WHY** of that convergence without messing with rigorous proofs, we have to visit the concept of **entropy** in an information theoretic sense later on.\n",
    "\n",
    "For now, shortly we can say that, means of large samples drawn from informative distributions become less informative of the original distribution. So the resulting distribution of sample means is the least informative one, that means the distribution that we can assume with the least information we have, the mean and the standard deviation of the original population. We will understand that informativeness when we discuss entropy.\n",
    "\n",
    "Think about it: Individuals may have quite unique voices when they shout or scream:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13283925-ec6a-4866-b4ca-b9de51256437",
   "metadata": {},
   "source": [
    "[![screams](https://img.youtube.com/vi/jFpkNtg731A/0.jpg)](https://www.youtube.com/watch?v=jFpkNtg731A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b74061-e0f0-43eb-963b-eb038a82aad7",
   "metadata": {},
   "source": [
    "But the crowd roars lose that information about the uniqueness of the voices of their individuals: Almost all crowd roars and cheers are similar:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae55749-382c-4f35-8c5c-39e6db2f7621",
   "metadata": {},
   "source": [
    "[![roars](https://img.youtube.com/vi/p4BrdRnbw1I/0.jpg)](https://www.youtube.com/watch?v=p4BrdRnbw1I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376a1e67-703b-427a-a3f9-db2ab370d668",
   "metadata": {},
   "source": [
    "We will combine **maximum entropy principal** that we will learn later with **central limit theorem**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a086b6-31ec-4996-80ac-d94e028e4d08",
   "metadata": {},
   "source": [
    "## Z-Score and Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42207c6-887c-43ff-9f26-6b548e0deee5",
   "metadata": {},
   "source": [
    "Let's recall the formula for the PDF of normal distribution that creates the famous bell shape.\n",
    "\n",
    "The <span style=\"font-weight:bold;color:blue;\">blue</span> part centers and scales $x$ so that we always get a similar curve, centered on 0 and with the same width:\n",
    "\n",
    "$${\\huge\n",
    "{\\bf\n",
    "{\n",
    "\\color{red}\n",
    "{\n",
    "\\frac\n",
    "{1}{\\sqrt {2\\pi \\sigma ^{2}}\n",
    "}\n",
    "}}e^\n",
    "{\n",
    "\\color{blue}\n",
    "{\n",
    "{-{\\frac {(x-\\mu )^{2}}{2\\sigma ^{2}}\n",
    "}\n",
    "}\n",
    "}\n",
    "}\n",
    "}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f36f15-74c9-4b34-bab4-0ed8fd61cc9e",
   "metadata": {},
   "source": [
    "Without standardization, all variables may have different locations ($\\mu$) and scales ($\\sigma$):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8131fe-c50a-45c6-ad46-529a22cfe6de",
   "metadata": {},
   "source": [
    "Let's create a multivariate sample again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5123276-080e-4091-b1ac-c6cbc806cdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(3)\n",
    "means <- rnorm(nv, 0, 2)\n",
    "set.seed(1)\n",
    "sds <- diag(rexp(nv, 1/2))\n",
    "corm <- diag(rep(1, nv))\n",
    "covr <- sds %*% corm %*% sds\n",
    "samp_iid <- mvrnorm(1e3, means, covr)\n",
    "samp_iid <- as.data.table(samp_iid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39d11ee-127a-4dae-9a8e-78da63b1f35d",
   "metadata": {},
   "source": [
    "See that the locations and scales are quite different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e54e5ad-3299-489c-8b77-68db45a5b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_iid %>%\n",
    "pivot_longer(everything()) %>%\n",
    "ggplot(aes(x = value, color = name)) +\n",
    "geom_density(adjust = 2) +\n",
    "guides(color =\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bceeb9-e0b3-454b-8372-3841fddabb89",
   "metadata": {},
   "source": [
    "The Z-score centers the variable by subtracting the mean, so the mean is 0 and rescales by dividing by the standard deviation so that the resulting standardized version has a standard deviation of 1:\n",
    "\n",
    "$\\huge {\\frac {x- \\mu}{\\sigma}}$\n",
    "\n",
    "The standardized variable is called the Z-score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c874cc7-5e9c-43af-9f8c-7e11d8687297",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_iid %>%\n",
    "mutate_all(normalize) %>%\n",
    "pivot_longer(everything()) %>%\n",
    "ggplot(aes(x = value, color = name)) +\n",
    "geom_density(adjust = 2) +\n",
    "guides(color =\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bc17c5-3e57-4c65-a0b8-0dc8a4f71f03",
   "metadata": {},
   "source": [
    "## Shape of My Normal PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b654fa4-ccf5-45e6-98cf-f54c1b9f0454",
   "metadata": {},
   "source": [
    "A great movie and the debut of Natalie Portman, Léon: The Professional by Luc Besson, ends with **Shape of My Heart** by Sting:\n",
    "\n",
    "[![roars](https://img.youtube.com/vi/DOZCqVLK6JU/0.jpg)](https://www.youtube.com/watch?v=DOZCqVLK6JU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d583da-675e-4f62-aacf-090a414fc647",
   "metadata": {},
   "source": [
    "That might inspire us to explore the shape of our famous bell curve:\n",
    "\n",
    "In a tandem plot of PDF and CDF of standard normal distribution, we can track where the Z scores correspond to cumulative probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d69a37-0d5f-4f55-9b30-68b174198430",
   "metadata": {},
   "outputs": [],
   "source": [
    "qvals1 <- seq(-4, 4, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3053f22-d609-4f16-b830-8a5ad6380c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 <- plot_ly(x = qvals1, y = round(dnorm(qvals1), 3), type = \"scatter\", mode = \"lines\") %>%\n",
    "  layout(\n",
    "    xaxis = list(\n",
    "      showspikes = TRUE, \n",
    "      spikemode = \"across\", \n",
    "      spikesnap = \"cursor\", \n",
    "      spikethickness = 1.5,\n",
    "      spikecolor = \"red\"\n",
    "    ),\n",
    "    yaxis = list(showspikes = FALSE)\n",
    "  )\n",
    "\n",
    "p2 <- plot_ly(x = qvals1, y = round(pnorm(qvals1), 3), type = \"scatter\", mode = \"lines\") %>%\n",
    "  layout(\n",
    "    xaxis = list(\n",
    "      showspikes = TRUE, \n",
    "      spikemode = \"across\", \n",
    "      spikesnap = \"cursor\", \n",
    "      spikethickness = 1.5,\n",
    "      spikecolor = \"red\"\n",
    "    ),\n",
    "    yaxis = list(showspikes = FALSE)\n",
    "  )\n",
    "\n",
    "subplot(p1, p2, nrows = 2, shareX = TRUE) %>%\n",
    "  layout(\n",
    "      title = \"Standard Normal Distribution\",\n",
    "    hovermode = \"x unified\",\n",
    "      annotations = list(\n",
    " list(y = 0.9, text = \"Probability Density Function\", showarrow = F, xref='paper', yref='paper'),\n",
    "  list(y = 0.3, text = \"Cumulative Distribution Function\", showarrow = F, xref='paper', yref='paper'))\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9680b9a-38c3-4d08-9e75-c026e8ab49a1",
   "metadata": {},
   "source": [
    "We see that the cumulative probability of -1 z-score is 15.9%. That means, probability that the z-score falls within 1 standard deviation of the mean of 0 is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce458bb-e7a7-4e21-8158-c499b4be1658",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(pnorm(1) - pnorm(-1), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35515cc-711d-431e-b5d0-5265872dcde1",
   "metadata": {},
   "source": [
    "We can repeat the same calculation for 2 and 3 standard deviations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bb7374-065c-478b-aaaa-38ed7a747833",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(pnorm(1:3) - pnorm(-(1:3)), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcdf74b-ce93-48b3-9554-8fcb209a9c5e",
   "metadata": {},
   "source": [
    "Which yields the famous 68-95-99.7 rule.\n",
    "\n",
    "(https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859207b4-2afa-4fd2-b37c-980861c92fb9",
   "metadata": {},
   "source": [
    "So we can say almost everyone stands within 3 standard deviations of the mean.\n",
    "\n",
    "What do you mean \"everyone\"?\n",
    "\n",
    "[![everyone](https://img.youtube.com/vi/zTFt5wxx3g8/0.jpg)](https://www.youtube.com/watch?v=zTFt5wxx3g8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87636ff9-1d2b-4117-a375-c9ded3774e8d",
   "metadata": {},
   "source": [
    "**Trivia:** Great actor Gary Oldman, who portrays a psychopatic DEA agent passionate with Beethoven's works here in Léon, also played the role of Ludwig van Beethoven in Immortal Beloved the same year in 1994!\n",
    "\n",
    "\n",
    "[![everyone](https://img.youtube.com/vi/7qWbcosJdtU/0.jpg)](https://youtu.be/7qWbcosJdtU?t=396)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85248fc-0202-4e09-b6eb-cbf1f5e6064c",
   "metadata": {},
   "source": [
    "## Normal Distribution Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6f9796-c96b-4697-acfe-bd8fb77e7145",
   "metadata": {},
   "source": [
    "Now let's cover the four friend functions of normal distribution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32305129-c6fc-45d9-8304-1b03a5dc6e26",
   "metadata": {},
   "source": [
    "Sample from standard normal distribution with `rnorm`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1c63ee-05c6-4882-9264-6a72a9153b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsamp <- rnorm(1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1fc72-1660-4a56-b4c4-eeca5f677430",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(rsamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5c3b75-c036-4857-83e5-91b7cf2e10d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(density(rsamp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91e988c-aebf-4c9b-911f-4a62bd131a34",
   "metadata": {},
   "source": [
    "Now let's create p values between 0 and 1 but leaving small tails (so that we don't have $-\\infty$ or $\\infty$ for quantile values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57d725b-692b-4f16-ba94-a24bd50d9b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseq <- seq(0.001, 1 - 0.001, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc60a84-0176-45a8-ad43-d1395977dd2a",
   "metadata": {},
   "source": [
    "The quantile values - values of the random variable - that correspond to the given p-values - or cumulative probabilities from the left tail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09ce5b7-68a7-4f00-80f1-40f93b76a099",
   "metadata": {},
   "outputs": [],
   "source": [
    "qseq <- qnorm(pseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c049b834-c4bc-4911-8e70-65c01de26170",
   "metadata": {},
   "source": [
    "The p-values across quantiles form the cumulative distribution function CDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44c1739-b2c9-49fc-bf7b-906675219f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(qseq, pseq, type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b789661-43a4-4fd6-803f-a334ce0d2860",
   "metadata": {},
   "source": [
    "Now let's do the inverse, and get the p-values that correspond to the quantiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d77b94c-11d9-4305-8282-c0550919adb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseq2 <- pnorm(qseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e77fcd-0865-452e-ab53-4951d9074d01",
   "metadata": {},
   "source": [
    "And compare the calculated p-values and the p-values that we supplied at the beginning, see that they are equal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df48c2b1-9025-4683-93a5-13af6389480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(pseq, pseq2, type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9095a475-d7be-49a6-a631-3a0bdeb6d69d",
   "metadata": {},
   "source": [
    "Now let's get the densities - the instant rate of change in CDF - corresponding to quantile values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d521baf8-fbdf-4d2f-9be7-4b738a458801",
   "metadata": {},
   "outputs": [],
   "source": [
    "dseq <- dnorm(qseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41544bcb-956b-421b-98c2-643dc1b68a13",
   "metadata": {},
   "source": [
    "Plot of densities across quantile values form the probability density function PDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1156f7-d710-438b-9320-19c60a649cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(qseq, dseq, type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c68c5e-00ba-4ec1-856b-614fcb0a9daa",
   "metadata": {},
   "source": [
    "## Resources on Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b38ac2-9e05-4ee8-883c-9a200538b7d7",
   "metadata": {},
   "source": [
    "Normal distribution is more than just some fancy mathematical function creating a certain bell shape. It is a natural outcome of the naive forces of nature and that's why normal distribution is so ubiquitous in statistics and in many aspects of the world.\n",
    "\n",
    "Some suggested further non-technical and semi-technical reading can be found below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4431d080-de71-43cf-98d1-3df24cdc703b",
   "metadata": {},
   "source": [
    "- Chapter 3 \"Adolphe Quetelet's Bell Curve Bridge\" from \"Bernoulli's Fallacy\" by Clayton (2021), is an excellent account on the history of and the reasoning behind the development of normal distribution\n",
    "\n",
    "- Chapter 7 \"The central, Gaussian or normal distribution\" from \"Probability Theory: The Logic of Science\" by Jaynes (2003) includes some great ideas behind normal distribution's ubiquity also borrowing ideas from information theory and entropy, especially in section 7.6 \"Why the ubiquitous use of Gaussian distributions?\" and section 7.7 \"Why the ubiquitous success?\". The chapter also includes some rigorous proof that you can skip.\n",
    "\n",
    "- The paper titled \"The Evolution of the Normal Distribution\" by Stahl (2006) is a detailed and accessible account on the history of the mathematical derivation of the normal distribution.\n",
    "\n",
    "- Page 76 from \"Statistical Rethinking: A Bayesian Course with Examples in R and Stan\" by McElreath (2020) provides some concise information to demistify the monstrous formulation of normal PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2b1aa1-b106-4f96-816e-4ab30b5f613e",
   "metadata": {},
   "source": [
    "# Cauchy Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92fbf7c-a217-47b1-b234-d8d030d6ebcc",
   "metadata": {},
   "source": [
    "Up to now we covered \"well-behaved\" discrete and continuous probability distribution which all had finite means and variances.\n",
    "\n",
    "Now let's cover an \"ill-behaved\" or pathological distribution type which we will revisit in Student's t distribution: The Cauchy distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6b72d5-13d1-48e4-9b3e-65a992397f8e",
   "metadata": {},
   "source": [
    "Suppose that we are in front of an infinite length wall 1 meters away and we are continually shooting balls to the wall:\n",
    "\n",
    "\n",
    "[![federer](https://img.youtube.com/vi/8BdHP6FWxKU/0.jpg)](https://www.youtube.com/watch?v=8BdHP6FWxKU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c40401d-e672-4573-ba08-4b15c33199f4",
   "metadata": {},
   "source": [
    "Of course we won't be as accurate as Roger Federer. Suppose there is a semi circle in front us and between the wall and us, and before every shoot we are selecting a random point on the semi circle uniformly, so the angle is uniformly distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f0cb65-c37d-466a-baef-a341197d3ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xval <- seq(-1, 1, 0.01)\n",
    "yvals <- sqrt(1 - xval^2)\n",
    "\n",
    "plot(xval, yvals, type = \"l\", xlim = c(-1, 1), ylim = c(0, 1))\n",
    "abl <- lapply(seq(0, 1, length.out = 9), function(x) abline(a = 0, tan(pi * (x - 1/2)), col = x * 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a5f84f-dd00-4106-9b97-9118482aa7f0",
   "metadata": {},
   "source": [
    "Each ray from the origin is the trajectory of a shoot. The distance of the point that the ball hits the wall to the origin follows a Cauchy distribution. As you may see, as the angle approaches 0 or $\\pi$, the distance also approaches $-\\infty$ or $\\infty$.\n",
    "\n",
    "The x intercept can be calculated by tangent function:\n",
    "\n",
    "${\\displaystyle x=\\tan \\left(\\pi (u-{\\tfrac {1}{2}})\\right)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9353db-a003-4cf3-b0c9-657d7ea16286",
   "metadata": {},
   "source": [
    "Let's draw a sample following this definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2f5d8d-ea05-4394-b01d-6aa4a49449c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(10)\n",
    "hist(tan(pi*(runif(1e3) - 1/2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f023108-30e1-46d6-856b-606b7e5eda89",
   "metadata": {},
   "source": [
    "Another definition of a Cauchy distribution is the ratio of two standard normally distributed variables with mean 0 and variance 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4007af1b-a6c9-474f-a11a-ff8e649daeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(20)\n",
    "hist(rnorm(1e3) / rnorm(1e3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680f119b-764a-4ac3-ae30-b893a446bc2c",
   "metadata": {},
   "source": [
    "Or we can sample using `rcauchy` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05900d7c-e19f-4e48-99d1-ad1a0b9c559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(40)\n",
    "hist(rcauchy(1e3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b93e14-aec0-468d-9c49-44c370b6fc0d",
   "metadata": {},
   "source": [
    "Now to see the main difference between Cauchy and normal distributions, let's first make 10 random simulations from normal distributions and draw their histograms sequentially in an animated plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28d513d-607e-4370-947a-df0e1fbb8422",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(50)\n",
    "rruns <- data.table(runs = 1:10)\n",
    "rruns2 <- rruns[, .(samplx = {rnorm(1e4)}), by = runs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41af09d1-e1b2-4fcf-b081-b0e20a9320e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rruns2 %>%\n",
    "plot_ly(x = ~samplx) %>%\n",
    "add_trace(frame = ~runs, type = \"histogram\") %>%\n",
    "animation_opts(\n",
    "    frame = 500, redraw = T, easing = \"linear\", mode = \"next\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298e7683-2c9a-466b-8244-b1af4ee2711e",
   "metadata": {},
   "source": [
    "Across runs overall location and scale. of the distribution does not change much"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd248961-14e6-4dfb-ae88-935344a6066f",
   "metadata": {},
   "source": [
    "Now let's draw 10 large samples from Cauchy distribution and animate the histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4895226-24fc-4206-91aa-22b6a612a61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(60)\n",
    "cruns <- data.table(runs = 1:10)\n",
    "cruns2 <- rruns[, .(samplx = {rcauchy(1e4)}), by = runs] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88b7ac3-5386-4020-abb1-b9046751b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "cplot <- cruns2 %>%\n",
    "plot_ly(x = ~samplx) %>%\n",
    "add_trace(frame = ~runs, type = \"histogram\", nbinsx = 500) %>%\n",
    "animation_opts(\n",
    "    frame = 1000, redraw = T, easing = \"cubic\", mode = \"next\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3269b5d-66c3-4872-8b3d-bec69e38a6b1",
   "metadata": {},
   "source": [
    "We have to rescale the x axis across frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e946b349-ff94-4346-9e23-6fbd4acbc941",
   "metadata": {},
   "outputs": [],
   "source": [
    "cplot2 <- plotly_build(cplot)\n",
    "cranges <- lapply(split(cruns2$samplx, cruns2$runs), range)\n",
    "for (i in 1:10) cplot2$x$frames[[i]]$layout <- list(xaxis = list(range = cranges[[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05b094b-a612-4926-8505-730e1724bea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cplot2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af20cbe2-6940-481e-98f0-5f0a6f9c97a0",
   "metadata": {},
   "source": [
    "You can see that across frames the location and scale of the distribution changes vastly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a98dbae-715a-49fd-9294-b472b4c7884e",
   "metadata": {},
   "source": [
    "Now again let's conduct random simulations and tabulate the summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edb0d96-109e-4567-bd84-a800dc1e676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(70)\n",
    "cauchyruns <- lapply(1:10,\n",
    "                     function(x) { samp <- rcauchy(1e5); c(summary(samp), Var = var(samp)) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e446c0c-f3df-4fb0-8c29-80560ec32d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(80)\n",
    "normruns <- lapply(1:10,\n",
    "                     function(x) { samp <- rnorm(1e5); c(summary(samp), Var = var(samp)) })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60101a8f-d379-439e-b2b5-90fe724b174c",
   "metadata": {},
   "source": [
    "See that, across runs, the mean and five point summaries and the variances are all very similar for normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170ddc0c-0750-49b7-b341-75f88c9287b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "normruns %>% lapply(as.list) %>% rbindlist %>% round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa5ff9d-649d-49d3-b92e-0a5b04db18a3",
   "metadata": {},
   "source": [
    "However for Cauchy distribution, the mean and variance changes extensively across runs while median is always at the center:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e336d2-f473-4d23-9cc9-70d615702703",
   "metadata": {},
   "outputs": [],
   "source": [
    "cauchyruns %>% lapply(as.list) %>% rbindlist %>% round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534b62eb-fc97-424c-a2ab-cf048cb06660",
   "metadata": {},
   "outputs": [],
   "source": [
    "stepx <- 0.05\n",
    "pvals <- seq(stepx, 1 - stepx, stepx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9d050c-92a4-45bc-9cf0-648ef8338a23",
   "metadata": {},
   "source": [
    "Now let's get quantiles for 5% cumulative probability steps of normal and Cauchy distributions and plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bee4d7-5d92-4980-90b7-b97651c05050",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(pvals, qnorm(pvals) %>% round(2), type = \"l\", col = \"blue\", ylim = range(qcauchy(seq(stepx, 1 - stepx, stepx))))\n",
    "lines(pvals, qcauchy(seq(stepx, 1 - stepx, stepx)) %>% round(2), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24d1f29-ef3f-40e5-8965-7009f6cb3c95",
   "metadata": {},
   "source": [
    "You can see the dispersion of quantiles are far wider for the Cauchy distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304424c4-de60-4ebe-a63f-026263c3bc13",
   "metadata": {},
   "source": [
    "## Law of Large Number with Cauchy Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7639dc5-0faf-4d01-aba0-8c1816b2ec32",
   "metadata": {},
   "source": [
    "As we may recall, the mean of a sample converges to the mean of the population as the sample size grows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e3f508-0584-42f4-b35a-fdd24862cd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(100)\n",
    "plot(cummean(rnorm(1e5)), type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9276f6-5d51-4a0d-b894-895c9e72c6a4",
   "metadata": {},
   "source": [
    "For a Cauchy distribution, law of large numbers does not apply: The mean of the sample does not converge to a certain value as the sample size grows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1732d000-635b-458c-91a7-50d551a4b01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(0)\n",
    "plot(cummean(rcauchy(1e5)), type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1581bf35-03f9-4476-9b45-1c9f43483199",
   "metadata": {},
   "source": [
    "## CLT with Cauchy Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0032b0-7368-422c-9b54-61770bd82899",
   "metadata": {},
   "source": [
    "Now let's check whether means of samples drawn from a Cauchy distribution converges to normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1737cbc-e847-4463-bae7-de14db6b0180",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampx <- rcauchy(1e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38104542-aecc-47b5-8b08-b98816273cdf",
   "metadata": {},
   "source": [
    "The population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75568dd-0422-45e1-9909-aeb11fb06b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(sampx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f006ea29-cf16-4c0c-8f76-d576c254d365",
   "metadata": {},
   "source": [
    "Means of 1e4 samples of size 100 each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cb5476-a172-4523-8853-e69c9de79666",
   "metadata": {},
   "outputs": [],
   "source": [
    "simx <- rowMeans(t(replicate(1e4, sample(sampx, 100))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a53632f-0664-435f-ba7d-7bc0c8cafcb9",
   "metadata": {},
   "source": [
    "Still a Cauchy distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710cbf31-1577-4588-b5c4-51c031eb6ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5083cec-f47f-4236-a4b0-ee2529bb7811",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(c(summary(sampx), Var = var(sampx)),\n",
    "     c(summary(simx), Var = var(simx))) %>%\n",
    "lapply(as.list) %>% rbindlist %>% round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0122bd-d0ac-4156-951e-530f6e61978b",
   "metadata": {},
   "source": [
    "So the rule about having finite variance is a prerequisite for central limit theorem: The means of the samples from a Cauchy distribution, do not converge to normal distribution but still conforms with a Cauchy distribution.\n",
    "\n",
    "We will see Cauchy distribution as a special case of Student's t distribution later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42339c7f-1b4c-4ad1-93ca-d1c5085ccd2a",
   "metadata": {},
   "source": [
    "# Chi-squared Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c814fc1-5e48-4ce7-ba18-b0a658b60bf8",
   "metadata": {},
   "source": [
    "Until now, we talked about the distribution of sample means to discuss square root law and central limit theorem.\n",
    "\n",
    "We know that, for i.i.d variables with finite variances, the sample means converge to normal distribution.\n",
    "\n",
    "But what about the scales - as measured by sum of squared deviations, variance of standard deviation - of those samples?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2af495f-b9ec-4d70-b4f3-a712b5ca7a71",
   "metadata": {},
   "source": [
    "Let's first create a large sample from the population following a standard normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b0190-6123-40cb-af2c-b4d07eb842e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "popnorm <- rnorm(1e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999f777f-3785-4e62-83e8-6e7f121ec209",
   "metadata": {},
   "source": [
    "We know that the normal distribution is bell shaped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfcf757-d477-409a-8a52-4a9bfe2f682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(popnorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de42a52-7e29-4688-ac24-c96e7df49977",
   "metadata": {},
   "source": [
    "However, the squared values follow an almost - but not exactly - exponential shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a87fdd-ea82-4730-96b8-03d661601bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(popnorm^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd320ef8-f899-4992-9f14-b7b66d0d8a47",
   "metadata": {},
   "source": [
    "Set the total number of samples and the size of each sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f9434d-918b-456f-a4e9-f222b19513ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamp <- 1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1a0db3-89d7-49a8-8414-c5a2e02a5407",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizet <- 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a4f39d-730e-44a8-afe2-7dbaa47b7bbd",
   "metadata": {},
   "source": [
    "Now create smaller samples from the same population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596ca1ef-f814-4d38-86b5-342f14c252ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(10)\n",
    "sampt <- t(replicate(nsamp, rnorm(sizet)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e59e5c-d98c-42b9-bef3-05e791796466",
   "metadata": {},
   "source": [
    "Get the sum of squares for each sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d89917-7c97-4908-bf89-28f1204f7a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sumsq <- rowSums(sampt^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d166d5-579f-4e5d-b9e9-b123cc44b04f",
   "metadata": {},
   "source": [
    "And view the histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1389b3b1-8527-43ba-a1f4-e7c2261ecd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(sumsq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafddf81-3f7e-465e-b9f6-a184e2eddb94",
   "metadata": {},
   "source": [
    "Now let's draw samples from Chi-Squared distribution with $k$ degrees of freedom - as the name of the parameter goes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebada153-02fc-4f2d-8483-f53bad98e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(11)\n",
    "hist(rchisq(1e4, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2393a4a9-17b9-492d-ab47-eec21f754f77",
   "metadata": {},
   "source": [
    "And let's see whether they follow a similar PDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983301ac-bf84-4a15-a56f-30898595c655",
   "metadata": {},
   "outputs": [],
   "source": [
    "densx <- density(sumsq)[c(\"x\", \"y\")]\n",
    "maxx <- max(sumsq)\n",
    "setDT(densx)\n",
    "xvals <- seq(0, maxx, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7ae60a-d89a-47fb-aeef-d5d5e72b1f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(densx[x > 0], type = \"l\", col = \"blue\")\n",
    "lines(xvals, dchisq(xvals, sizet), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316f5edf-86f2-4845-a689-b9973ca888b6",
   "metadata": {},
   "source": [
    "We see that the sum of squares of the 10 sized samples that we created and Chi-squared distribution with 10 degrees of freedom have the same densities.\n",
    "\n",
    "the  ${\\displaystyle \\chi ^{2}}$-distribution (or *Chi-squared* distribution) with ${\\displaystyle k}$ degrees of freedom is the distribution of a sum of the squares of ${\\displaystyle k}$ independent standard normal random variables.\n",
    "\n",
    "The chi-squared distribution ${\\displaystyle \\chi _{k}^{2}}$ is a special case of the gamma distribution. Specifically if ${\\displaystyle X\\sim \\chi _{k}^{2}}$ then ${\\displaystyle X\\sim {\\text{Gamma}}(\\alpha ={\\frac {k}{2}},\\theta =2)}$ (where ${\\displaystyle \\alpha }$ is the shape parameter and ${\\displaystyle \\theta }$ the scale parameter of the gamma distribution.\n",
    "\n",
    "Let's confirm that with simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522b64ce-8447-468c-bc0c-aaf257fb1e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(rgamma(1e4, sizet/2, 1/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7420f665-eb8b-4da1-a5ed-f4023939013e",
   "metadata": {},
   "source": [
    "And densities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fb6c78-9ca0-4f58-a782-cb8f04a8bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(densx[x > 0], type = \"l\", col = \"blue\")\n",
    "lines(xvals, dchisq(xvals, sizet), col = \"red\")\n",
    "lines(xvals, dgamma(xvals, sizet/2, 1/2), col = \"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccd0322-7235-41ea-a608-20d98adb4715",
   "metadata": {},
   "source": [
    "The expected value of $\\chi^2$-distribution is $k$ while variance is $2k$. Let's check..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861b1c55-9af0-4c52-a8af-7423afd409ae",
   "metadata": {},
   "source": [
    "Theoretical statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc27fa17-c655-425c-bed1-5aac083e8f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "distx <- Chisq(sizet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5854b5ac-2472-4e12-a946-fd5de57c1443",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(distx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d9a57b-3a2c-4f5e-a17f-01889a396bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(distx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0f6812-c5d4-4045-b235-19ccee2a03ed",
   "metadata": {},
   "source": [
    "And the empirical statistics from our samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f85b4a-e925-460f-853d-da904218d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(sumsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2079137-dba2-4caa-b8f5-1be5f7cffb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(sumsq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f47d0b-91e8-4edc-b7d1-c7cee6c3b844",
   "metadata": {},
   "source": [
    "$\\chi^2$-distribution is closely related to Student's t distribution - the topic of next section - and also a part of $\\chi^2$ test for goodness of fit of observed data to hypothetical distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c059d05-ab15-40fd-b3bc-d30bc44782da",
   "metadata": {},
   "source": [
    "# Student's t Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db00ae24-ff50-4845-83df-222466e7f788",
   "metadata": {},
   "source": [
    "Now let's create a large sample and smaller samples again.\n",
    "\n",
    "Suppose we have a sample from the population, the mean and standard deviation of which we don't know, and we want to test whether that sample is from the hypothesized population (a topic which we will see later)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d34b7c-2434-4738-a552-c81e46dd407b",
   "metadata": {},
   "source": [
    "Let's first create a large sample from the population following a standard normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cc44f4-4ffb-45ef-83ae-dec059fd766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "popnorm <- rnorm(1e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c602bc98-167f-432b-bfba-784a4c0f3f00",
   "metadata": {},
   "source": [
    "Again create smaller samples from the same population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2b946e-4beb-46a6-8579-99b26acb6046",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamp <- 1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf5db37-9e8a-4441-82aa-b4e46b0f6ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizet <- 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df69b4-ff3c-4fd4-b578-07f0b4f9a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(10)\n",
    "sampt <- t(replicate(nsamp, rnorm(sizet)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6259a84d-2c50-4261-9581-ef16a2bf81fe",
   "metadata": {},
   "source": [
    "Let's calculate the means of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4821a6-3aaf-4afa-9a59-e05fc69a946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampm <- rowMeans(sampt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e1221b-f0c7-4e80-955c-407cc85eec2b",
   "metadata": {},
   "source": [
    "Let's calculate the sd's of the samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5310f4f7-80f1-435a-8216-076bc02e1393",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampsd <- apply(sampt, 1, sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6428b824-f25e-4837-b591-b3437451735f",
   "metadata": {},
   "source": [
    "Combine them into a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dad36c1-b74d-4263-9c6a-f250af3b3c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_dt <- data.table(sampm, sampsd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6cc4e1-33f4-4ff0-99a7-f1ac9ad19678",
   "metadata": {},
   "source": [
    "And also add sum of squared deviations following the formula of sample variance:\n",
    "\n",
    "${\\displaystyle s^{2}={\\frac {1}{n-1}}\\sum _{i=1}^{n}\\left(x_{i}-{\\overline {x}}\\right)^{2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcad9dc-ce9d-42f5-96b4-4a874cdc2886",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_dt[, sampss := sampsd^2 * (sizet - 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0672a7-5c23-48d1-bbee-1fd7373b03c3",
   "metadata": {},
   "source": [
    "Now let's look at the distribution of standard deviations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfed5f23-144a-4863-a423-0bf8abccac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(samp_dt$sampsd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672e365c-8f84-41ce-90bc-e5710a3dfc91",
   "metadata": {},
   "source": [
    "Or better check distribution of sum of squared deviations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1fafc4-e280-4a44-87e1-0445c01cc7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(samp_dt$sampss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c743fc59-eb2e-492e-9916-290f5e6a41af",
   "metadata": {},
   "source": [
    "The sum of squared deviations follow a $\\chi^2$ deviation with $n - 1$ degrees of freedom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad5f440-c7da-4763-9cf7-bc3c3c2f4492",
   "metadata": {},
   "outputs": [],
   "source": [
    "densx <- density(samp_dt$sampss)[c(\"x\", \"y\")]\n",
    "maxx <- max(samp_dt$sampss)\n",
    "setDT(densx)\n",
    "xvals <- seq(0, maxx, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a4a8c2-95d8-47f2-aab9-20bc4a56db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(densx[x >= 0], type = \"l\", col = \"blue\")\n",
    "lines(xvals, dchisq(xvals, sizet - 1), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3603fcba-f872-4106-b483-652a25b12978",
   "metadata": {},
   "source": [
    "Note that the densities overlap, we confirm the theoretical distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f556d197-2591-40bb-b045-05b2aa12adea",
   "metadata": {},
   "source": [
    "Now let's view the distribution of sample means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fc99c5-90e8-4919-bf4a-7e6d5d11a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(samp_dt$sampm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70739b76-3ab3-4758-b2ce-e24e45f9da8a",
   "metadata": {},
   "source": [
    "In line with square root law, the sd of the sample means is $\\displaystyle s = \\frac {\\sigma}{\\sqrt{k}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33e3d7e-e252-4a8c-98af-7977cdc3891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / sqrt(sizet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1f18d7-4c10-4479-9ee8-61f7e557da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(samp_dt$sampm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433fc450-8a6c-416d-8771-284c36b05aec",
   "metadata": {},
   "source": [
    "Note that, the sample means are:\n",
    "\n",
    "${\\displaystyle {\\overline {X}}_{n}={\\frac {1}{n}}(X_{1}+\\cdots +X_{n})}$\n",
    "\n",
    "And sample variances are:\n",
    "\n",
    "${\\displaystyle s^{2}={\\frac {1}{n-1}}\\sum _{i=1}^{n}\\left(X_{i}-{\\overline {X}}_{n}\\right)^{2}}$\n",
    "\n",
    "The standardized sum of squares:\n",
    "\n",
    "${\\displaystyle V=(n-1){\\frac {s^{2}}{\\sigma ^{2}}}}$\n",
    "\n",
    "has a chi-squared distribution with ${\\displaystyle \\nu =n-1}$ degrees of freedom as we have shown above.\n",
    "\n",
    "${\\displaystyle Z=\\left({\\overline {X}}_{n}-\\mu \\right){\\frac {\\sqrt {n}}{\\sigma }}}$\n",
    "\n",
    "is normally distributed with mean 0 and variance 1, since the sample mean ${\\displaystyle {\\overline {X}}_{n}}$ is normally distributed with mean μ and variance $\\displaystyle \\frac {\\sigma^2}{n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d35ab8-183d-46f8-bfe3-1e2d1a6b4638",
   "metadata": {},
   "source": [
    "Let's calculate the Z values using this formula (note that population standard deviation $\\sigma$ is 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5056f722-12ba-4cf1-885e-ed93ac7b0906",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_dt[, sampz := sampm * sqrt(sizet)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ce3399-7a87-47fc-a91b-86d4561064e4",
   "metadata": {},
   "source": [
    "And see the histogram of Z values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5470886-f3ae-459c-9ee2-11d06641dc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(samp_dt$sampz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d203c011-06b8-453d-9720-5f0d1e5fe3aa",
   "metadata": {},
   "source": [
    "They have a mean of around 0 and variance of 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ea5942-9077-43df-83e8-36c81ca15f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(samp_dt$sampz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dda598-9bc5-4173-ba4e-2d4fe940e040",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(samp_dt$sampz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f66785-6943-486e-9b9b-adb285685937",
   "metadata": {},
   "source": [
    "Let's see the densities of Z values and compare with normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33590dfa-ddc2-41c6-b1b9-ccf466f53bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "densx <- density(samp_dt$sampz)[c(\"x\", \"y\")]\n",
    "maxx <- max(abs(range(samp_dt$sampss)))\n",
    "setDT(densx)\n",
    "xvals <- seq(-maxx, maxx, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8868e347-087f-4a4f-ab53-7d41168148e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(densx, type = \"l\", col = \"blue\")\n",
    "lines(xvals, dnorm(xvals, 0, 1), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdf1fa6-9f5a-4f7f-9091-49d67a76eceb",
   "metadata": {},
   "source": [
    "Z values are normally distributed, as suggested in above formulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a80de0-4ee3-40f0-a832-070a590b45bc",
   "metadata": {},
   "source": [
    "Now suppose from the sample means and standard deviations we want to extract the standardized scores:\n",
    "\n",
    "${\\displaystyle T={\\frac {Z}{\\sqrt {V/\\nu }}}=Z{\\sqrt {\\frac {\\nu }{V}}}}$\n",
    "\n",
    "where\n",
    "\n",
    "- Z is a standard normal with expected value 0 and variance 1;\n",
    "- V has a chi-squared distribution (χ2-distribution) with ${\\displaystyle \\nu }$ degrees of freedom;\n",
    "- Z and V are independent;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7ab2cb-b7b0-41e5-9900-93a16a307d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_dt[, .(sampz, sampss)] %>% cor %>% round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb56ab63-3f66-4506-af4e-7fec57ef948a",
   "metadata": {},
   "source": [
    "The statistic can also be rearranged such that:\n",
    "\n",
    "${\\displaystyle T\\equiv {\\frac {Z}{\\sqrt {V/\\nu }}}=\\left({\\overline {X}}_{n}-\\mu \\right){\\frac {\\sqrt {n}}{s}}}$\n",
    "\n",
    "Notice that the unknown population variance σ2 does not appear in T, since it was in both the numerator and the denominator, so it canceled. \n",
    "\n",
    "This is the distribution of t-statistic to conduct Student's t-test of whether the mean of a population has a value specified in a null hypothesis, as we will see later in hypothesis testing.\n",
    "\n",
    "Now let's calculate this t-statistics and understand its distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ee81fb-ab3b-4ad9-8d37-273bf58bfb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_dt[, sampt := sampm / sampsd * sqrt(sizet)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2240869e-b77b-4b23-81ee-17693799425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(samp_dt$sampt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afb89c8-a362-4571-b0f2-ded0c3259f89",
   "metadata": {},
   "source": [
    "It looks closer to Cauchy distribution than to normal distribution. Check the kurtosis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739518ea-d448-4571-88ff-d1f721184cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kurtosis(samp_dt$sampt) - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5962edf-aff2-458f-be5e-b5b15359a5e3",
   "metadata": {},
   "source": [
    "The distribution has a very high level of excess kurtosis, so highly leptokurtic.\n",
    "\n",
    "Now let's overlap the density with that of a normal distribution with the same standard deviation and also with that of Cauchy distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda051db-22a1-47b3-8a3a-415bb576b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "densx <- density(samp_dt$sampt)[c(\"x\", \"y\")]\n",
    "maxx <- max(abs(range(samp_dt$sampt)))\n",
    "setDT(densx)\n",
    "xvals <- seq(-maxx, maxx, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9ff846-ddc4-41a0-98d1-15c992c0775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(densx, type = \"l\", col = \"blue\")\n",
    "lines(xvals, dnorm(xvals, 0, sd(samp_dt$sampt)), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a786709c-f0ac-4dd2-8cff-22b0c7806562",
   "metadata": {},
   "source": [
    "The distribution is more peaked than normal distribution. The statistics that we derived conforms with Student's t distribution with degrees of freedom $\\nu = n - 1$.\n",
    "\n",
    "Student's t distribution (or simply the t distribution) ${\\displaystyle t_{\\nu }}$ generalizes the standard normal distribution. Like the latter, it is symmetric around zero and bell-shaped.\n",
    "\n",
    "However, ${\\displaystyle t_{\\nu }}$ has heavier tails, and the amount of probability mass in the tails is controlled by the parameter ${\\displaystyle \\nu }$.\n",
    "\n",
    "Mean is 0 for $\\nu > 1$ otherwise undefined (we will see below why it is undefined)\n",
    "\n",
    "Variance is ${\\displaystyle {\\frac {\\nu }{\\nu -2}}}$ for ${\\displaystyle \\nu >2}$, ${\\displaystyle \\infty }$ for ${\\displaystyle 1<\\nu \\leq 2}$ otherwise undefined.\n",
    "\n",
    "Student's t distribution is named after the the penname of William Sealy Gosset. Gosset was a statistician working for Guiness Brewery company in early 1900's. In order to prevent researchers from revealing trade secrets of the company, the Board of Directors decided that scientist at Guiness could publish their work on the condition that beer, Guiness or their surnames are not mentioned. So Gosset chose the penname *Student* to publish his papers.\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Student%27s_t-distribution)\n",
    "\n",
    "(https://en.wikipedia.org/wiki/William_Sealy_Gosset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fc78f9-638e-42fc-9d07-76a3c61dd82a",
   "metadata": {},
   "source": [
    "Let's try for $\\nu = 3$ and sample from the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca418ce-58f5-4d15-a676-6f3ae65e00ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124529ab-bfe1-4b5c-8422-ba3ad583adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(6)\n",
    "tsamp <- rt(1e5, sizet - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d8b97c-3872-4a87-aa32-b1ff71ad0229",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(tsamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77315f69-e89a-4750-9b1f-4da33fa8fa11",
   "metadata": {},
   "source": [
    "The empirical variance of the sample is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2def060c-326d-4056-8c22-e7d61a7cffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(tsamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41f91e2-ee33-40e6-8d4b-7de559741f5c",
   "metadata": {},
   "source": [
    "While the theoretical variance is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec66a09f-5d5e-47d0-92b6-4f21c4791361",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(Stud(sizet - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5802b27e-d20f-4654-afaf-5e313cd5f440",
   "metadata": {},
   "source": [
    "And the comparison of densities of the t-statistic values we derived from the simulation and the theoretical distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54972289-7598-4b22-aaac-5d85b266708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "densx <- density(samp_dt$sampt)[c(\"x\", \"y\")]\n",
    "maxx <- max(abs(range(samp_dt$sampt)))\n",
    "setDT(densx)\n",
    "xvals <- seq(-maxx, maxx, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f603fbe-eec0-4aa6-b620-261aeaa0d288",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(densx, type = \"l\", col = \"blue\")\n",
    "lines(xvals, dt(xvals, sizet - 1), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dc0d93-2989-4e3e-947b-c966099d773e",
   "metadata": {},
   "source": [
    "So the distribution of t statistics that we simulated obeys t distribution with $\\nu = 3$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001737e2-28ce-4d23-b9c6-801dd3318a56",
   "metadata": {},
   "source": [
    "Now let's compare the densities of Student's t distribution with different $\\nu$ parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e428746-8c72-446c-b9b7-fd3065053cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs <- c(1:10, 50, 100, 1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a1a314-deca-443e-a026-17632a4d6d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_dt <- data.table(df = dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c762a77a-41f9-4679-a1cf-bcab6a563eb0",
   "metadata": {},
   "source": [
    "For 5% cumulative p-value points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b157a852-d19e-4f94-b24c-479cf90cd7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals<- seq(0.05, 1 - 0.05, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16881da0-72f6-440b-a346-107a5c6539d3",
   "metadata": {},
   "source": [
    "Calculate the quantiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ee6261-af7c-49f9-a8f8-06b277201ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_dt2 <- st_dt[, .(pval = pvals, qvals = qt(pvals, df)), by = df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5579ef3-3271-4e0c-a693-c41d0b6d998f",
   "metadata": {},
   "source": [
    "And the densities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439e1295-9d3c-48d5-9def-ad96e063dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_dt2[, dvals := dt(qvals, df)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7b9474-9339-425a-ad6f-be4da74282ff",
   "metadata": {},
   "source": [
    "Plot the CDFs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9826216-bd22-46f9-93f1-f86e020312e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_cdf <- st_dt2 %>%\n",
    "mutate_at(\"df\", factor) %>%\n",
    "ggplot(aes(x = qvals, y = dvals, color = df)) +\n",
    "geom_line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b082f781-bf5a-4199-b4c4-e062993d26f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6921ad50-78cb-4bcd-bdec-cda25a2bac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplotly(p_cdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c837ac-2c24-40f4-be1f-3ee6b14e8bcb",
   "metadata": {},
   "source": [
    "Tails are fatter in lower df values.\n",
    "\n",
    "The theoretical excess kurtosis values start high and approach 0 by higher degrees of freedom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898c55e6-c07c-4b7a-9e62-a8291f745453",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(sapply(dfs[dfs > 5], Stud) %>% sapply(kurt), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe58ffb-4b32-483e-b27f-35c391109151",
   "metadata": {},
   "source": [
    "The pdf also confirms the tails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928ec233-4ce0-4bc2-a878-0f1a53d93c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pdf <- st_dt2 %>%\n",
    "mutate_at(\"df\", factor) %>%\n",
    "ggplot(aes(x = qvals, y = pval, color = df)) +\n",
    "geom_line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be792801-91f8-4630-ae87-0197e112521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9505efa7-5e95-476b-bf52-428b2751f739",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplotly(p_pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9dc983-fb0a-4f40-8a4f-47f214c87538",
   "metadata": {},
   "source": [
    "The pdf's of t distributions with different df values also confirm the change in shape: At lower df degrees, p-values correspond to more extreme quantile values at both tails so the tails are fatter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c605f32-6db3-4d51-a4f6-534751e4b0e9",
   "metadata": {},
   "source": [
    "We can also confirm with another plot showing quantiles vs degrees of freedom for each p-value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40472d07-740d-45e1-bc85-671b007d3196",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst3 <- st_dt2 %>%\n",
    "mutate_at(\"df\", factor) %>%\n",
    "mutate_at(\"pval\", factor) %>%\n",
    "ggplot(aes(x = qvals, y = df, color = pval, group = pval)) +\n",
    "geom_line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2bd535-6414-4172-8232-3caf83ebd8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739120ca-fafc-4b48-b255-96d3a9efc68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplotly(pst3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bf44d7-cb0d-493a-bf65-1f4ac68dcd2f",
   "metadata": {},
   "source": [
    "For each selected p-value, lower df values correspond to more extreme quantile values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3e50e6-cf01-46af-b75d-39772c947bdf",
   "metadata": {},
   "source": [
    "Now let's take two extreme examples, the one with a very high df:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c3acc1-10cf-4688-a6aa-868c968b8bb6",
   "metadata": {},
   "source": [
    "The PDF of normal distribution and the t-distribution with 1e5 df overlap drawn for p-values of 0.05 intervals between 0.05 and 0.95:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51792b3-75a2-4c61-98be-1a2c91b222c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b06f6f-d5da-411a-9ff8-1f1276d9369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(qnorm(pvals), pvals, type = \"l\", col = \"blue\")\n",
    "lines(qt(pvals, 1e5), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb55297-fd26-4dbc-8b10-f2a6ebe4fb19",
   "metadata": {},
   "source": [
    "So t distribution converges to normal distribution as df approaches $\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9094f0e4-9395-405c-91e2-a16d27c35a6c",
   "metadata": {},
   "source": [
    "The PDF of Cauchy distribution and the t-distribution with 1 df also overlap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb962ddc-9781-4ee8-a10c-d415331095bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(qcauchy(pvals), pvals, type = \"l\", col = \"blue\")\n",
    "lines(qt(pvals, 1), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f563cb-c5c4-48f4-b232-4ef90fade314",
   "metadata": {},
   "source": [
    "So Cauchy distribution is a special case of t distribution with $\\nu = 1$ and that's why moments are not defined for that df value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fda42c-fadb-455d-b18c-654922e44fc3",
   "metadata": {},
   "source": [
    "# APPENDIX: Other Important Continuous Probability Distributions (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203da26f-c37f-400b-a1dd-0d78cd9d41c3",
   "metadata": {},
   "source": [
    "## Weibull distribution (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9d8c43-c027-4dbe-916f-7d793206f03a",
   "metadata": {},
   "source": [
    "In the previous life expectancy simulation, we assumed that the hazard or mortality rate is fixed throughout the whole life of each member of the population.\n",
    "\n",
    "The resulting life expectancies or failure times formed an exponential distribution with the hazard rate as the single parameter.\n",
    "\n",
    "Now we will relax the assumption of fixed rate such that the rate is allowed to be a decreasing or increasing function of the initial rate and shape parameters. The distribution of failure times with accelerated or decelerated hazard rate agrees with a Weibull distribution. So first let's give some information on Weibull distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eef314-2440-4ef7-adc5-83904eed8069",
   "metadata": {},
   "source": [
    "The PDF of Weibull distribution is:\n",
    "\n",
    "${\\displaystyle f(x;\\lambda ,k)={\\begin{cases}{\\frac {k}{\\lambda }}\\left({\\frac {x}{\\lambda }}\\right)^{k-1}e^{-(x/\\lambda )^{k}},&x\\geq 0,\\\\0,&x<0,\\end{cases}}}$\n",
    "\n",
    "where k > 0 is the shape parameter and λ > 0 is the scale parameter of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de62515-8eb9-4926-9fec-deb11782079b",
   "metadata": {},
   "source": [
    "If the quantity, x, is a \"time-to-failure\", the Weibull distribution gives a distribution for which the failure rate is proportional to a power of time. The shape parameter, k, is that power plus one, and so this parameter can be interpreted directly as follows:\n",
    "\n",
    "- A value of ${\\displaystyle k<1\\,}$ indicates that the failure rate decreases over time. This happens if there is significant \"infant mortality\", or defective items failing early and the failure rate decreasing over time as the defective items are weeded out of the population.\n",
    "\n",
    "- A value of ${\\displaystyle k=1\\,}$ indicates that the failure rate is constant over time. This might suggest random external events are causing mortality, or failure. The Weibull distribution reduces to an exponential distribution.\n",
    "\n",
    "- A value of ${\\displaystyle k>1\\,}$ indicates that the failure rate increases with time. This happens if there is an \"aging\" process, or parts that are more likely to fail as time goes on. The function is first convex, then concave with an inflection point at ${\\displaystyle (e^{1/k}-1)/e^{1/k},\\,k>1\\,}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a07c615-00e0-47a2-85e8-98bf818fefc6",
   "metadata": {},
   "source": [
    "The expected value is:\n",
    "\n",
    "${\\displaystyle \\operatorname {E} (X)=\\lambda \\Gamma \\left(1+{\\frac {1}{k}}\\right)\\,}$\n",
    "\n",
    "where $\\Gamma\\$ is the gamma function, mathematical details of which is outside the scope of this course, however, you can access it through `gamma` function in base R.\n",
    "\n",
    "Variance is:\n",
    "\n",
    "${\\displaystyle \\operatorname {var} (X)=\\lambda ^{2}\\left[\\Gamma \\left(1+{\\frac {2}{k}}\\right)-\\left(\\Gamma \\left(1+{\\frac {1}{k}}\\right)\\right)^{2}\\right]\\,}$\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Weibull_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc24d64d-ebee-4c19-8de8-22cefee1ebc7",
   "metadata": {},
   "source": [
    "The effect of $k$ parameters on the shape of the distribution is shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96cc5ed-85c9-4f91-a497-d392ccfa13e1",
   "metadata": {},
   "source": [
    "Different $k$ parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2440fdf-7baf-4160-a496-f0870842e250",
   "metadata": {},
   "outputs": [],
   "source": [
    "kvals <- c(0.5, 0.7, 1, 1.5, 2, 5, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a00fd4-b126-419d-b2fe-b8cd31879b9b",
   "metadata": {},
   "source": [
    "Scale, $\\lambda$ parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d15cdf8-3eb0-4bdd-97a9-b1e2e35fa442",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmb <- 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acce9a11-70e3-47d2-8e79-716e343391bd",
   "metadata": {},
   "source": [
    "Different values for $x$, time to failure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e7c9fc-32b8-47da-bebf-7df582550111",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals <- seq(0, 5, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f58b051-97f3-4493-b13f-9bb0f280952a",
   "metadata": {},
   "source": [
    "Create a cartesian product of parameters values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9931cd70-5fdf-4f00-950b-d4b22c41f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "densewb_dt <- crossing(lmb, kvals, xvals)\n",
    "setDT(densewb_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41de819a-7720-4e1b-84c5-8269b942b87d",
   "metadata": {},
   "source": [
    "Calculate the densities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e25ab28-cb22-408b-b2cd-d87d047e4a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "densewb_dt[, dwb := dweibull(xvals, kvals, lmb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443f2322-49c0-4803-a47c-f40599af8438",
   "metadata": {},
   "source": [
    "Plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37983e3-0f01-4fd2-9b43-2afe31f4c126",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwb <- densewb_dt %>%\n",
    "mutate_at(\"kvals\", factor) %>%\n",
    "mutate(expo = ((kvals == 1) * 1.5) + 0.5) %>%\n",
    "ggplot(aes(x = xvals, y = dwb, color = kvals)) +\n",
    "geom_line(aes(size = expo)) +\n",
    "scale_size_identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bb8051-a9d4-49d6-8832-509158d45819",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplotly(pwb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ae4293-a24b-454b-ba3f-2cdcc3a83d82",
   "metadata": {},
   "source": [
    "The case of $k=1$, drawn in bolder line, is the special case of exponential distribution.\n",
    "\n",
    "Distibutions with $k < 1$ has a decelarating hazard rate. So the early higher mortality rates cause the distribution to concentrate in the leftmost part, while the lower rates cause tails extended to right.\n",
    "\n",
    "Distributions with $k > 1$ has an accelerating hazard rate. So the early lower mortality rates cause the leftmost part to be thinner while the accelerating mortality will cause a concentration in the middle and an exhaustion of the population causes a thinner tail that stretches to the right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e650bb-4d33-4720-9343-3deca6ac2a96",
   "metadata": {},
   "source": [
    "### Accelerated hazard rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baab2dd-59f0-4997-b4f7-f9723701bb13",
   "metadata": {},
   "source": [
    "Now, let's simulate a population again, similar to the one we did in the fixed rate with exponential distribution case:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3580ec-666d-4982-8034-1926bcd01e93",
   "metadata": {},
   "source": [
    "Number of agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c0bfc0-d57a-428f-b577-fb66c8eaec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nagentw <- 1e3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902d117b-c4b0-4b98-b434-e0f7c198e3ad",
   "metadata": {},
   "source": [
    "Initial life table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7929c46-d2d5-485f-bc14-f8168f7237ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "life_dtw <- data.table(dead = rep(0, nagentw), life = rep(0, nagentw))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c10c52c-818f-4777-97d9-d603db933ca6",
   "metadata": {},
   "source": [
    "And set the hazard rate - proportion of still alive population to die in the period - to 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de520ade-5bf1-41d6-a63e-922a21934cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratew <- 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108a1d34-e667-4b9e-bcfa-b9d1189f09c7",
   "metadata": {},
   "source": [
    "The shape parameter is $k>1$ so we have accelerated hazard rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c68b0c7-9f87-4c87-aa68-ab030da699f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kx <- 1.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f9461d-6850-4997-951a-86f6be7a80dd",
   "metadata": {},
   "source": [
    "Initialize the period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19013916-1e02-43f7-a829-814965aeb402",
   "metadata": {},
   "outputs": [],
   "source": [
    "periodxw <- 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bdc8f5-573b-4ace-8c3a-82cf8911b989",
   "metadata": {},
   "source": [
    "Randomly sample from live population using Bernoulli trials with a bias of 0.1 and record the age (period) of each individual when they die.\n",
    "\n",
    "Continue until no one stays alive.\n",
    "\n",
    "Note that the hazard rate for a time period $x$ should be adjusted with $\\lambda$ and $k$ parameters using the formula below, from the PDF of Weibull distribution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cf9c06-b325-4a9c-a70e-8b18e3081bc7",
   "metadata": {},
   "source": [
    "$\\displaystyle {\\frac {k}{\\lambda }\\left({\\frac {x}{\\lambda }}\\right)^{k-1}}$\n",
    "\n",
    "$\\lambda$ is the inverse of hazard rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e79f28c-ec83-4281-9167-9cdc709db750",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(5)\n",
    "while(life_dtw[dead == 0, .N] > 0)\n",
    "{\n",
    "    periodxw <- periodxw + 1\n",
    "    ratew2 <- kx * ratew * (periodxw * ratew)^(kx-1)\n",
    "    life_dtw[dead == 0, dead := rbinom(.N, 1, ratew2)]\n",
    "    life_dtw[dead == 1 & life == 0, life := periodxw]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3035f851-f0b0-4eee-899b-80eea2599d51",
   "metadata": {},
   "source": [
    "Check the inidivuduals who die at the oldest age:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02037fc3-8a31-472c-9996-56a3dfff996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "life_dtw[, sort(life, decreasing = T)][1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d4a4bd-e017-487c-b769-5d9428ee3870",
   "metadata": {},
   "source": [
    "The last period is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc1e6d3-ea52-4e0f-9793-01c06c602921",
   "metadata": {},
   "outputs": [],
   "source": [
    "periodxw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebd4e2d-231b-440d-b086-2c3ca8c3ad0b",
   "metadata": {},
   "source": [
    "Histogram of simulated life expectancies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc95b164-b507-403f-8928-4074a3bfee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(life_dtw$life)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3be5130-64f9-40f5-8e01-b19bb07a8d36",
   "metadata": {},
   "source": [
    "The mean life expectancy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb7c0b3-ad38-4c8b-bab2-ea44d3ae11c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "life_dtw[, mean(life)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33b3761-c712-429f-b6d8-5ba3935a6a69",
   "metadata": {},
   "source": [
    "And variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b68dd70-a744-42be-a273-81ae87077d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "life_dtw[, var(life)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12119613-d686-4399-bea4-b1e13aa26508",
   "metadata": {},
   "source": [
    "Mean and variance from theoretical distributions are (note that the hazard rate is inverted for the rate parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d925ea8e-ea3e-467e-a3b8-883bdcce6af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(Weib(kx, 1/ratew))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fa2e76-b7ca-4e8b-843b-0397d338f741",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(Weib(kx, 1/ratew))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3197b9e-73db-48f3-ba7e-92fe3176298f",
   "metadata": {},
   "source": [
    "Now simulate from Weibull distribution with the same parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b69906-ba5c-449b-9882-0497ec0d4afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(5)\n",
    "lewei <- rweibull(nagentw, kx, 1/ratew)\n",
    "hist(lewei)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f51f45b-ce22-4117-a1ad-5b89ba261b57",
   "metadata": {},
   "source": [
    "The longest life values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d252b0-752e-48b3-8f76-5764b18102de",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(sort(lewei, decreasing = T)[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c2d86d-6903-4184-b986-0b43820daf63",
   "metadata": {},
   "source": [
    "Extract the density of accelerated hazard rate simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7104e65-3f0d-4ef2-a7dc-3efd646b25e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "life_densw <- density(life_dtw[, life], bw = 1)[c(\"x\", \"y\")]\n",
    "setDT(life_densw)\n",
    "maxxw <- life_densw[, max(x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602b9e65-285b-4ee6-b870-625ae7dedbf5",
   "metadata": {},
   "source": [
    "And compare with theoretical density of Weibull distribution and exponential distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f49d17-49e2-49d0-9461-f72de309eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(life_densw[x > 0], type = \"l\", col = \"blue\", ylim = c(0, max(dexp(0:maxxw, ratew))))\n",
    "lines(0:maxxw, dweibull(0:maxxw, kx, 1/ratew), col = \"red\")\n",
    "lines(0:maxxw, dexp(0:maxxw, ratew), col = \"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c461c75-1088-4937-8a72-f7a51d189684",
   "metadata": {},
   "source": [
    "We see that, density of simulated values and theoretical Weibull densities overlap to a large extent. The density in shorter life spans is lower for Weibull, since hazard rate in early times is relatively lower, while the density concentrates in the middle where most of the population dies due to accelerated hazard rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf877036-9e20-4c13-9b3c-aa74ab0ad3b7",
   "metadata": {},
   "source": [
    "### Decelerated hazard rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d32015-80b7-48c6-989c-37d2be08ab40",
   "metadata": {},
   "source": [
    "Now let's simulate a case with decelerated hazard rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d0a7b8-594c-4d44-907a-5b2f923cce9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nagentw2 <- 1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7101a2e0-18a5-4e50-979b-b7a97db9c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "life_dtw2 <- data.table(dead = rep(0, nagentw2), life = rep(0, nagentw2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5101b6-1cc3-4f49-b36b-ad6d573ec981",
   "metadata": {},
   "source": [
    "Set the hazard rate - proportion of still alive population to die in the period - to 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cad2ee8-5164-499a-9c29-ada66079b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratew2 <- 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a7b432-5283-4a50-870e-cf15158bf1a5",
   "metadata": {},
   "source": [
    "And the shape parameters is $k<1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a150da5-4e5f-47ee-bfe1-588cabd8b904",
   "metadata": {},
   "outputs": [],
   "source": [
    "kx2 <- 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7616994-2cb2-4f2d-b3c9-f120f7dc4093",
   "metadata": {},
   "source": [
    "Initialize the period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db12f59f-4610-43c2-8af7-096538aea1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "periodxw2 <- 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a2dc2c-b147-403d-aa3e-aaba88c37bc7",
   "metadata": {},
   "source": [
    "Randomly sample from live population using Bernoulli trials with a bias of 0.1 and record the age (period) of each individual when they die.\n",
    "\n",
    "Continue until no one stays alive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167b853d-fee3-4920-93c6-0d0dc0355323",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(5)\n",
    "while(life_dtw2[dead == 0, .N] > 0)\n",
    "{\n",
    "    periodxw2 <- periodxw2 + 1\n",
    "    ratew22 <- kx2 * ratew2 * (periodxw2 * ratew2)^(kx2 - 1)\n",
    "    life_dtw2[dead == 0, dead := rbinom(.N, 1, ratew22)]\n",
    "    life_dtw2[dead == 1 & life == 0, life := periodxw2]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa640987-0cfc-4bbd-83e4-f8c611d2b513",
   "metadata": {},
   "source": [
    "Check the inidivuduals who die at the oldest age:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105f168c-7d2a-49b6-9eea-9f82e42fa5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "life_dtw2[, sort(life, decreasing = T)][1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032af078-e5f2-43f3-bacd-529636fdecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "periodxw2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0895a2d6-5dd8-4871-9a51-a1d6e12bb926",
   "metadata": {},
   "source": [
    "Histogram of simulated life expectancies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc92eae-29d0-4845-b6d4-0c3e1ab86c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(life_dtw2$life)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50d4995-0dbf-4f56-aa40-ccb6cef6d673",
   "metadata": {},
   "source": [
    "The mean life expectancy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff8dd27-8666-494e-8128-7719f0974507",
   "metadata": {},
   "outputs": [],
   "source": [
    "life_dtw2[, mean(life)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b131f3-f912-4c7d-ba01-cb86bfb0a154",
   "metadata": {},
   "source": [
    "And variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4045d9ff-eca1-4866-b181-a51e6351badc",
   "metadata": {},
   "outputs": [],
   "source": [
    "life_dtw2[, var(life)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaa88fa-1082-4c44-86d5-985ee5de682a",
   "metadata": {},
   "source": [
    "Mean and variance from theoretical distributions are (note that the hazard rate is inverted for the rate parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ba2f8c-a304-4268-838d-0e6954f96c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(Weib(kx2, 1/ratew2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7274a084-49ac-4e2f-a340-9002595d933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(Weib(kx2, 1/ratew2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb115ce-6086-4a70-8d32-fdde4549d493",
   "metadata": {},
   "source": [
    "Simulate from exponential distribution with the same hazard rate ($\\lambda$ is inverted hazard rate):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aced17f-2e84-4704-b7fd-10906399f0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(5)\n",
    "lewei2 <- rweibull(nagentw, kx2, 1/ratew2)\n",
    "hist(lewei2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7040855b-b2d7-43af-9bbf-4d42ecabb166",
   "metadata": {},
   "source": [
    "Largest life expectancy values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f65930-cbbe-4240-8f3d-a4d500cedecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(sort(lewei2, decreasing = T)[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da418bd2-87b5-4539-b2c7-43635956a81b",
   "metadata": {},
   "source": [
    "Density of values from iterative simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cf07d0-d73d-4bad-984b-4e2503fbcd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "life_densw2 <- density(life_dtw2[, life], bw = 1)[c(\"x\", \"y\")]\n",
    "setDT(life_densw2)\n",
    "maxxw2 <- min(life_densw2[, max(x)], 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10de8661-c641-4390-8bbb-0a79b8f4ba6c",
   "metadata": {},
   "source": [
    "And compare with theoretical density with a rate of reciprocal of initial wealth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3784ca-f265-4860-922b-0448edfd349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(life_densw2[x > 1 & x <= maxxw2], type = \"l\", col = \"blue\", xlim = c(0, 50), ylim = c(0, max(dweibull(1:maxxw2, kx2, 1/ratew2))))\n",
    "lines(1:maxxw2, dweibull(1:maxxw2, kx2, 1/ratew2), col = \"red\")\n",
    "lines(1:maxxw2, dexp(1:maxxw2, ratew2), col = \"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1f3dba-4d2c-4cd2-af0d-e04e5b40b799",
   "metadata": {},
   "source": [
    "Due to decelarated hazard rate (starting out with higher rates), early and later deaths have more density while the density in the middle is lower as compared to the exponential distribution with the same $\\lambda$ parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9b08ae-a069-4f70-81e0-d26e6c48d667",
   "metadata": {},
   "source": [
    "## Gamma distribution (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa83cb90-6d79-464f-ace8-48c8780ae57b",
   "metadata": {},
   "source": [
    "As you may recall from discrete distributions, negative binomial distribution is used for modelling number of failures until a certain number of successes are encountered.\n",
    "\n",
    "Gamma distribution, while it has many more applications due to its flexible parametrization, can be considered as the continuous analogue to the negative binomial distribution, in its simplest case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1038769d-318b-4913-96b3-582c27c594f6",
   "metadata": {},
   "source": [
    "Consider a sequence of events, with the waiting time for each event being an exponential distribution with rate $\\lambda$. Then the waiting time for the $n$th event to occur is the gamma distribution with integer shape ${\\displaystyle \\alpha =n}$.\n",
    "\n",
    "This construction of the gamma distribution allows it to model a wide variety of phenomena where several sub-events, each taking time with exponential distribution, must happen in sequence for a major event to occur.\n",
    "\n",
    "Examples include the waiting time of cell-division events, number of compensatory mutations for a given mutation, waiting time until a repair is necessary for a hydraulic system and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51bcd5f-63c4-4117-b472-37527c29c29a",
   "metadata": {},
   "source": [
    "If $\\alpha$ is an integer, the gamma distribution (the special case called an Erlang distribution) is the probability distribution of the waiting time until the \\$alpha$-th \"arrival\" in a one-dimensional Poisson process with intensity $1/\\theta$. If,\n",
    "\n",
    "${\\displaystyle X\\sim \\Gamma (\\alpha \\in \\mathbf {Z} ,\\theta ),\\qquad Y\\sim \\operatorname {Pois} \\left({\\frac {x}{\\theta }}\\right),}$\n",
    "\n",
    "then\n",
    "\n",
    "${\\displaystyle P(X>x)=P(Y<\\alpha ).}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a0a22b-75d1-4b58-acfc-c8ec1e7bd762",
   "metadata": {},
   "source": [
    "Let ${\\displaystyle X_{1},X_{2},\\ldots ,X_{n}}$ be ${\\displaystyle n}$ independent and identically distributed random variables following an exponential distribution with rate parameter $\\lambda$, then\n",
    "\n",
    "${\\displaystyle \\sum _{i}X_{i}\\sim \\operatorname {Gamma} (n,\\lambda )}$\n",
    "\n",
    "where $n$ is the shape parameter and $\\lambda$ is the rate, and\n",
    "\n",
    "${\\textstyle {\\bar {X}}={\\frac {1}{n}}\\sum _{i}X_{i}\\sim \\operatorname {Gamma} (n,n\\lambda )}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1615abb-b810-4d01-a1fa-e7a9d85b5d30",
   "metadata": {},
   "source": [
    "If X ~ Gamma(1, λ) (in the shape–rate parametrization), then X has an exponential distribution with rate parameter λ. In the shape-scale parametrization, X ~ Gamma(1, θ) has an exponential distribution with rate parameter 1/θ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693472a6-44da-4f6d-98d1-8c6b7a46b29a",
   "metadata": {},
   "source": [
    "The above mentioned specifications are just some special cases of Gamma distribution, which has a wider are of applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af409e99-9c16-4bee-891b-74f5c9cbd20e",
   "metadata": {},
   "source": [
    "The mean of gamma distribution is given by the product of its shape and scale parameters:\n",
    "\n",
    "${\\displaystyle \\mu =\\alpha \\theta =\\alpha /\\lambda }$\n",
    "\n",
    "The variance is:\n",
    "\n",
    "${\\displaystyle \\sigma ^{2}=\\alpha \\theta ^{2}=\\alpha /\\lambda ^{2}}$\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Gamma_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d87742-e946-4743-8482-80f22920356f",
   "metadata": {},
   "source": [
    "### Gamma distribution as time to n-th event in Bernoulli trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe37329-0e31-4f8c-8137-8dcf6481583f",
   "metadata": {},
   "source": [
    "We have seen that, the geometric distribution of number of trials to success in discrete Bernoulli trials converge to an exponential distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ecf16-c450-4ad7-a76a-a3827153965e",
   "metadata": {},
   "source": [
    "Now, using the same discrete Bernoulli trials simulation, we will see that the negative binomial distribution of number of trials to nth success converge to a gamma distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f2bab1-75c4-4750-86ea-429cddb33673",
   "metadata": {},
   "source": [
    "we will simulate 1e7 Bernoulli trials with a success probability of 0.5%. To show convergence to Poisson, we will treat each 1e3 trials as a unit interval so the expected rate of success is 5.\n",
    "\n",
    "So these 1e7 trials are supposed converge to 1e4 Poisson samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a98303e-0833-4e5d-9819-146118fa1856",
   "metadata": {},
   "source": [
    "1e7 Bernoulli trials with a success probability of 0.5%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06ae465-9839-44d6-a0a0-82e99cade046",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratenb <- 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a33be29-6daa-479c-8f1a-5732d76a46cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2)\n",
    "bernpois <- rbinom(1e7, 1, ratenb/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b09a52-4af8-46e2-a9be-398ba3a4c013",
   "metadata": {},
   "source": [
    "Check total number of successes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1e4754-72f7-4acb-8e76-1326c43dd41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(bernpois)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1567c7-96f4-4010-b388-e29db34f0254",
   "metadata": {},
   "source": [
    "Now, in order to calculate the failure lengths or arrival times, we will compress the data in the run lengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec01a3b1-7f94-434d-8bec-2305bc73747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "length(bernpois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac5506e-94de-421c-9ea8-35e70cdcfc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernpoisrl <- rle(bernpois)\n",
    "setDT(bernpoisrl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bd24c0-e393-42c9-b1db-b2a665a14004",
   "metadata": {},
   "source": [
    "The run length encoding shows the length of contiguous runs of each value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88e97be-6ab0-49c2-a425-96d614f35f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernpoisrl %>% head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0893ec86-8f04-4256-b97a-a5a0787a8f67",
   "metadata": {},
   "source": [
    "We have ~1e5 run lengths from out of 1e6 Bernoulli trials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1e6c00-fa6a-47b0-b7a3-ccbef830b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernpoisrl[, .N]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c99265d-bdf4-4fa2-8c11-0ba624d183d3",
   "metadata": {},
   "source": [
    "We add an index for rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e27d93-a23c-4901-a2f3-fda42ada1b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernpoisrl[, ind := .I]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd15f81-e171-4b75-ab47-1703619b8c6e",
   "metadata": {},
   "source": [
    "There are 274 runs with length larger than 1 for values 1, that means, there are 0 length waiting times in between those consecutive 1 values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6af4cd-3cd9-4481-b323-f635acd6aed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernpoisrl[values == 1 & lengths > 1, .N]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fb5067-8ec7-469a-8987-0b60e2c3bbd5",
   "metadata": {},
   "source": [
    "We are going to manually add those 0 length waiting times between consecutive 1 values by replicating the rows. So don't bother with what the following code does in detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa908b82-2dcf-443c-8056-5aeca8920fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernpoisrl[, replx := values == 1 & lengths > 1]\n",
    "bernpoisrl[, times := ifelse(replx, lengths, 1)]\n",
    "bernpoisrl[, length2 := ifelse(replx, 1, lengths)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54065c7-0ba3-4251-8713-1777e79507bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernpoisrl2 <- bernpoisrl[, .(lengths = rep(as.integer(length2), times),\n",
    "                              values = rep(values, times)), by = ind]\n",
    "setorder(bernpoisrl2, -ind)\n",
    "bernpoisrl2[, successn := cumsum(values)]\n",
    "setorder(bernpoisrl2, ind)\n",
    "bernpoisrl2[, successn := max(successn) - successn + 1]\n",
    "bernpoisrl2[.N, successn := ifelse(values == 0, NA, successn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37514e9e-4680-4f99-b287-7f6935282840",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernpoisrl3 <- bernpoisrl2[!is.na(successn), .(lengths = sum(lengths)), by = successn]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c9b36f-a2b2-488a-81d0-c17b0d48be86",
   "metadata": {},
   "source": [
    "Let's delete some interim objects that we don't need anymore and that holds a large space in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f4e178-26a2-4678-ad45-b36ee58e03ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort(sapply(ls(), function(x) object.size(get(x))), decreasing = T)\n",
    "rm(list = c(\"bernpois\", \"bernpoisrl\", \"bernpoisrl2\"))\n",
    "gc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3945b3-0ee3-4f08-98f3-62d4ab043eb8",
   "metadata": {},
   "source": [
    "At the end we have a simpler table that shows each success and waiting time to that success (including the success itself):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262f1e20-a0c2-4a45-a03c-25f05d0566fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernpoisrl3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e299ec-e29c-4769-812d-42607c269e71",
   "metadata": {},
   "source": [
    "These rows are for length 1 waiting times, that means for successes that occus just after a previous success without a failure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed64586-53d2-4228-978f-d60da0ffb7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernpoisrl3[lengths == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573ecc94-436d-491c-803e-cd1df5876a4c",
   "metadata": {},
   "source": [
    "Now let's calculate the waiting times to each 3rd success:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e922c-0482-47ae-9a2f-4ab52b373378",
   "metadata": {},
   "outputs": [],
   "source": [
    "nth <- 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98cfef9-97f6-445d-9bd3-75223a4298e4",
   "metadata": {},
   "source": [
    "In order to trim incomplete waiting times at the end, we get the last row that a third success occurs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aee386-c0e2-4497-8e65-02f94d7247c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lastrow <- bernpoisrl3[, (.N %/% nth) * nth]\n",
    "lastrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aecf8e1-2e49-4b87-a1ef-7d4449dba5ba",
   "metadata": {},
   "source": [
    "We calculate the waiting times to each 3rd success, again don't mind the code complexity, we just divide the table in 3 row chunks and sum the consecutive lengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b58b1c1-78df-4daf-b117-bb26717bf837",
   "metadata": {},
   "outputs": [],
   "source": [
    "nthlength <- bernpoisrl3[1:lastrow, .(lengths = sum(lengths)), by = (successn - 1) %/% nth + 1] %>% pull(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d163a3-75d5-46a2-a087-3576f1bdce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(nthlength)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fee444d-de30-4514-805f-a6bad7f9af61",
   "metadata": {},
   "source": [
    "The histogram of waiting times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f0a0ed-369f-45da-983f-bcf88d984f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(nthlength)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1ebf76-80f8-4acb-a438-010ce9007b49",
   "metadata": {},
   "source": [
    "Let's treat the distribution as a discrete one and create a similar sample from negative binomial distribution. The rate per discrete interval is 0.5%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04747d67-dc2a-4f48-8200-563e3cfad472",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratenb/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22461b6-64a0-44bb-a5db-3c841aa18930",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(5)\n",
    "sampnb <- rnbinom(length(nthlength), nth, ratenb/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3697d0-ddc3-4238-a1cf-0976a1a40f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(sampnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb70ce86-c74e-4e39-bd20-e183e715db21",
   "metadata": {},
   "source": [
    "And compare their densities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c7995a-43f4-4a7c-b5d3-c6b7e55113cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "simnbd <- density(nthlength)[c(\"x\", \"y\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976253ab-fe52-406a-b1fc-ad3eeaec3ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxnb <- max(nthlength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb47dd9-4413-4639-be3f-8e22f1660fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "setDT(simnbd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40cb8ae-03fd-4aa6-be11-1fee1af538cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(simnbd[x > 0], type = \"l\", col = \"blue\")\n",
    "lines(1:maxnb, dnbinom(1:maxnb, nth, ratenb/1000), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a2f57b-06be-4f70-a6df-43be651b726c",
   "metadata": {},
   "source": [
    "They perfectly overlap!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b875d1d3-f13f-446d-b979-768b299cd8fc",
   "metadata": {},
   "source": [
    "Now let's treat are simulated values as continous such that we compress each discrete 1000 waiting as an interval of 1 time unit of continuous waiting times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5841baaf-31a4-473f-b86c-1efdb1381ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nthlengthc <- nthlength / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54c1249-5c40-47c5-8836-49bb883a4b1f",
   "metadata": {},
   "source": [
    "See the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc27383-18ac-47f4-bd18-2d06c8464587",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(nthlengthc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffd952f-ed57-45d7-bc76-ea0e701e6c6a",
   "metadata": {},
   "source": [
    "And histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ab3b57-cfd5-4a3a-8d80-7b027e94bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(nthlengthc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aef67a0-d26a-4c1c-a436-9444ec123c68",
   "metadata": {},
   "source": [
    "Now we sample from gamma distribution. The rate per continous time interval is 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3144e6-043f-499e-ba18-85c2edc5cfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratenb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d0aefc-0882-44a4-9328-c4abccbda210",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(5)\n",
    "sampgm <- rgamma(length(nthlengthc), nth, ratenb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2375a7-9391-4743-96c9-e905bbf15307",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(sampgm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab4dc94-2ae5-4c1a-911e-53ddbbea833e",
   "metadata": {},
   "source": [
    "And compare the densities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8da361-4c6b-4edd-b476-f2684fabaf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "simgmd <- density(nthlengthc)[c(\"x\", \"y\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0a6ebe-11ab-4d82-bab2-e702bf1fd540",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxgm <- max(nthlengthc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12390750-d09c-426f-a698-9c9dead140eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "setDT(simgmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b92df68-02ae-4abc-a949-fb3c61326c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmvals <- seq(0, maxgm, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2a0bf5-21e4-4bb8-8086-0cb4b52328fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(simgmd[x > 0], type = \"l\", col = \"blue\")\n",
    "lines(gmvals, dgamma(gmvals, nth, ratenb), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a59389-51ad-4cad-b4f4-9bfeb7d1c1d8",
   "metadata": {},
   "source": [
    "They perfectly overlap!\n",
    "\n",
    "So we show that gamma distribution is the continuous analog of negative binomial distribution for waiting times to nth successes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304f6eac-c360-4f59-8e2b-085d31f609cb",
   "metadata": {},
   "source": [
    "### Gamma distribution as sum of exponentially distributed variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4bd33f-ce60-424f-be03-11cb1cf0af66",
   "metadata": {},
   "source": [
    "Now we will conduct a second simulation to show that gamma distribution is sum of exponentially distributed variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb21976-0420-4ae4-827b-ec18f28c1492",
   "metadata": {},
   "source": [
    "The size of the sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e544e40-8d23-4a60-a9d9-d992da35ffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeexp <- 1e4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f41dfc-b49a-45ac-a68a-7ebb3dd36e68",
   "metadata": {},
   "source": [
    "The rate per unit time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25548f8a-c4a2-4f8a-bfe3-b401279d6762",
   "metadata": {},
   "outputs": [],
   "source": [
    "rateexp <- 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2c45fe-5e5c-4703-b8d9-6bac9998634f",
   "metadata": {},
   "source": [
    "We will create 3 samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea9af9f-0753-4fb2-ac07-1fea35d46fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "nexp <- 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d994d53-de5a-40fd-8c17-b4ae3f39ec5b",
   "metadata": {},
   "source": [
    "Create 3 samples from i.i.d exponential distribution and sum each row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32d92c7-2f15-4dc8-85c2-866aae0fe037",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(6)\n",
    "sampexpgm <- rowSums(replicate(3, rexp(sizeexp, rateexp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bc9647-90cd-412e-ad54-37b5490efc39",
   "metadata": {},
   "source": [
    "See the histogram of row sums:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af4528-f298-4d86-954d-cfc357129c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(sampexpgm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d72974a-b227-4f49-9fa1-20297f432d4c",
   "metadata": {},
   "source": [
    "They are gamma distributed. Let's confirm with directly creating a sample from gamma distribution with the same parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e5f482-a2cf-43cf-a69a-ba1b51b18ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(7)\n",
    "sampgm2 <- rgamma(sizeexp, nexp, rateexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d0d71b-25e5-42d7-a181-478837d7146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(sampgm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf771d8-d692-4c11-b097-448fc300c484",
   "metadata": {},
   "source": [
    "Let's extract the density of the first sample created from row sums of exponentially distributed variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2e94a1-8f74-4db8-86c4-9b1f4337bff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampexpgmd <- density(sampexpgm)[c(\"x\", \"y\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306e287f-7187-4ae1-995a-2ecf4caeb367",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxexpgm <- max(sampexpgm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c151ba-e0bd-4cfe-bdc2-b93539d8e530",
   "metadata": {},
   "outputs": [],
   "source": [
    "setDT(sampexpgmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52ffb4a-ea00-4757-8b07-a80f87c310f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmvals2 <- seq(0, maxexpgm, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ce49fd-0ab1-4eb9-890d-95621a36b605",
   "metadata": {},
   "source": [
    "And compare with the density of gamma distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb640540-a8d7-4753-a70b-d955a5a26a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sampexpgmd[x > 0], type = \"l\", col = \"blue\")\n",
    "lines(gmvals2, dgamma(gmvals2, nexp, rateexp), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21b968d-bccb-4ca1-93fd-64c262047717",
   "metadata": {},
   "source": [
    "They overlap perfectly! So we show that gamma distribution is the sum of i.i.d exponentially distributed variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
