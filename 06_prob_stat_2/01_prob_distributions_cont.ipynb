{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d37f78dc-d8d8-4b7f-8340-c4519fa12c6e",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b>BASIC PROBABILITY DISTRIBUTIONS: CONTINUOUS DISTRIBUTIONS</b></font>\n",
    "\n",
    "<font size=\"5\"><b>Serhat Çevikel</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0229fa88-d109-4d5c-8d0d-e277dcfbb18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(data.table)\n",
    "library(tidyverse)\n",
    "library(plotly)\n",
    "library(psych) # for pairwise scatter plots\n",
    "library(estimators) # for theoretical moments\n",
    "library(moments) # empirical moments\n",
    "library(miscTools) # for ddnorm, derivative of normal distribution curve\n",
    "library(MASS) # for multivariate normal distribution\n",
    "#library(GGally) # for pairwise scatter plots\n",
    "library(BBmisc) # for standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43734fa2-5eec-4eb8-bde9-f0c99fcd9b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.matrix.max.rows=20, repr.matrix.max.cols=15) # for limiting the number of top and bottom rows of tables printed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716036f0-a0d7-478e-8462-7f2da0a759fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(htmlwidgets_embed=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e0a02a-e711-40cc-810d-1a9d6e335940",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(knitr.kable.max_rows = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e54b741-8c8b-4abf-be5a-c41e04aecca2",
   "metadata": {},
   "source": [
    "![xkcd](../imagesba/normal_distribution.png)\n",
    "\n",
    "(https://xkcd.com/2118/)"
   ]
  },
  {
   "attachments": {
    "19c7cfcc-e7e1-4c64-b5b7-b8ffb22d2f5d.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAACMAAAAWCAIAAADFDLIQAAAA5klEQVR4AeSTMQqEMBBF1yDiBawtbPaCroVgp8IexN7egyzYWgjaiEmXZHfASjLDkggi+AkW3/k+54vse5bY4yzdkDQMw2cvIYRb32R7Wuu6rouieO9VluWyLA4wkjTPc9/35hPHcayqqsXUdR3n3IxsDklSSm0T5nWaJgzUNk2T57mU0oyAQ5LgnsNZ1xXKQIMkCX5oNPDXhA+MzpAkdPqIeQGSc3vU3hfYiXo1Z/9WO/m+71YUFSTbi6IojmNbWJIkEERTJIkxlmXZy1JpmnqeZ0eC6TAMn5YKggCC6CF3QqePmD8AAAD//42aV1MAAAAGSURBVAMAzcD1xFYo2KQAAAAASUVORK5CYII="
    },
    "59f65417-a59d-4016-bc05-07b80a568ba9.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFcAAAAfCAIAAAAdocY6AAABY0lEQVR4AeyXvWoCQRCADwMhEJKAIY1FYpcfSMoEUqVImzxBmvTW2ilYCAp24gP4ChYWWmhjYSsodleJP1iJoiKeMxbjsZyNsI7uzbFz7N5wt/N9N8VdwJHDcQKWHJYlFrALxIJYQAMYai9U2uPPTCcUa5o9gBFIUcAmVAvxYtceLTYpk0/ACKREqFqANOXMnrhJVQtmk++iEwtoRiwch4X38OV98Bxr4Qv+Xij8P/x9BPkM4M78FrAK7hAL+AZOwwJWqjMYLPy+3XTTrzSuL84iX3e0bCVedPJ6P5vBQqc/z1YGNBZLp2FPaJmrDr0r1XmVxcIsW+7TmC1XDXtKy3zNHxZ0vtQ9n83QC3tWqvM2sYB2+S08JVqpUg9r4Qt+C3zs253FAroQC14WwrfMP7lY1EHCTar2QvIn5E4fpB6GTYARSGlj1cL381U9+khf9aZOgBFId1qghK8mai/4Cp5g1wAAAP//wSp5HgAAAAZJREFUAwAn/0tYQyKHDAAAAABJRU5ErkJggg=="
    },
    "ea8cd5d8-ffdb-40c2-bb70-8207eed5cbee.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAG8AAABvCAIAAABtpwk3AAAPXUlEQVR4AeycCVRW1RaABUTmWZFBRhFRcMAhB9RMe6WZlopTapqlrbJX+nLo2TJtPS17WZbZc1XqytTMnOfU1J4+CzUVZwXECeH/QRCZ4Qd83/0PXFQEQu79Bdd17XXd99x9zz3nu/vss8+5gLnBYMjPz8/Ly8vNzc3R/j0UgdzcXADm5+ebc3tycrJOp9Pr9SiaPAQB0Ol0Om40z8jIcHNz89P+1ZgAGM2LiopsbGzqaf9qTACM5jWuRKugjIBGs4xFzTWNZs0ZltWg0SxjUXNNo1lzhmU1aDTLWNRc02jWnGFZDRrNMhY119SiWfOW1cUaNJpKvjWNpkZTSQJK1qX5pkZTSQJK1qX5pkZTSQJK1qX5pkZTSQJK1qX5pkZTSQJK1lUbffNcYtaG4/ozN7Ie0NHaXVTraG44pp+3I76w6M43/71eu9E9oHWPgGZyRgHel1NQVL45/4u9tfpIUmQHj1Bve7Pyl2t9iUlpHruaMXHVOWTW5rgxS09/vD0+Vp8jI8rMK/zW6I+9W7idSsgM8bSTL9UVxXQ0951PZQiH+zp+Nyb065EtO/g7Hb+WMWNDTFxyCdCtJ1NyDcVdg5ztrCwOxtx6IsC5PMSDsbcS0/PLl9eSEhPRTM8xLDl4w8bSfExXL2dbS3fHBuO6eQsEMs1fz6VS8mSw6++X0ovv3Ong78jp3bLvQtrCX6/+cubm3YW1SjcRzV1nUg1FxU3dbS0tSp7YyKEBINr4OPQJa4gCQUa6g3X9dn6O204mD+ngQeF9Ulx8x9vZOiLoAT57n6U4zcovOhx/+6IuW5wSZ77ae+3TXy6LUzWOJX1To+q764y+nsGpo019jrK8+4z/5L/5i9M/4tJRIHXk8m1D4R1CJ6f3ydMt3b4YEdLc4/54mpFbeCju1ro/dbwP+RYi7yvLTn+176q78bVdSMqetyP+QExaqyYOso3iiolopmUbaPrZe1PIzk2lEEk5cjIhkyOuuuRgwus9fdDLy/mk7EspUpCN0WcPWRyNwGjbyZRXvz/zxZ6ra47qiLziruz8ImICemR7Dxc7SxRiNEekezMXjiqJiWg2tJfG9e3cws92XSnfExL13IIiJp9zidldmjpbmJttOqFnYMqWqVkGMoEPNsWKYWsouiMurfgjMc9Q9P24Vp5OVpTkGYo5IoRgnoWCO3NETlyVBkdbX0eewqlKYiKazNSiA1Hx6V/vuyZ0+XjSGAdsG1hsPZkcn5Izbe3FVVFJC/aUcf/pSBJZqk0Di6dbuHHX9bQ8jkiYtz3JKYBSjb4f2NCGQoS8lWNEkIu9lQXKldRcBCXcV8VhTv0motkrxFWMOB7528W03WfvmZcZwpSnZBZwDPN26BwozTP5huL8QsnXmEy4hUsM0gb1pQaL8c6UNah9Y8px7QKjpYiJRBXBTs4K9hqzBSzbqBk0qV9qHP+pLbjVW7185acs/z0x6XZJ2sjwFOOXq/94xn9YR4/6FtI6KKChjZWR3Z+Xb3MJeSrElSPgThuD7JPNXYTBmRtSzPVwsnKzl0KkQI9lmLc9x1s5BlIrFOZAbxdrFIRKiBLT111EN4oyBxPRpLGtmziM6OSJgtCZL0oH8vmkkt2NZ8MaEjS5etY4WXUMcEJHTlyTQh5ZapC7LacHYm4RRlG6lc4n4mW08pbYUfP2UylcxR5B+elwEoUoLT0lAxT4Tl17cUt0cnpOIacKiulo0uhB7Ro/UcooPiWXZIhCUhmOyGDjsL2amktvOW3lLcW4W9kGUlFO5WG76UQyp0429Zs2kuCixxqXpy28JFjrj+tJmCh0tZOyMZYGwjEpIWHgSDxhXWtWzwy9rY/0CBSlxKQ0afTbvf1cbKXxiB5tdLpziZJvMipF+cnr0rBlCIt1+jajo2EcYkwzf7uYps+QQkSokR3l+KkIr252lqw7WZL2CJYCQkqm4Y9L6XO2XXqudSPMEBa1N9LzPt4R/1r3Jj2aS3nSC+FS2OWSUqIuTfI+puO722plaR7ZoaQPUCBo4qQYyOm6GPiBjaTZmflnV+l85eVszSkpOsYIyyqOyM0sae5CYfOJHJPI26yx5LNk8p/vvtK/jXsDC6mPLL1O38hcciDhn88F+rhYb41OfrV7Ey9nKa/iXqVEepJSdZWvZ3N08o7T90zf2IiZF4VJOUZfsuyTC8WmBlMKBqsPJ8mz8NnErH9tvSQnBiKGYmNhLo1ZFDL5EU94Ut6zuWunQCfC9DtP+/UIdhEjICWzAO6zBgSB9fM9V9r5OYoVLTcqKOrSJIsmLZenb9FuSoTCnAMjdKYL4iAKkpkn7XvezDKwpoa1vGBfFZVo28A83KdkK8S/NLUEH86IyxOURcJkKCoObGgL5KUHE95ceU5kS3/v7RfZXlr7L9h9pbi4Hqc8S3FRl2ZmnjRp7iiNfaL1YlYhn2fFfSZBCprBxrEprlpbSk06nZBJnk+foSbynpZe9lP7BHQJcp79QtCHLwTZNpDScnHLR4OCV77WWiQMvLk3VpyLTc4J9XaY0idgQFt3bBgEHY07UvA9r8ue1jeAQjVEaroa9Yo6uzaV8nD20I6W5oysFzefSMYr2e9g+x3vw1JMOCgIlziSn07rE+DrKqWHcwcGz4sMFgRZQTL/QBabB8rao7omLtbT+wa8GO7u72az/0IaZpP/5keF647paAmBVR4HXFJW1KU5JsIbB6TFC/ZcJS9Bfj6a9EZPH7pEYW5BMQMZ6eBXklpSOLqL16dDm3/7cqhIaCjBN5s2kiYW9ColJauAkY4ZK6JPdsYzOIieBGWyyzVHdLxCkRtgoIaoS9PVznLOwGZr32j744TWOBfySWTzXsa1Np0B09COHojnvXMrPiXGOzbVlcHtGucUFL/94/l311xg/T53UDOS/B8PJ7HyYRInvFS3wmrZq0uzWk1RxLitr+Pi0S3ffdb/s2Eh0/sG2lvVZ3t443H92AhvNSbx+9r8uNEU3SO8MpWTFbyz+jwrLgZ4v9IcXhiodCxPU6UHqVgt3+ZYArDyYX7jK/zszXEjvzv18XZpp531FeFF7QEu96120byZVRCrzyHfjrqU/tuFNKbgTSf0LHJ+Pqq7W9ifn7/r8syNsW+tOj96yamXl5yavu4iK5+VUYlkuCKH9XG15kPeVyNbVJIAyBSUUh4NzRu38o5fzWCe/e5AAiucST9dGLvsNF8mSBX5Jjx3e/xnu698vf8a6eGqqKQNx/Rr/9TdLbvO3OTz2QVdtj4jP690v50ZL7ixXedAZxbm/x7S/PNhIX1bNbIy7ukpBavKekxH81paHvg+3BIHNfCx+8A8y7Yxe0jAZUVfZVsxgA7pDt8nSKSYasjkkYUjWpA2fPNyKDM4ha9EeLM3irHpRXWal2/m4mKs8EhZwMc+eXU7GdjI9sXwxm8+5UuytXJ86w/6N339SR8WObghmTxyX4JV3foVtFeRJkvDmZti+chD+GPTobqN7hToROL9/bhWn0QGj+zs+VSIq1gIVLceU9qrQhN/nLU5js+TF5JKtoiq1SUG8qKRLac8G0DiTQZerXsfrbEqNAlb5CXEskUjW7Bklr9JVNlVssKlY8MYyI0dpS/GVdrXNgNVaMqdbOxo1cHfif2L/4xqiaOZyRfKKZYW5jP7N2XF4mgjfYEod71uFKhLU2bAHi1B8IMBQWyOyYWyQo790eBm7O/KJXVUMRFNQYePPwuGP+AHiQgL7HQImzp9NClNSLG3SKITESR95OIUIT2sPSkO7amJmI7m3a18+2lf/JQSDyerPq2knzhEfwzk0dA0NzPjswR+2r9NI/THgKPowqOhybP5sPNmL9/2d+26U1jX5ZHRBFw7X0e231EeG3mUNB8biHJHNJoyCgUUjaYCEOUqNJoyCgUUjaYCEOUqNJoyCgUUjaYCEOUqNJoyCgWUuk9TAQiKVaHRVAwlFWk0gaCYaDQVQ0lFGk0gKCYmpdmrV68DBw6Ub/vcuXMXL15cvrzOlahFc+HChf369QsLCxswYACwCgulH4CviA6UIyIiKrr6V8rbt28faPxXVCT9EkIlt6xcudJoGDh//vxKzB7ukio09+3bt2jRotGjRx86dGj27Nl+fn7161f2XbdLly6tW7d+uA7Id23bti0+Pt7Couy3C7jEixTsOO7atYuSUaNGYUbb0BUXVWjq9fo2bdoMHz7cycmpXbt2dEBu99GjRyMjI9u2bfvSSy/t3r1blL/33nvCU9avXz9p0qQZM2bgqt27d582bVpeXl5WVlZoaOjZs2eFMW7esWNH3pM4rfzIo3HGZs2aYZaSIv3+JYp6ogrNbt26JSYmzpkzJykp6b6mR0VFAQuOPj4+77///n1XOd2yZUtwcDCONm/ePHwcvvb29v3799+4cSNXkb179zo4OHTt2hW9SmnSpMkPP/zg6OjYu3dvM7NKfjqiypr+koEqNCG1fft2a2vrgQMHjhs3LiEhQW4LDou3uru7T548OTU1Fb+TLwnF399/7NixLi4uuGefPn2uXZP+NMCwYcOgiVdiA+ghQ4aYmVWNhhg6ceLEjIyM5cuX29ra3rlT8hcXqEQlUYUmbXV2dp4yZQrjsUePHniWPMrc3KQ/foAB3eNoMEh/7wNFFtmAEhsbG0EwPDzcy8uLwHf79m0cdvDgwVytXLhRoFy2bBnP+vLLLxn1ld9S86tq0RQtY07A0Rhox48fFyXm5lU8sSID4uymTZt27tzJ68G1RW0VHUE5YcIEvBKUDJGKzCotf5iLVfTtYaqsV+/UqVPMNsnJ0i+S79+/n14xKT1cVfJdZFq8EsY7w1wurEiZOnVqfn7+0qVLTYmSxqhCMy4ubvz48Z07d+7UqRMOtXr1ag8PDx5WE7Gzs3v++eeZ3Hr27FllPSRAS5YsIVBUaamsgSo0Bw0aFB0dTVp3+PBhAlZISIhoNCGPcSp0hj8GzDacMn0TZFEIiGvWrEERwqQ/c+ZMoXPE3ciuKgoFGMjCRGd6lDxdFZrUq7gcO3Zs69atQ4cOrahmPJcUnXm8IgNRTvqJ2YoVK8Spssc6QFOn09H/ESNGzJo1y9PT84H9hzWejjDvPdBALmRmxwwRo0EuV0SpAzSJuXQ+JiamEsdUhEXNK6kDNGveSZPVoNFUErVGU6OpJAEl69J8U6OpJAEl6/orvqnk8x7vujSaSr5fjaZGU0kCStal+aZGU0kCStal+aZGU0kCStal+aZGU0kCStal+aZGU0kCStb1KH1TyX7Ujrr+DwAA//8v5nhgAAAABklEQVQDALDaQa1qCzQDAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "id": "bee346d3-0103-480d-be59-6545ac0c99a8",
   "metadata": {},
   "source": [
    "**Note:** For the interactive applications, please:\n",
    "\n",
    "- Select file browser from the side bar through the symbol: ![image.png](attachment:19c7cfcc-e7e1-4c64-b5b7-b8ffb22d2f5d.png)\n",
    "\n",
    "- Open the Launcher by hitting the button: ![image.png](attachment:59f65417-a59d-4016-bc05-07b80a568ba9.png)\n",
    "\n",
    "- Hit \"Shiny\" button from the Launcher:\n",
    "\n",
    "  ![image.png](attachment:ea8cd5d8-ffdb-40c2-bb70-8207eed5cbee.png)\n",
    "\n",
    "- Navigate to 05_prob_stat_1/apps/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d37137-c068-41d3-a60f-8c1fc2e8a54f",
   "metadata": {},
   "source": [
    "Continuous probability distribution can take real values on the supported portion of the continuum. For Beta distribution the supported domain is the interval (0,1), while for the exponential and gamma distributions the supported domain is (0, $\\infty$). For normal and Student's t distribution the supported domain is the whole continuum ($-\\infty, \\infty$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9501a5c6-399a-47a8-bbba-8cea6cddb469",
   "metadata": {},
   "source": [
    "For both discrete and continuous distributions, the range of cumulative distribution function is between 0 and 1 and cumulative distribution function is monotonically increasing between 0 and 1. \n",
    "\n",
    "However, for discrete distributions, the probability mass function can take on probabilities between 0 and 1 for discrete values.\n",
    "\n",
    "For continuous distributions, any single point has a zero probability of occurence since the domain is the supported portion of the continuum. The probability density function show the instantenous change in the cumulative probability and can take on any positive values and can be above 1.\n",
    "\n",
    "Both probability mass and probability density functions can have negative and positive slopes across their domains, so they don't have to be monotonically increasing functions.\n",
    "\n",
    "So the cumulative distribution function is the integral of probability density function and probability density function is the derivative of the cumulative distribution function.\n",
    "\n",
    "We can compare the cases of selected discrete and continuous distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7681e3-f16e-4cf6-9de0-ce44c30f3ce8",
   "metadata": {},
   "source": [
    "As an example of a discrete distribution, we can create two vertical subplots for the probability mass function and cumulative distribution function for binomial distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3419e8b5-0e32-495d-9df2-c2a50e7ae702",
   "metadata": {},
   "outputs": [],
   "source": [
    "qvals1 <- 0:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d570fa5-ad98-4184-aa11-604574fb7513",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 <- plot_ly(x = qvals1, y = dbinom(qvals1, 10, 0.3), type = \"scatter\", mode = \"lines\") %>%\n",
    "  layout(\n",
    "    xaxis = list(\n",
    "      showspikes = TRUE, \n",
    "      spikemode = \"across\", \n",
    "      spikesnap = \"cursor\", \n",
    "      spikethickness = 1.5,\n",
    "      spikecolor = \"red\"\n",
    "    ),\n",
    "    yaxis = list(showspikes = FALSE)\n",
    "  )\n",
    "\n",
    "p2 <- plot_ly(x = qvals1, y = pbinom(qvals1, 10, 0.3), type = \"scatter\", mode = \"lines\") %>%\n",
    "  layout(\n",
    "    xaxis = list(\n",
    "      showspikes = TRUE, \n",
    "      spikemode = \"across\", \n",
    "      spikesnap = \"cursor\", \n",
    "      spikethickness = 1.5,\n",
    "      spikecolor = \"red\"\n",
    "    ),\n",
    "    yaxis = list(showspikes = FALSE)\n",
    "  )\n",
    "\n",
    "subplot(p1, p2, nrows = 2, shareX = TRUE) %>%\n",
    "  layout(\n",
    "      title = \"Binomial Distribution for p = 0.3 and n = 10\",\n",
    "    hovermode = \"x unified\",\n",
    "      annotations = list(\n",
    " list(y = 0.9, text = \"Probability Mass Function\", showarrow = F, xref='paper', yref='paper'),\n",
    "  list(y = 0.3, text = \"Cumulative Distribution Function\", showarrow = F, xref='paper', yref='paper'))\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add553b4-044c-44b6-a23d-9ea1f81f4212",
   "metadata": {},
   "source": [
    "As you see the probability mass function takes on values up to 1, cumulative distribution function is the cumulative sum of those discrete values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2ebde1-5688-4afa-9d22-ed24e02aadc7",
   "metadata": {},
   "source": [
    "Now as an example of continuous distributions, we can create two vertical subplots for the probability density function and cumulative distribution function for beta distribution and we will see in the next section what beta distribution is all about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e705015e-4663-4477-bac9-9604e2fd0ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "qvals2 <- seq(0, 1, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3421780-d8c3-4a54-9030-c4f3e8b86786",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 <- plot_ly(x = qvals2, y = dbeta(qvals2, 0.3, 0.3), type = \"scatter\", mode = \"lines\") %>%\n",
    "  layout(\n",
    "    xaxis = list(\n",
    "      showspikes = TRUE, \n",
    "      spikemode = \"across\", \n",
    "      spikesnap = \"cursor\", \n",
    "      spikethickness = 1.5,\n",
    "      spikecolor = \"red\"\n",
    "    ),\n",
    "    yaxis = list(showspikes = FALSE)\n",
    "  )\n",
    "\n",
    "p2 <- plot_ly(x = qvals2, y = pbeta(qvals2, 0.3, 0.3), type = \"scatter\", mode = \"lines\") %>%\n",
    "  layout(\n",
    "    xaxis = list(\n",
    "      showspikes = TRUE, \n",
    "      spikemode = \"across\", \n",
    "      spikesnap = \"cursor\", \n",
    "      spikethickness = 1.5,\n",
    "      spikecolor = \"red\"\n",
    "    ),\n",
    "    yaxis = list(showspikes = FALSE)\n",
    "  )\n",
    "\n",
    "subplot(p1, p2, nrows = 2, shareX = TRUE) %>%\n",
    "  layout(\n",
    "      title = \"Beta Distribution for Shape Parameters α = 0.3 and β = 0.3\",\n",
    "    hovermode = \"x unified\",\n",
    "      annotations = list(\n",
    " list(y = 0.8, text = \"Probability Density Function\", showarrow = F, xref='paper', yref='paper'),\n",
    "  list(y = 0.3, text = \"Cumulative Distribution Function\", showarrow = F, xref='paper', yref='paper'))\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57648180-c259-4c75-a267-0da793b315a5",
   "metadata": {},
   "source": [
    "Here, the probability density function can take values above 1. When the slope of probability density function is negative, cumulative distribution function is concave, its slope is decreasing. When the slope of the probability density function positive, cumulative distribution function convex, its slope is increasing.\n",
    "\n",
    "The reason for this relationship is grounded in their mathematical explanations. For continuous distributions:\n",
    "\n",
    "- Cumulative distribution function (CDF) is the integral - or area under the curve - of probability density function (PDF)\n",
    "- PDF is the derivative - or the instantenous rate of change - of CDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f889db48-7f43-4132-8959-b38d37af5fdd",
   "metadata": {},
   "source": [
    "# Beta distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409f1105-cd56-4ff2-b17e-c8e051bab126",
   "metadata": {},
   "source": [
    "Under binomial distribution, we calculated the probabilities of having $k$ successes in $n$ trials in which probability of success is $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe11c739-15f0-4dd7-ac01-a9276df74072",
   "metadata": {},
   "source": [
    "Now let's take $k$ and $n$ as given, and calculate the probabilities of having $k$ successes in $n$ trials for different $p$ values:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aaf6c6-c139-46fe-8084-4e7329fcb910",
   "metadata": {},
   "source": [
    "Let's divide the whole domain of possible $p$ values between 0 and 1 into intervals of 0.001:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f102d43-972c-4ea8-83c5-4b1eb9f22c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals <- seq(0, 1, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d52c78-b43e-4fdb-a8f0-ceb1ec773148",
   "metadata": {},
   "source": [
    "Let's select some arbitrary $k$ and $n$ values.\n",
    "\n",
    "Foe example we can say, we tossed a coin only one time and got a head. So what is the likelihood of this data given different bias values. And repeat the same calculation when we have 2 and 3 tosses but still have only one head:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e27eef-f74f-4c9f-ad2d-d87a9395087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvals0 <- prop.table(dbinom(0, 0, pvals)) * length(pvals)\n",
    "dvals1 <- prop.table(dbinom(1, 1, pvals)) * length(pvals)\n",
    "dvals2 <- prop.table(dbinom(1, 2, pvals)) * length(pvals)\n",
    "dvals3 <- prop.table(dbinom(1, 3, pvals)) * length(pvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d5989-ff88-4656-8502-5c88a0da10f2",
   "metadata": {},
   "source": [
    "Plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5dcaf1-3ea6-418c-9dde-9a9a5fae25f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(pvals, dvals0, type = \"l\", ylim = c(0, 2.5), col = \"green\")\n",
    "lines(pvals, dvals1, col = \"red\")\n",
    "lines(pvals, dvals2, col = \"blue\")\n",
    "lines(pvals, dvals3, col = \"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89661bd0-671f-44ec-bb9a-56f1ae73dff9",
   "metadata": {},
   "source": [
    "- <span style=\"font-weight:bold;color:green;\">Green</span> line shows the relative plausibilities of the bias values in the domain between 0 and 1 when no tosses has been conducted yet. Without any tosses yet, all bias values has the same flat probability. So we can be totally ignorant about the bias value before any experiment provided that we have no prior belief.\n",
    "- <span style=\"font-weight:bold;color:red;\">Red</span> line shows the relative plausibilities of different bias values while the data we have is 1 head in 1 toss. Bias values closer to 1 have more relative plausibility.\n",
    "- <span style=\"font-weight:bold;color:blue;\">Blue</span> line shows the updated plausibilities when we have a second toss which is tail, so at that time we have 1 head in 2 tosses. Now the bias values closer to 0.5 are more plausible, with a bump in the middle and the relative plausibilities decreasing towards to 0 and 1 extremes.\n",
    "- <span style=\"font-weight:bold;color:black;\">Black</span> line shows the situation when we have three tosses and still only one head. Now the plausibilities of bias values closer to 1 decreased further while, values closer to 0 became more plausible, with the bump shifting left."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fddf01e-70df-4837-8db9-782d3274eda1",
   "metadata": {},
   "source": [
    "The above simulation shows a discrete version of beta distribution the PDF of which is:\n",
    "\n",
    "${\\displaystyle P(p;\\alpha ,\\beta )={\\frac {p^{\\alpha -1}(1-p)^{\\beta -1}}{\\mathrm {B} (\\alpha ,\\beta )}}.}$\n",
    "\n",
    "The domain of the beta distribution can be viewed as a probability, and in fact the beta distribution with shape parameters $\\alpha$ and $\\beta$ is often used to describe the distribution of a probability value p for a binomial distribution of $\\alpha - 1$ successes in $\\alpha + \\beta - 2$ trials.\n",
    "\n",
    "The beta function, ${\\displaystyle \\mathrm {B} }$, is a normalization constant to ensure that the total probability is 1. The binomial coefficient which appears in binomial distribution is a constant as ${\\displaystyle {\\binom {\\alpha+\\beta-2}{\\alpha-1}}}$ so in the PDF of beta it can be considered to be a part of the beta function, the normalization constant.\n",
    "\n",
    "The expected value or mean is:\n",
    "\n",
    "${\\displaystyle \\mu =\\operatorname {E} [X]={\\frac {\\alpha }{\\alpha +\\beta }}}$\n",
    "\n",
    "The variance is:\n",
    "\n",
    "${\\displaystyle \\operatorname {var} (X)={\\frac {\\alpha \\beta }{\\left(\\alpha +\\beta \\right)^{2}\\left(\\alpha +\\beta +1\\right)}}}$\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Beta_distribution)\n",
    "\n",
    "Note that the parameters for success and failures are incremented in $\\alpha$ and $\\beta$ parameters of beta distribution. Let's repeat the above simulation with beta distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8c48aa-b083-43c7-9c4c-d40820d8450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbetax <- function(a, b, x) x^(a-1)*(1-x)^(b-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f7d78d-a283-46ae-8c7d-8b59eb2ce926",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvals0b <- dbeta(pvals, 1, 1)\n",
    "dvals1b <- dbeta(pvals, 2, 1)\n",
    "dvals2b <- dbeta(pvals,2, 2)\n",
    "dvals3b <- dbeta(pvals, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a61711-8138-4813-b01f-9f5f859b7278",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(pvals, dvals0b, type = \"l\", ylim = c(0, 2), col = \"green\")\n",
    "lines(pvals, dvals1b, col = \"red\")\n",
    "lines(pvals, dvals2b, col = \"blue\")\n",
    "lines(pvals, dvals3b, col = \"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b09272e-6f2d-47df-898a-31ff32facadf",
   "metadata": {},
   "source": [
    "The previous simulation was a discrete version sum of the values of which are normalized to 1, so can be considered as a probability mass function. The second simulation above is the PDF of continuous beta distribution so the range is not capped at 1. And the parametrization is different, the k and N parameters of the first simulation using binomial distribution are equal to $\\alpha-1$ and $\\alpha+\\beta-2$ using the parameters of beta distribution.\n",
    "\n",
    "This change of scale and the reparametrization are the only differences. Other than that the shapes are the same:\n",
    "\n",
    "- <span style=\"font-weight:bold;color:green;\">Green</span> flat line reflects the case where we have no success or failures so any $p$ value is equally probable. That is in fact the uniform distribution that we will see later.\n",
    "- <span style=\"font-weight:bold;color:red;\">Red</span> line is the case with 1 success and 0 failure. Density of $p$ values linearly increase in the domain from 0 to 1.\n",
    "- <span style=\"font-weight:bold;color:blue;\">Blue</span> line is the case with 1 success and 1 failure. Density is higher in the middle one for $p$ values closer to 0.5.\n",
    "- <span style=\"font-weight:bold;color:black;\">Black</span> line is the case with 1 success and 2 failures. Density now shifts to lower $p$ values.\n",
    "\n",
    "And fact this progression shows one of the simplest case of Bayesian inference and the classical use case of beta distribution:\n",
    "\n",
    "As you may recall, Bayes rule is basically:\n",
    "\n",
    "${\\displaystyle P(B | A) = \\frac{P(B)P(A | B)}{P(A)}}$\n",
    "\n",
    "Hidden behind these symbols, the true meaning can be understood as such:\n",
    "\n",
    "- Let B be some hypothesis we want to test the probability of. We cannot directly observe hypothesis so we have to make an inference about it. For example the event of raining tomorrow may be an hypothesis, we cannot directly observe tomorrow's rain today.\n",
    "- Let A be some evidence or data related to the hypothesis. We directly observe and measure the evidence, such as the meteorological conditions today\n",
    "\n",
    "So the Bayes's rule in plain English is:\n",
    "\n",
    "${\\displaystyle\\begin{align}\n",
    "The\\ (posterior)\\\\\n",
    "probability\\ of\\ hypothesis\n",
    "\\\\ given\\ evidence\n",
    "\\end{align} =\n",
    "\\frac{\n",
    "\\begin{align}\n",
    "The\\ prior\\ probability && * && The\\ likelihood\\ of\\ evidence\\\\\n",
    "of\\ hypothesis && && given\\ the\\ hypothesis\n",
    "\\end{align}}{\\mathit{The\\ probability\\ of\\ evidence}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8310a6eb-0479-47b3-b417-0a67c477b872",
   "metadata": {},
   "source": [
    "Beta distribution can be used as a conjugate prior probability distribution for Bernoulli/binomial likelihood. But what is a conjugate prior?\n",
    "\n",
    "In Bayesian probability theory, if, given a likelihood function ${\\displaystyle p(x\\mid \\theta )}$, the posterior distribution ${\\displaystyle p(\\theta \\mid x)}$ is in the same probability distribution family as the prior probability distribution ${\\displaystyle p(\\theta )}$, the prior and posterior are then called conjugate distributions with respect to that likelihood function and the prior is called a conjugate prior for the likelihood function ${\\displaystyle p(x\\mid \\theta )}$.\n",
    "\n",
    "A conjugate prior is an algebraic convenience, giving a closed-form expression for the posterior; otherwise, numerical integration may be necessary. Further, conjugate priors may clarify how a likelihood function updates a prior distribution.\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Conjugate_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da9a4e2-e6af-4a8d-a7aa-34f5250b3d76",
   "metadata": {},
   "source": [
    "That explanation may seem to abstract, but we can clarify it with a concrete example.\n",
    "\n",
    "The question is,\n",
    "\n",
    "- We have a certain coin of a currency, denomination and vintage year.\n",
    "- We have prior knowledge of certain number of tosses resulting in $\\alpha - 1$  successes and $\\beta - 1$ failures, which can be used to model as a prior distribution of biases.\n",
    "- Now we collect new data with new tosses of the same coin, a total of $N$ tosses resulting in $z$ successes.\n",
    "- What is the posterior distribution of the biases?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae8e262-3174-4892-8f81-8d7874670ae3",
   "metadata": {},
   "source": [
    "The model will be as follows:\n",
    "\n",
    "- Let's model the prior distribution of biases $\\theta$ as a beta distribution: ${\\displaystyle beta(\\theta|\\alpha, \\beta)}$\n",
    "- The likelihood of the data for the range of bias values will be modeled by binomial distribution, normalized by the probability of data:\n",
    "  ${\\displaystyle \\frac {binom(z, N|\\theta)}{p(z,N)}}$\n",
    "- And the magic happens: The posterior distribution ${\\displaystyle beta(\\theta|\\alpha, \\beta)\\frac {binom(z, N|\\theta)}{p(z,N)}}$ is equal to\n",
    "${\\displaystyle beta(\\theta|\\alpha + z, \\beta + N - z)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b372f49-1b80-489e-a2dc-6b89f6c65dbd",
   "metadata": {},
   "source": [
    "So by using beta distribution as a conjugate prior distribution, to go from the prior to the posterior, we add $z$ to the $\\alpha$ parameter and\n",
    "$N - z$ to the $\\beta$ parameter of the prior distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cd655a-0d9c-45a7-93d3-05bf1d20580e",
   "metadata": {},
   "source": [
    "Let's confirm it by simulation. Let:\n",
    "- $\\alpha = 2$\n",
    "- $\\beta = 3$\n",
    "- $N = 4$\n",
    "- $z = 3$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b232cd1-c543-4b4b-889c-4665d4233b82",
   "metadata": {},
   "source": [
    "Get prior values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b43228-83e2-4225-8912-da4cd8fdf0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dprior <- dbeta(pvals, 2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abf874b-814a-4737-a08c-d54171ebfd4c",
   "metadata": {},
   "source": [
    "Get likelihood values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5480f7c2-e655-4fc7-88d2-8e8f52f59bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlhood <- prop.table(dbinom(3, 4, pvals)) * length(pvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f807e2-9225-467b-b217-4d88af8281ee",
   "metadata": {},
   "source": [
    "Get posterior values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0078c0-ab1b-480b-b73d-0c0c8376b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dposterior <- dbeta(pvals, 2+3, 3+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ccd880-3662-44ff-a736-737f51d13038",
   "metadata": {},
   "source": [
    "Plot priors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005a1d9d-a3f6-4622-aa60-86e9b02e81e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(pvals, dprior, type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d30d3e5-ff4c-4352-ae23-031aff405a5a",
   "metadata": {},
   "source": [
    "Plot likelihood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2793de-2584-463f-af40-a9ee698da402",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(pvals, dlhood, type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b530ee4b-3a00-4c40-9abc-c7ff38ca3e0d",
   "metadata": {},
   "source": [
    "And confirm the shape with $likelihood=posterior/prior$ identiy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73350b49-048e-4c70-8859-1d7f9bd4c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(pvals, dposterior/dprior, type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a9eb86-1eb2-4ec2-8db7-0104025357b5",
   "metadata": {},
   "source": [
    "Plot the posterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f007dd7-5da8-40bd-97f8-291bb5ff37fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(pvals, dposterior, type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432952ff-624f-41c7-bfa5-43a86d0642e0",
   "metadata": {},
   "source": [
    "Let's plot them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18426da-e834-4167-bc0f-49d557de020f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(pvals, dprior, type = \"l\", col = \"blue\", ylim = c(0, 2.5))\n",
    "lines(pvals, dlhood, col = \"red\")\n",
    "lines(pvals, dposterior, col = \"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a63364-5504-4749-84e1-cb69c7b7ed78",
   "metadata": {},
   "source": [
    "See that the <span style=\"font-weight:bold;color:black;\">posterior</span> is a compromise\n",
    "between <span style=\"font-weight:bold;color:blue;\">prior</span> and\n",
    "<span style=\"font-weight:bold;color:red;\">likelihood</span> \n",
    "\n",
    "So we start with a prior belief and update it with our new evidence to arrive at our posterior, the basis of Bayesian inference. Note that the posterior can serve as the prior for the next Bayesian updating with new evidence (e.g. new coin tosses).\n",
    "\n",
    "(Kruschke 2015, Doing Bayesian Data Analysis: A Tutorial with R, JAGS and STAN, p. 126-134)\n",
    "\n",
    "You can also play with the interactive app **Beta conjugate and binomial likelihood** under 06_prob_stat_2/apps with Shiny interface to simulate Bayesian updating with beta conjugate prior distribution. That is a very simple introduction to Bayesian modeling, which itself is based on simple main ideas. The beauty of this simplicity is very well summarized by Aubrey Clayton:\n",
    "\n",
    "> No professional hand-holding is necessary for Bayesian inference, outside \n",
    "of perhaps advising on what sorts of probability models might apply to cer-\n",
    "tain data-gathering procedures and what distributions would represent vari-\n",
    "ous states of knowledge. Once those are determined, the inferential process is \n",
    "automatic and simply consists of using Bayes’ theorem, as Jaynes and Richard \n",
    "Cox showed was required by the rules of consistent logical reasoning when \n",
    "expressed in probabilities. Because the frequentist methods sometimes violate \n",
    "these rules, they will necessarily sometimes produce illogical results.\n",
    "> ...\n",
    "> So, with one tool, we can handle \n",
    "these basic examples as well as the pathological ones, plus anything in between.\n",
    "But where do the problems facing working scientists actually fall on this\n",
    "\n",
    "(Clayton 2021, Bernoulli's Fallacy: Statistical Logic and the Crisis of Modern Science, p.239)\n",
    "\n",
    "and Ed Jaynes:\n",
    "\n",
    "> What the orthodox literature invariably fails to recognize is that all of these difficulties are\n",
    "resolved effortlessly by the uniform application of the single Bayesian method. In fact, once\n",
    "the Bayesian analysis has shown us the correct answer, one can often study it, understand\n",
    "intuitively why it is right, and, with this deeper understanding, see how that answer might\n",
    "have been found by some ad hoc device acceptable to orthodoxy.\n",
    "We shall illustrate this in later chapters by giving the solution to the aforementioned\n",
    ">\n",
    "> Our derivation showed that, from the standpoint of logic, the product rule (and therefore Bayes’\n",
    "theorem) expresses simply the associativity and commutativity of Boolean algebra. This is what\n",
    "gives us that greater freedom of action in calculations, leading in later chapters to the unrestricted\n",
    "use of Bayes’ theorem, in which we have complete freedom to move propositions back and forth\n",
    "between the left and right sides of our probability symbols in any way permitted by the product and\n",
    "sum rules. This is a superb computational device – and by far the most powerful tool of scientific\n",
    "inference – yet it is completely missing from expositions of probability theory based on the KSP (Kolmogorov System of Probability)\n",
    "work (which do not associate probability theory with information or inference at all).\n",
    "\n",
    "(Jaynes 2003, Probability Theory: The Logic of Science, p. 551,654)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3a935b-f490-4b1c-9d1f-07fff4963f16",
   "metadata": {},
   "source": [
    "# Higher moments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688bf933-b46b-49cc-8f21-e7953fa4d1dd",
   "metadata": {},
   "source": [
    "In probability theory and statistics, a central moment is a moment of a probability distribution of a random variable about the random variable's mean; that is, it is the expected value of a specified integer power of the deviation of the random variable from the mean.\n",
    "\n",
    "For a continuous univariate probability distribution with probability density function f(x), the n-th central moment of a real-valued random variable $X$ about the mean ($\\mu$) is:\n",
    "\n",
    "${\\displaystyle \\mu _{n}=\\operatorname {E} \\left[{\\left(X-\\operatorname {E} [X]\\right)}^{n}\\right]=\\int _{-\\infty }^{+\\infty }(x-\\mu )^{n}f(x)\\,\\mathrm {d} x.}$\n",
    "\n",
    "A standardized moment of a probability distribution is a moment (often a higher degree central moment) that is normalized, typically by a power of the standard deviation, rendering the moment scale invariant. The shape of different probability distributions can be compared using standardized moments.\n",
    "\n",
    "The standardized moment of degree n is ${\\displaystyle \\mu _{n}/\\sigma ^{n}}$ that is, the ratio of the n-th moment about the mean $\\mu _{n}$ to the n-th power of the standard deviation,:\n",
    "\n",
    "${\\displaystyle \\sigma ^{k}=\\mu _{2}^{k/2}=\\operatorname {E} \\!{\\left[{\\left(X-\\mu \\right)}^{2}\\right]}^{k/2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff94587e-0b1c-46ec-a632-8e8c6649add5",
   "metadata": {},
   "source": [
    "Moments are useful to define the shape of distributions.\n",
    "\n",
    "- Zeroth central moment and standardized moment are 1  since $x^0=1$\n",
    "- First central moment and standardized moment are by definition zero (average distance to mean is zero)\n",
    "- Second central moment is variance and second standardized moment is by definition 1 since central moment variance is divided by $\\sigma^2$ which is itself variance\n",
    "- Third and fourth moments are calculated as standardized moments and are denoted by $\\tilde {\\mu _n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e6e797-06ee-4f76-b255-4f7c9e3bf3e3",
   "metadata": {},
   "source": [
    "Third standardized moment is skewness, a measure of the asymmetry of the probability distribution of a real-valued random variable about its mean:\n",
    "\n",
    "${\\displaystyle {\\tilde {\\mu }}_{3}={\\frac {\\mu _{3}}{\\sigma ^{3}}}={\\frac {\\operatorname {E} \\left[(X-\\mu )^{3}\\right]}{\\left(\\operatorname {E} \\left[(X-\\mu )^{2}\\right]\\right)^{3/2}}}}$\n",
    "\n",
    "There are two kinds of skewness a distribution can have:\n",
    "\n",
    "- Negative skew: The left tail is longer; the mass of the distribution is concentrated on the right of the curve. The distribution is said to be left-skewed, left-tailed, or skewed to the left, despite the fact that the curve itself appears to be skewed or leaning to the right; left instead refers to the left tail being drawn out and, often, the mean being skewed to the left of a typical center of the data. A left-skewed distribution usually appears as a right-leaning curve.\n",
    "\n",
    "- Positive skew: The right tail is longer; the mass of the distribution is concentrated on the left of the figure. The distribution is said to be right-skewed, right-tailed, or skewed to the right, despite the fact that the curve itself appears to be skewed or leaning to the left; right instead refers to the right tail being drawn out and, often, the mean being skewed to the right of a typical center of the data. A right-skewed distribution usually appears as a left-leaning curve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a022dd-34e9-4ba8-9344-59178bce6c6e",
   "metadata": {},
   "source": [
    "Fourth standardized moment is kurtosis, the degree of “tailedness” in the probability distribution of a real-valued random variable. It is related to the tails of the distribution, not its peak. Higher kurtosis corresponds to greater extremity of deviations (or outliers), and not the configuration of data near the mean:\n",
    "\n",
    "${\\displaystyle {\\tilde {\\mu }}_{4}={\\frac {\\mu _{4}}{\\sigma ^{4}}}={\\frac {\\operatorname {E} \\left[(X-\\mu )^{4}\\right]}{\\left(\\operatorname {E} \\left[(X-\\mu )^{2}\\right]\\right)^{4/2}}}}$\n",
    "\n",
    "There are three types of kurtosis:\n",
    "\n",
    "- Distributions with zero excess kurtosis are called **mesokurtic**, or mesokurtotic. The most prominent example of a mesokurtic distribution is the normal distribution family, regardless of the values of its parameters.\n",
    "\n",
    "- A distribution with positive excess kurtosis is called **leptokurtic**, or leptokurtotic. A leptokurtic distribution has fatter tails. (\"Lepto-\" means \"slender\", originally referring to the peak. Examples of leptokurtic distributions include the Student's t-distribution, Rayleigh distribution, Laplace distribution, exponential distribution, Poisson distribution and the logistic distribution. Such distributions are sometimes termed super-Gaussian.\n",
    "\n",
    "- A distribution with negative excess kurtosis is called **platykurtic**, or platykurtotic. A platykurtic distribution has thinner tails. (\"Platy-\" means \"broad\", originally referring to the peak. Examples of platykurtic distributions include the continuous and discrete uniform distributions, and the raised cosine distribution. The most platykurtic distribution of all is the Bernoulli distribution with p = 1/2 (for example the number of times one obtains \"heads\" when flipping a coin once, a coin toss), for which the excess kurtosis is −2.\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Central_moment)\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Standardized_moment)\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Skewness)\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Kurtosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa547018-7569-48b6-a716-9843d206be19",
   "metadata": {},
   "source": [
    "We can calculate empirical moment values from the data using the above definitions or theorerical moments from the distribution parameters using their closed formed formulas.\n",
    "\n",
    "For example, for beta distribution, skewness is defined as:\n",
    "\n",
    "${\\displaystyle \\gamma _{1}={\\frac {\\operatorname {E} \\left[\\left(X-\\mu \\right)^{3}\\right]}{\\left(\\operatorname {var} (X)\\right)^{3/2}}}={\\frac {2\\left(\\beta -\\alpha \\right){\\sqrt {\\alpha +\\beta +1}}}{\\left(\\alpha +\\beta +2\\right){\\sqrt {\\alpha \\beta }}}}.}$\n",
    "\n",
    "And, excess kurtosis, defined as kurtosis minus 3, is defined as:\n",
    "\n",
    "${\\displaystyle {\\begin{aligned}{\\text{excess kurtosis}}&={\\text{kurtosis}}-3\\\\&={\\frac {\\operatorname {E} [(X-\\mu )^{4}]}{(\\operatorname {var} (X))^{2}}}-3\\\\&={\\frac {6[(\\alpha -\\beta )^{2}(\\alpha +\\beta +1)-\\alpha \\beta (\\alpha +\\beta +2)]}{\\alpha \\beta (\\alpha +\\beta +2)(\\alpha +\\beta +3)}}.\\end{aligned}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b982c8-e1b3-4a99-8ae5-09e16d9a1e36",
   "metadata": {},
   "source": [
    "## Skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ee486b-d7b6-4b0d-abff-97d3af7f25a4",
   "metadata": {},
   "source": [
    "Let's first explore beta distributions with different skewness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5857003b-4ef1-4ad7-951f-b94d1b1353c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qvals2 <- seq(0, 1, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9f5779-cad6-469f-b3c0-2fbeff6ca0ac",
   "metadata": {},
   "source": [
    "### Positive skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3190d418-2d22-4931-be25-bd6b0958efef",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 <- 3\n",
    "b1 <- 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d33f7-ec4b-4623-b87b-dead83b2c384",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(qvals2, dbeta(qvals2, a1, b1), type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c70fbf-9250-4bed-933b-5214728ae927",
   "metadata": {},
   "source": [
    "The distribution is right-skewed or positive skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3804bf-bce1-4151-8763-b0148abac78d",
   "metadata": {},
   "source": [
    "The theoretical skewness value is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4eb53b-5041-4f03-b936-3cfa39b44c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(2*(b1-a1)*sqrt(a1+b1+1)) / ((a1+b1+2)*sqrt(a1*b1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3540fc20-5fcf-4867-9ba2-c9f0905d23c4",
   "metadata": {},
   "source": [
    "Or easier by using `estimators` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfae7a47-e244-4ea1-876c-52b5b7a19367",
   "metadata": {},
   "outputs": [],
   "source": [
    "db1 <- Beta(a1,b1)\n",
    "skew(db1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc08116-aa17-4190-bb9b-dfc483c30a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew(db1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02832a82-db99-44a4-a284-a9e467e93b85",
   "metadata": {},
   "source": [
    "Let's create a sample and calculate empirical skewness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0b7237-a27d-45e5-8850-8fbb470f7137",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssize <- 1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf4be97-864a-4460-8aa9-06dddf4484a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "sampb1 <- rbeta(ssize, a1, b1)\n",
    "hist(sampb1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f16ac2-ed9b-41a2-9e14-cbb0ed942be7",
   "metadata": {},
   "source": [
    "Mean and (population) standard deviation reversed for Bessel correction are calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb3c332-59c0-462e-b11b-9650a0d9be5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanb1 <- mean(sampb1)\n",
    "sdb1 <- sd(sampb1)*sqrt((ssize - 1)/ssize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987113e4-3d06-45f0-b52a-168d1ac40b11",
   "metadata": {},
   "source": [
    "The skewness is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30afba07-cac4-4318-8a42-1034fc058825",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean((sampb1 - meanb1)^3) / (sdb1)^3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed9aa57-fbf1-4b20-8f07-679b038dee16",
   "metadata": {},
   "source": [
    "Or easier by using `moments` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2e7fd3-9e3b-458f-a67d-c8e4d8121e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness(sampb1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde3083a-633a-45d1-89b1-8e2c26c7755c",
   "metadata": {},
   "source": [
    "The skewness value is positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331452a9-cfb7-4859-9a7b-084d1f06be9d",
   "metadata": {},
   "source": [
    "### Negative skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de4d408-86f5-4730-82b9-bb531e8a08a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 <- 10\n",
    "b2 <- 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9eb394-15b4-4600-9bbd-4fa622867e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(qvals2, dbeta(qvals2, a2, b2), type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34993c2c-684f-44cb-878e-f911a6a4b7b3",
   "metadata": {},
   "source": [
    "The distribution is left-skewed or negative skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e81986c-980e-49a7-8c0b-af09bfa1e2dd",
   "metadata": {},
   "source": [
    "The theoretical skewness value is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14375dd7-57ba-481b-aa43-44575dc3739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(2*(b2-a2)*sqrt(a2+b2+1)) / ((a2+b2+2)*sqrt(a2*b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db333aae-351d-44a5-a255-26874b3884d2",
   "metadata": {},
   "source": [
    "Or easier by using `estimators` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8131f714-07c5-42fd-bb16-f6f925823a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "db2 <- Beta(a2,b2)\n",
    "skew(db2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e43c3d-f9aa-4933-a178-0d4fb4aaaf01",
   "metadata": {},
   "source": [
    "Let's create a sample and calculate empirical skewness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cb24be-f305-4c5f-b576-2199df3c4dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssize <- 1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26a113e-2f70-4f8e-85d9-99963a50d563",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "sampb2 <- rbeta(ssize, a2, b2)\n",
    "hist(sampb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb77ed9-1461-407e-a73e-10b52ee3c1c4",
   "metadata": {},
   "source": [
    "Mean and (population) standard deviation reversed for Bessel correction are calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b436d10e-3f1e-4a80-be96-f6ee2c53eabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanb2 <- mean(sampb2)\n",
    "sdb2 <- sd(sampb2)*sqrt((ssize - 1)/ssize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbd1154-c9b0-4653-897f-e94fb0e6727c",
   "metadata": {},
   "source": [
    "The skewness is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db2bb89-ceed-4c3d-ae69-8d5305df9b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean((sampb2 - meanb2)^3) / (sdb2)^3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a47e717-a31d-4fb8-8490-dffb2af19d69",
   "metadata": {},
   "source": [
    "Or easier by using `moments` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b9bc23-c08d-44ca-a39f-40210f6ee701",
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness(sampb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b87b46e-c961-4353-af84-a591d7fcb1e4",
   "metadata": {},
   "source": [
    "The skewness value is negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2a9449-3f7a-4248-a5a7-dad114ecaf20",
   "metadata": {},
   "source": [
    "## Kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cfd0ca-24f4-495b-a010-e506909aaedc",
   "metadata": {},
   "source": [
    "### Leptokurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad92a010-ce81-4390-b1a2-5a96b275fdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a3 <- 50\n",
    "b3 <- 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbed794f-0964-4bbf-80e9-1263bb55d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(qvals2, dbeta(qvals2, a3, b3), type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb658977-b019-4174-8834-0f67acc4285c",
   "metadata": {},
   "source": [
    "The distribution is leptokurtic, more extreme values in the tails, compared to the standard deviation of the distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e7fb3a-1c0c-424b-8693-c9036051caa5",
   "metadata": {},
   "source": [
    "The theoretical excess kurtosis value is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4e4f47-25f5-423a-97b0-c6e5f9cd84e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "6*((a3 - b3)^2 * (a3 + b3 + 1) - a3*b3 * (a3 + b3 + 2)) / (a3 * b3 * (a3 + b3 + 2) * (a3 + b3 + 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7abcc93-2dde-4d2e-910f-a8becbd92641",
   "metadata": {},
   "source": [
    "Let's create a sample and calculate empirical kurtosis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0860ee8-569c-43f7-9cfa-89d8cbe14a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssize <- 1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42a41e2-e658-4813-b1f2-f108cc76490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "sampb3 <- rbeta(ssize, a3, b3)\n",
    "hist(sampb3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6a60e7-0ead-42e7-b43e-30adc21fda78",
   "metadata": {},
   "source": [
    "Mean and (population) standard deviation reversed for Bessel correction are calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2d43aa-6a01-4707-a12b-bf19cbf6ac5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanb3 <- mean(sampb3)\n",
    "sdb3 <- sd(sampb3)*sqrt((ssize - 1)/ssize)\n",
    "meanb3\n",
    "sdb3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcda46a9-4bef-4912-8387-bd00feb8b290",
   "metadata": {},
   "source": [
    "The highest values that contribute to the kurtosis are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7555043c-e6a8-43ef-8f98-2c53bc9facfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort((sampb3 - meanb3)^4, decreasing = T)[1:10] / (sdb3)^4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce59b545-ad83-4d47-9b07-232296a1f9e4",
   "metadata": {},
   "source": [
    "The excess kurtosis value is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e166a37e-0055-4547-8473-e992e400ef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean((sampb3 - meanb3)^4) / (sdb3)^4 - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eced0ad8-11ea-41cc-976e-897f2404e430",
   "metadata": {},
   "source": [
    "Or easier by using `moments` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de17c56-f564-4889-bdf2-ffd1e754adf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kurtosis(sampb3) - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3ad5d5-ec3f-4999-af43-3ddb46e97194",
   "metadata": {},
   "source": [
    "The excess kurtosis is positive, distribution has fatter tails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b674a58e-a06b-4587-8329-741218c6f957",
   "metadata": {},
   "source": [
    "### Platykurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0bcfea-5719-4068-90d5-9200d41f453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a4 <- 1.5\n",
    "b4 <- 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6e72ec-434e-430f-806a-b6f298e5bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(qvals2, dbeta(qvals2, a4, b4), type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d29445e-c9d5-4e42-affb-07a2a3a4bbff",
   "metadata": {},
   "source": [
    "The distribution is platykurtic, less extreme values in the tails, compared to the standard deviation of the distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bda2ed-b890-4620-9e1b-18f2ef56355b",
   "metadata": {},
   "source": [
    "The theoretical excess kurtosis value is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdc1347-19a2-45f0-90c5-688cec2290f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "6*((a4 - b4)^2 * (a4 + b4 + 1) - a4*b4 * (a4 + b4 + 2)) / (a4 * b4 * (a4 + b4 + 2) * (a4 + b4 + 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fb3117-d81a-430c-a07f-623e16011428",
   "metadata": {},
   "source": [
    "Let's create a sample and calculate empirical kurtosis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a0d508-4aa2-48cd-87cf-f7b78c082adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssize <- 1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce43fa92-39ea-469f-9566-15fd3b9af926",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "sampb4 <- rbeta(ssize, a4, b4)\n",
    "hist(sampb4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af1d68b-11fd-4723-88d6-e1b7dae0a023",
   "metadata": {},
   "source": [
    "Mean and (population) standard deviation reversed for Bessel correction are calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fd2b73-61c5-41d0-8296-7a48bc3665e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanb4 <- mean(sampb4)\n",
    "sdb4 <- sd(sampb4)*sqrt((ssize - 1)/ssize)\n",
    "meanb4\n",
    "sdb4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050ed799-69f0-462c-b146-999a2b69e673",
   "metadata": {},
   "source": [
    "The highest values that contribute to the kurtosis are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea869df-b7c3-40c3-9252-b500f43845aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort((sampb4 - meanb4)^4, decreasing = T)[1:10] / (sdb4)^4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6ec352-9cb8-4576-a810-e30c26f82ebe",
   "metadata": {},
   "source": [
    "The excess kurtosis value is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a463f80-b36c-4338-a91c-9af075e8bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean((sampb4 - meanb4)^4) / (sdb4)^4 - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eda733f-f4ad-45fe-9f38-a006813bc79c",
   "metadata": {},
   "source": [
    "Or easier by using `moments` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa5d60f-61af-4515-82bd-bfd401d99e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "kurtosis(sampb4)  - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bce0570-cbfc-4cc2-b31a-9bdadb93e5d7",
   "metadata": {},
   "source": [
    "The excess kurtosis is negative, the distribution has flatter tails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82c80ed-4780-4c04-bca8-7aa561912015",
   "metadata": {},
   "source": [
    "You can also play around with **Higher Moments of Beta Distribution** app under 06_prob_stat_2/apps with Shiny interface to see how skewness and kurtosis changes with different $\\alpha$ and $\\beta$ parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a74254-7673-4f4a-8561-ef36178f3034",
   "metadata": {},
   "source": [
    "# Uniform distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9a5e35-465d-4571-bc5c-16763f83ff00",
   "metadata": {},
   "source": [
    "The two basic physical tools that we simulated at the beginning of the probability sessions are coin and dice. Provided that they are fair, all possible values in the sample space has the same probability, and hence they are equiprobably:\n",
    "\n",
    "- Each side to a fair coin has a 1/2 probability of occuring\n",
    "- Each side to a fair die has a 1/6 probability of occuring\n",
    "\n",
    "If we increase the number of the sides to a fair die - still keeping it fair - we will have more possible values $n$ each with a probability of $1/n$. In the limit we will have a perfect sphere dropped on a perfectly flat surface, so that any one of the $\\infty$ points on the sphere has the same equal probability of $1/\\infty=0$ while the total sample space $\\Omega$ has a probability of 1. So the equiprobable discrete distribution converges to a continuous distribution.\n",
    "\n",
    "Uniform distribution describes an experiment where there is an arbitrary outcome that lies between certain bounds. The bounds are defined by the parameters, ${\\displaystyle a}$ and \n",
    "${\\displaystyle b,}$ which are the minimum and maximum values. The difference between the bounds defines the interval length; all intervals of the same length on the distribution's support are equally probable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a28d1-17e3-46c2-aa29-c64b88e6e0c1",
   "metadata": {},
   "source": [
    "The probability density function for uniform distribution is:\n",
    "\n",
    "${\\displaystyle f(x)={\\begin{cases}{\\dfrac {1}{b-a}}&{\\text{for }}a\\leq x\\leq b,\\\\[8pt]0&{\\text{for }}x<a\\ {\\text{ or }}\\ x>b.\\end{cases}}}$\n",
    "\n",
    "Expected value is:\n",
    "\n",
    "${\\displaystyle \\operatorname {E} [X]={\\frac {b+a}{2}}}$\n",
    "\n",
    "Variance is:\n",
    "\n",
    "${\\displaystyle \\operatorname {Var} [X]={\\frac {(b-a)^{2}}{12}}}$\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Continuous_uniform_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9739fc5a-d110-4357-b9c0-2564c6ea3dfa",
   "metadata": {},
   "source": [
    "Let's get some samples from the standard uniform distribution with a support in the open interval (0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74c4bff-6939-4f5c-8b15-3f8299b18532",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(70)\n",
    "unisamp <- runif(1e4, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e54ad9-a33c-404d-9ee0-8bcff886445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(unisamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f089cc-5771-49fd-9121-35530443640c",
   "metadata": {},
   "source": [
    "Theoretical mean is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72fddcf-26a4-43b8-b8e7-e569eeb208d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(0+1)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c783b9-05ac-4a66-a526-63c5238b74ca",
   "metadata": {},
   "source": [
    "While the sample mean is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c42764-5df7-47e1-8c98-f540e5349e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(unisamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e805d47b-dcdd-4475-8c16-9ffc1ef9e90d",
   "metadata": {},
   "source": [
    "Theoretical variance is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d820e73-2d47-4b8e-b6fd-65e4e00014f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 - 0)^2 / 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4703d6d-c821-4599-9a54-d0f3dd904184",
   "metadata": {},
   "source": [
    "While the sample variance is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319db8c9-ad6f-4fd8-990c-0392ef0057fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(unisamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3525cc-de26-4fad-9b75-5e36060c34db",
   "metadata": {},
   "source": [
    "A useful aspect of standard uniformly distributed sample is that it can be used to be converted to samples of any distribution using the quantile functions, since basically every probability distributions CDF lies between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e34aff-1d6f-430d-9c6c-16ea5ffd88b6",
   "metadata": {},
   "source": [
    "So for example the standard uniform sample can be converted to a sample of beta values with parameters 0.5 and 0.5 (which is known as Jeffrey's prior from Harold Jeffrey):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a304202-4bd3-4f2d-848c-8c34664ab545",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(qbeta(unisamp, 0.5, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292d72df-26d4-41e3-a3fe-053b008631e4",
   "metadata": {},
   "source": [
    "Confirm with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4dd864-620d-4e41-97da-db93a77a260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(75)\n",
    "hist(rbeta(1e4, 0.5, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5d034e-7d44-475c-814d-51db3e582af4",
   "metadata": {},
   "source": [
    "Poisson with a rate of 20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e3cb45-37a4-4a57-b521-d14608d3e999",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(qpois(unisamp, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61a778a-64ac-480c-a76a-929bdebd7016",
   "metadata": {},
   "source": [
    "Confirm with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1b3e6c-aca1-42cd-ad59-7f7c552616d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(76)\n",
    "hist(rpois(1e4, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775f2466-08a0-4d56-b60a-c5a9b72e2d91",
   "metadata": {},
   "source": [
    "We will use uniform distribution to demonstrate central limit theorem later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379a0e97-ab48-44d9-b75a-8f61289182df",
   "metadata": {},
   "source": [
    "# Exponential distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b1cb37-95c0-4634-83c4-b87f20f15933",
   "metadata": {},
   "source": [
    "The exponential distribution is the probability distribution of the distance between events in a Poisson point process, i.e., a process in which events occur continuously and independently at a constant average rate.\n",
    "\n",
    "The distance parameter could be any meaningful mono-dimensional measure of the process, such as time between production errors, or length along a roll of fabric in the weaving manufacturing process.\n",
    "\n",
    "It is the continuous analogue of the geometric distribution, and it has the key property of being memoryless.\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Exponential_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ce3879-baba-4fb5-9905-ed9e845ff700",
   "metadata": {},
   "source": [
    "As you may recall from geometric distribution, the probabilities of successive discrete values in the probability mass function decay at a constant rate: The ratio between two successive values is always the same.\n",
    "\n",
    "Since exponential distribution is the continuous analogue of geometric distribution, the rate of change between the probabilities of equally spaced values in probability density fuction is always the same. To illustrate let's make the log transformation because log transformation converts the division in rate of change calculation to a difference operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ffdeb4-a18d-464e-8f84-c138469679d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff(log(dexp(0:10, 1/2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e6618e-e565-4036-a6ea-884623ef817e",
   "metadata": {},
   "source": [
    "The density is plotted as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea58132-4d12-4daf-a829-d2b5fdd10ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(dexp(seq(0, 10, 0.1), 1/2), type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d522b26-fdb5-4fad-b093-944c88ad017d",
   "metadata": {},
   "source": [
    "While the log density is a linear shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4b33c5-1f04-4b80-8d8f-6dff0b5fb127",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(log(dexp(seq(0, 10, 0.1), 1/2)), type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18a790c-8487-486a-b5cf-702064910a61",
   "metadata": {},
   "source": [
    "Which is quite obvious since logarithm is the inverse of exponentiation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de3fbaa-802c-497b-a5a8-182f62d8ee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log(exp(0:10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18496d8b-654f-413f-9c10-4ac2b38a412c",
   "metadata": {},
   "source": [
    "The mean or expected value of an exponentially distributed random variable $X$ with rate parameter $\\lambda$ is given by:\n",
    "\n",
    "${\\displaystyle \\operatorname {E} [X]={\\frac {1}{\\lambda }}}$\n",
    "\n",
    "The variance of $X$ is given by\n",
    "\n",
    "${\\displaystyle \\operatorname {Var} [X]={\\frac {1}{\\lambda ^{2}}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4158c4-8e57-4c15-8d97-2e0ae1835cad",
   "metadata": {},
   "source": [
    "We will first simulate a disrete version of a Poisson point process with Bernoulli trials to show that the geometric waiting times between consecutive successes converge to an exponential distribution.\n",
    "\n",
    "And then do the reverse, sample waiting times from an exponential distribution and show that the event counts form a Poisson point process and obey the Poission distribution.\n",
    "\n",
    "Exponential distribution is useful for describing wealth distribution inequalities. We will make a simple agent-based simulation of fair trade in an economy and see how laws of nature drive the wealth distribution towards inequality in the form of an exponential distribution.\n",
    "\n",
    "Exponential distribution is also a critical tool in survival analysis cases where the hazard rate is assumed to be constant. So in the end of the section, we will simulate a hypothetical living population with a constant mortality rate and show that the life expectancy obeys an exponential distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2eca5c-f537-49dd-8094-e486b6fb4eca",
   "metadata": {},
   "source": [
    "## Poisson process simulation from Bernoulli trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7c74a1-4f9e-4411-80ce-31f97432fc28",
   "metadata": {},
   "source": [
    "We know that when the number of trials is large and the probability of success is low, binomial distribution converges to Poisson distribution. For this reason, we will simulate 1e7 Bernoulli trials with a success probability of 0.5%. To show convergence to Poisson, we will treat each 1e3 trials as a unit interval so the expected rate of success is 5.\n",
    "\n",
    "So these 1e7 trials are supposed converge to 1e4 Poisson samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641e79a9-4adf-46f1-8ec4-071d9d6ae9a6",
   "metadata": {},
   "source": [
    "1e7 Bernoulli trials with a success probability of 0.5%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cc0f96-f1fb-4ee5-905f-c1bd85133068",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2)\n",
    "bernpois <- rbinom(1e7, 1, 5/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06832cc8-b895-4565-98fa-cc3e6f48bb1f",
   "metadata": {},
   "source": [
    "Check total number of successes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b01d666-cd79-4e3e-87c3-a680b2cc6206",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(bernpois)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa43ca8-dfa5-4463-8d97-85cf515ece33",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fee06cee-7023-48a7-b805-24a9b499a0ea",
   "metadata": {},
   "source": [
    "Since each 1e3 trial is considered an interval, we assume to have sampled 1e4 Poisson counts with a rate of 5.\n",
    "\n",
    "Let's check whether two distributions converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8945c25e-71bd-4c1f-a8e1-941318713d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(3)\n",
    "samppois <- rpois(1e4, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f282d22-ec45-4d03-bdba-e9f2f6d1ecb3",
   "metadata": {},
   "source": [
    "Check the number of successes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61719023-1150-4c3c-a958-1e47c5c7e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(samppois)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5df46a8-ba8a-426e-a3df-40114ed32220",
   "metadata": {},
   "source": [
    "And the historgram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52b2213-d430-4f28-8d88-cb2c9504d976",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(samppois)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9132d267-a59f-45ba-a1ec-932039e669b5",
   "metadata": {},
   "source": [
    "Now let's treat 1e7 trials as a matrix of 1e3 columns (for each interval) and 1e4 samples, and get the counts for each interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20009629-812e-4f69-a0d9-774acde604d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "samppois2 <- rowSums(matrix(bernpois, ncol = 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18c6333-33e5-434a-be17-d6c6697bdcfb",
   "metadata": {},
   "source": [
    "And see the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4aaec2-6f38-4f83-b67c-4ccc31d34477",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(samppois2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7cc660-eea9-4c4f-a15b-eafb2fea2187",
   "metadata": {},
   "source": [
    "Histograms reveal convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376d43e7-f9e1-4948-80b7-dbd6dac9b64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(prop.table(table(samppois2)), type = \"l\", col = \"red\")\n",
    "lines(0:20, dpois(0:20, 5), col = \"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5600beb9-e402-427f-a550-0125a8c09e97",
   "metadata": {},
   "source": [
    "Line plots of relative counts also confirm the convergence: Our discrete Bernoulli trials, compressed into 1000 trial intervals converge to Poisson distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4856efb1-5e90-444a-a347-e11836d29181",
   "metadata": {},
   "source": [
    "Poisson point process is the sequence of events arrival times of which are exponentially distributed.\n",
    "\n",
    "To see that discrete geometric arrival times converge to continuous exponential distribution, we will treat the sequence of discrete Bernoulli trials as a continuous Poisson point process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6106e98f-1833-4a78-af56-e2698161baec",
   "metadata": {},
   "source": [
    "Now, in order to calculate the failure lengths or arrival times, we will compress the data in the run lengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4513fbec-08b6-4511-b8fa-690a4ed7f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernpoisrl <- rle(bernpois)\n",
    "setDT(bernpoisrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b09a7e1-747c-437a-9aa4-a2af461f08f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernpoisrl %>% head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b99e3a-b9bc-483d-8640-65732778bc39",
   "metadata": {},
   "source": [
    "Get the non-zero waiting times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4df3a6-c651-431f-b116-1ee446dc5061",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernpois_wt <- bernpoisrl[values == 0, lengths]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd5d2a1-23cf-4bb3-82ad-d8f6c2900936",
   "metadata": {},
   "source": [
    "And calculate the total number of zero waiting times as sum of decremented run lengths of successes. So if there is a run length of 3 successes, we have 2 zero length waiting times in between:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62c8b03-cb08-4519-87a7-b49db30d40a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nzero <- bernpoisrl[values == 1, sum(lengths - 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b33fcb-510d-47f3-acad-785f671de408",
   "metadata": {},
   "source": [
    "We combine all zero and non-zero waiting times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c03e48-1dee-4e8d-a6e9-b30cba4c168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernpois_wt2 <- c(bernpois_wt, rep(0, nzero))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f62eb5-c13a-4a65-a8a8-9e8f107008de",
   "metadata": {},
   "source": [
    "And convert the discrete waiting times to continuous ones such that 1000 trials make up an interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5f12b4-3606-444b-a401-f7e489461634",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernpois_wt3 <- bernpois_wt2 / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f48967-3d6c-491d-8002-e29e02ef77bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "length(bernpois_wt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0386de-e8fe-4b4c-9b2f-3ab7273eec15",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(bernpois_wt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce12d72-b5b9-4757-929f-98d2c4dda615",
   "metadata": {},
   "source": [
    "See the distribution of waiting times extracted from discrete Bernoulli trials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7ffcc4-a02d-4e24-8ec2-b3303df0d638",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(bernpois_wt3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93695ef3-8033-4ed2-9b07-391353fae870",
   "metadata": {},
   "source": [
    "Variance is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53611176-c534-4238-8050-dc2fe6b6c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(bernpois_wt3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6564ea-05b4-4123-8dcb-2ee733f11e7a",
   "metadata": {},
   "source": [
    "Mean is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1038e8ad-453d-4327-8859-1b71c13a3d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(bernpois_wt3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184f542d-548e-42c1-8576-096a94e413f1",
   "metadata": {},
   "source": [
    "Now let's sample 5e4 values from an exponential distribution with a rate of 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1044b7f4-3deb-49a6-9807-e83ab08aca05",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(3)\n",
    "sampexp <- rexp(5e4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412bfb6b-b1da-4427-ba60-bb4dc7c040a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(sampexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47589752-8402-46bf-8718-540cbe6bf479",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(sampexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a72a9f-5753-47f4-b919-dad42df3991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(sampexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9590f029-69c9-4c08-b96c-786df7942394",
   "metadata": {},
   "source": [
    "Theoretical mean of geometric distribution with a p of 5/1000 and converted from a count to a rate by dividing by 1000 is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5004be38-d198-42c8-89aa-95013ade82a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "((1 - 5/1000) / (5 / 1000))/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ae011d-7459-43ab-b2d0-146d8e9bda77",
   "metadata": {},
   "source": [
    "Theoretical variance of geometric distribution with a p of 5/1000 and converted from the scale of counts to the scale of rates by dividing by 1000^2 is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33142536-bede-43d8-b946-6ada70341994",
   "metadata": {},
   "outputs": [],
   "source": [
    "((1 - 5/1000) / (5 / 1000)^2)/1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0399d5c0-2a6e-4616-85d7-0c5df6c528cc",
   "metadata": {},
   "source": [
    "The theoretical mean of exponential distribution with a rate of 5 is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d304d1df-7be8-492b-b09f-aed6706256b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "1/5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9031cda0-eca7-4349-8113-27c4d23be00a",
   "metadata": {},
   "source": [
    "And the theoretical variance is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc3cc73-5314-4347-b6f6-6fdf8807ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "1/5^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb05de33-1422-42e6-8b60-f4f7d7c23945",
   "metadata": {},
   "source": [
    "And last, let's compare the densities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97247140-6613-4513-8181-110c67fadc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpd <- density(bernpois_wt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e29a294-62e7-4494-b0cb-8e7b318b1ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpd2 <- density(sampexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0993c7-cae1-46a9-b60a-c73df10db239",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpd_s <- as.data.table(bpd[c(\"x\", \"y\")])[x >= 0.03]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fae585-323d-4f08-a174-dac8640348c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpd2_s <- as.data.table(bpd2[c(\"x\", \"y\")])[x >= 0.03]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7f81c7-0c49-45ca-bfdf-4f1cd4ee32fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(bpd_s, type = \"l\", col = \"blue\")\n",
    "lines(bpd2_s, col = \"red\")\n",
    "lines(seq(0, 2, length.out = 101), dexp(seq(0, 2, length.out = 101), 5), col = \"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b501e7a5-900c-49cb-b07d-0291d190d309",
   "metadata": {},
   "source": [
    "The empirical densities we get\n",
    "\n",
    "- From Bernoulli trials with a p of 0.5% and 1000 trials compressed into an interval\n",
    "- From simulations from exponential distribution with a rate of 5\n",
    "- And theoretical exponential distribution with a rate of 5\n",
    "\n",
    "all overlap perfectly!\n",
    "\n",
    "So we see that exponential distribution can be derived empirically from simple discrete Bernoulli trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca737b8-5cc7-4bd0-b0c1-1ea4e545a2d1",
   "metadata": {},
   "source": [
    "## Poisson process simulation from exponential distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826f5949-da4a-40c4-8b2c-277783582634",
   "metadata": {},
   "source": [
    "We have demonstrated that, Bernoulli trials with a low probability and high trial number converge to a Poisson distribution and the discrete waiting times with geometric distribution converge to exponential distribution.\n",
    "\n",
    "Now we will do the continuous analogue from the other way around: We will sample continuous waiting times for a Poisson point process from an exponential distribution and show that the counts form a Poisson distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d747af0-2ca3-4949-8063-d4fa6392a8db",
   "metadata": {},
   "source": [
    "We reuse the same code to create the exponentially distributed sample from previous section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d582e1bd-c97f-498f-9c1d-7938f2ac663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(3)\n",
    "sampexp <- rexp(5e4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b774fa-0a08-414d-9c70-03e77a512d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(sampexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1174dc08-3f52-430c-8c4b-bf5baadf7120",
   "metadata": {},
   "source": [
    "Variance and mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3652e9b-bab6-4b4c-bddb-1d133014cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(sampexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9696190d-99a3-4e2b-a41a-7414b4e362fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(sampexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ed5f06-5690-4d21-aba4-8e6833c52636",
   "metadata": {},
   "source": [
    "And total time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb510687-7ca4-4995-814e-3943f1d33c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(sampexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98553a1-d195-48f7-aeb2-91ce1b433496",
   "metadata": {},
   "source": [
    "We first get the cumulative sum of waiting times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a64b01a-6ab1-4c21-8e73-a002490935c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampexpc <- cumsum(sampexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832a9c8c-4550-40b6-9dd3-4953c03405fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(sampexpc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c610adf5-f954-4842-9da5-9552c312a2ec",
   "metadata": {},
   "source": [
    "Then we wrangle the data to get the distribution of the number of events per 1 interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6f28d4-2564-495c-80fe-00815ce075c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts1 <- sapply(split(sampexpc, round(sampexpc)), length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda2d8b2-9790-40dc-8430-c062bb14019b",
   "metadata": {},
   "source": [
    "Confirm the sum of counts is equal to the number of points created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3183906-2c25-42c5-afe8-525ea25a0a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(counts1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcde51a-50af-4264-ad9a-f7640196676d",
   "metadata": {},
   "source": [
    "Get the time intervals with no points until:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd5b83c-0060-4243-bbe9-dad10583d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(max(sampexpc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4492f6f-a2b7-4d73-aeec-038f0fd959dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "zerocounts <- setdiff(0:round(max(sampexpc)), as.integer(names(counts1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e01c26f-8032-482b-8c8c-b3f074ad3fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "zerocounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e7ebe9-d4ff-4c8a-a9ed-29bced3b6911",
   "metadata": {},
   "source": [
    "Augment the counts with zero count intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be26d0-09c3-4e0c-8f09-c7e17fc7cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts1b <- c(counts1, rep(0, length(zerocounts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75897d1e-3886-4708-b3c7-060a0aeefd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "length(counts1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b275b0-d3ef-44c8-b500-d3423a5a6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(counts1b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ab966-7253-4b59-8b56-df73e84b1f96",
   "metadata": {},
   "source": [
    "The contingency table of counts itself reveals a Poisson distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4498b26-e197-43be-8219-fdb7536538b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "countst1 <- table(counts1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851adf3b-b6e0-41db-9db2-121839388d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "countst1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b58e4c-d32c-4828-890b-c968733e5beb",
   "metadata": {},
   "source": [
    "And also the histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34a8c10-c0ea-474a-bd9a-2d09fa813a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(counts1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd8dac5-786b-4311-9e39-3fb5cf6e2cdf",
   "metadata": {},
   "source": [
    "And compare the PMF of the simulated counts and Poisson distribution with a rate of 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51bde95-2679-4eb1-9bd1-fc4480c563f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(prop.table(countst1), type = \"l\", col = \"blue\")\n",
    "lines(0:20, dpois(0:20, 5), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea75a89c-6659-4ac6-97f7-62322a2e3d6f",
   "metadata": {},
   "source": [
    "They almost totally overlap! So the Poisson point process with waiting times from an exponential distribution with a rate of 5 events per unit interval results in a count distribution from a Poisson distribution with a rate of 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a6f404-1492-4018-9f78-d48433f99012",
   "metadata": {},
   "source": [
    "The empirical mean and variance of the count distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdc4bc2-866a-420f-9e1b-3232b3ed0d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(counts1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f3f318-6346-4735-8ab2-ace9db15f1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(counts1b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f37528-06a2-4c0a-a8be-7882a0c9ed2a",
   "metadata": {},
   "source": [
    "Is in line with theoretical mean and variance of a Poisson distribution with rate 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b30221b-dea4-4eaa-bbd6-46a476eb4b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(Pois(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f901a1-dd4e-434f-9df2-3b5bf34bb337",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(Pois(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06733463-9448-48fa-9d8c-8a1d20712399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80828bb6-f8ff-4c78-a8bd-f4cf3dc98efc",
   "metadata": {},
   "source": [
    "Now let's use the same waiting times to get the counts of successes or events per 10 time interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c94f24-ed68-48b8-a9c8-0853ef2d88ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampexpc10 <- sampexpc / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cda16f7-6579-4d69-a3dd-2637eb027ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts10 <- sapply(split(sampexpc10, round(sampexpc10)), length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be513a7-1771-43f9-8948-d0f9f88badf7",
   "metadata": {},
   "source": [
    "Confirm the sum of counts is equal to the number of points created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b7f1c0-4de2-4030-a04d-cf06e69dbaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(counts10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeeef05-e3c0-4db5-8354-4a6f5932e4a6",
   "metadata": {},
   "source": [
    "Get the time intervals with no points until:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138b2003-cf99-4a56-95bc-2e4433183da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(max(sampexpc10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25164835-bd2b-4e03-9eae-62870785f399",
   "metadata": {},
   "outputs": [],
   "source": [
    "zerocounts10 <- setdiff(0:round(max(sampexpc10)), as.integer(names(counts10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9fdea7-d84c-4385-a883-dcc4322bc6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "zerocounts10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c8a7ad-4ea8-42bc-95ef-4f8ac99e1e8b",
   "metadata": {},
   "source": [
    "No 10 unit intervals with zero counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870a7e20-87bb-408c-95c2-2f2585b0b3ea",
   "metadata": {},
   "source": [
    "Anyway, augment the counts with zero \"zero\" count intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e2ef0a-c0f6-4cbf-923a-40bce859b481",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts10b <- c(counts10, rep(0, length(zerocounts10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d4b711-6205-4aad-a187-126f30fa1123",
   "metadata": {},
   "outputs": [],
   "source": [
    "length(counts10b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4052a6a3-47ad-4b7a-b2f5-0c56f7e9a83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(counts10b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d203f72-61da-407e-bfae-28bc5f54b0fa",
   "metadata": {},
   "source": [
    "The contingency table of counts itself reveals a Poisson distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42b1ac6-65fd-45ee-b9c4-211389c76b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "countst10 <- table(counts10b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb6a2db-793b-4015-9a2a-dc8060b42209",
   "metadata": {},
   "outputs": [],
   "source": [
    "countst10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09115da-ccc8-40cc-a07b-8112ae097e07",
   "metadata": {},
   "source": [
    "And also the histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8713946-cbea-42de-bde0-c7346daca878",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(counts10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21325a5-053c-41ff-82f8-281cbf64da4a",
   "metadata": {},
   "source": [
    "Get the density of count data to smooth out wigglyness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a438800e-a2e3-4ae3-bd4b-83156e4fd95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts10d <- density(counts10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490b892a-49b8-4355-8a7e-6f6e334d2aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts10dt <- as.data.table(counts10d[c(\"x\", \"y\")])[x >= 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8321228-d371-4f04-9d50-be7127260ee8",
   "metadata": {},
   "source": [
    "And compare the PMF of the simulated counts and Poisson distribution with a rate of 50:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167f3209-50da-437d-b057-2f14d8ed708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(counts10dt, type = \"l\", col = \"blue\")\n",
    "lines(0:75, dpois(0:75, 50), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e16d75e-73bc-4417-8cd6-ef7aa9fea9c4",
   "metadata": {},
   "source": [
    "They almost totally overlap again! So the Poisson point process with waiting times from an exponential distribution with a rate of 5 events per 1 unit interval results in a count distribution from a Poisson distribution with a rate of 50 when the count data for ten interval groups are aggregated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e125875c-1ad4-4a22-abfe-df35d7d3902e",
   "metadata": {},
   "source": [
    "The empirical mean and variance of the count distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78333a7d-18fa-4bf6-b346-4085ea8ef28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(counts10b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6dc737-906b-40c3-bf7d-91fa89d132b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(counts10b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e4c671-2a07-4ffc-a94c-244de8c1a30f",
   "metadata": {},
   "source": [
    "Is in line with theoretical mean and variance of a Poisson distribution with rate 50:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19292d5a-1bf6-4520-8de3-2a4c12d8bd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(Pois(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a97633e-d572-4f83-b5d2-86f6d859d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(Pois(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea713df-a466-46f8-af29-109b5e77dce0",
   "metadata": {},
   "source": [
    "That's the beauty of Poisson distribution: We can stretch or contract the time intervals to get a new count data and it will conform to a Poission distribution with a rate multiplied by the number of intervals!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379f315e-2a56-4c70-b728-06f77deae86b",
   "metadata": {},
   "source": [
    "In this case we could get a Poisson distributed count data with a rate of 50 events per 10 time interval by aggregating Poisson distributed count data with a rate of 5 events per time interval by compressing the data of 10 consecutive intervals into one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d12f12-fe0a-46ae-b4ec-cddb177b689c",
   "metadata": {},
   "source": [
    "## Wealth distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06314305-32ba-423c-a3c0-3465e8d4c81c",
   "metadata": {},
   "source": [
    "Now let's simulate financial transactions among the participants in a small economy using agent-based simulation.\n",
    "\n",
    "The idea is simple: All participants start out with the same wealth. In every iteration (period), all agents are matched and 1 unit is exchanged randomly from one side to the other.\n",
    "\n",
    "The probability of giving or taking does not depend on the size of current wealth. So we can assume that the rules of trade are completely fair. The only restriction is that noone is allowed to go below zero wealth. And to ensure that zero wealth agents are not excluded out of further trade, at the beginning of each iteration each zero wealth agents receive 1 unit randomly from a separate non-zero wealth agent.\n",
    "\n",
    "So in each iteration a single agent can give or receive at most 1 units.\n",
    "\n",
    "We create 1e3 agents, each with 20 units of initial wealth. And see what happens after 5e3 iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a99e04-8c5f-4f81-8988-59c5daec59db",
   "metadata": {},
   "outputs": [],
   "source": [
    "nagent <- 1e3\n",
    "niter <- 5e3\n",
    "initw <- 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fa2126-b322-48b2-8567-f1b448519cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(80)\n",
    "wealth_dt <- data.table(wealth = rep(initw, nagent), match = rep(0, nagent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9eff89-16cc-4918-8269-9470a90e87af",
   "metadata": {},
   "source": [
    "Check the starting total wealth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fa05df-3092-4f85-a33f-18beb9c5425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wealth_dt[, sum(wealth)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb55bc8-ae3c-4cac-acef-b781d0d9f7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(90)\n",
    "for (i in 1:niter)\n",
    "{\n",
    "    zerow <- wealth_dt[wealth == 0, .N]\n",
    "    wealth_dt[, wealthnew := wealth]\n",
    "    wealth_dt[wealth == 0, wealthnew := 1]\n",
    "    wealth_dt[wealth > 0, match := sample(c(rep(-1, zerow), rep(0, .N - zerow)))]\n",
    "    wealth_dt[match == -1, wealthnew := wealth - 1]\n",
    "    wealth_dt[wealth > 0 & match != -1, match := sample(.N) - 1]\n",
    "    wealth_dt[wealth > 0 & match != -1, wealthnew := wealth + sample(c(-1,1), .N), by = match %/% 2]\n",
    "    wealth_dt[, wealth := wealthnew]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facf8fd4-3148-44fe-a1c8-49f22164dec8",
   "metadata": {},
   "source": [
    "Check the ending total wealth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aa44fa-5b06-408d-8eaa-d1a3f5497b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "wealth_dt[, sum(wealth)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439a3f5b-2e7e-4427-94e5-5f45180123f4",
   "metadata": {},
   "source": [
    "See the histogram of ending wealth distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7910adb1-8650-4471-936c-043a8c262b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(wealth_dt[, wealth], breaks = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076a7f15-a8e4-40b1-8795-6e5eda21fb3b",
   "metadata": {},
   "source": [
    "See the largest wealth values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e83a215-5e43-4ebb-b403-706e1c3826e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wealth_dt[, sort(wealth, decreasing = T)][1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968bc87d-c141-4362-b0e8-476ab5a1dbc0",
   "metadata": {},
   "source": [
    "Now let's sample values from exponential distribution with a rate of reciprocal of initial wealth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa4d625-c682-44f1-9fe6-d15f1065a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(95)\n",
    "wealth_exp <- rexp(nagent, 1/initw)\n",
    "round(sort(wealth_exp, decreasing = T))[1:10]\n",
    "hist(wealth_exp, breaks = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4978c00-a63a-458c-80b9-a644a1c303ff",
   "metadata": {},
   "source": [
    "The extreme values from the simulation and sampled exponential values are quite close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb0da02-df41-4cd1-84a0-d454e3ee985d",
   "metadata": {},
   "source": [
    "Calculate the density of simulated wealths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924d0a27-4743-4ec3-a193-13229a575460",
   "metadata": {},
   "outputs": [],
   "source": [
    "wealth_dens <- density(wealth_dt[wealth > 0, wealth])[c(\"x\", \"y\")]\n",
    "setDT(wealth_dens)\n",
    "maxx <- wealth_dens[, max(x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2434c2-768b-4239-a727-85f61cbf6449",
   "metadata": {},
   "source": [
    "And compare with theoretical density with a rate of reciprocal of initial wealth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f5e208-9a98-4819-94e8-9fc0faf0993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(wealth_dens[x > 10], type = \"l\", col = \"blue\")\n",
    "lines(10:maxx, dexp(10:maxx, 1/initw), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4334c1cd-fa30-4384-ab5f-4e27a37af824",
   "metadata": {},
   "source": [
    "The densities almost perfectly overlap. So even fair laws of nature result in wealth inequality with an exponential distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b61cc2c-f615-421b-a84e-5643d2807153",
   "metadata": {},
   "source": [
    "## Life expectancy with constant hazard rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370b8701-6f4c-4277-a44b-f851d7905f27",
   "metadata": {},
   "source": [
    "Exponential distribution is also useful in survival analysis where the hazard rate is constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e2f91b-640f-418f-944f-6daf897787cb",
   "metadata": {},
   "source": [
    "Let's create a new born population of 1e4 people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5925f631-1623-4dc1-8646-b122c5b98ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "life_dt <- data.table(dead = rep(0, 1e4), life = rep(0, 1e4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24180de4-5b80-4c83-a82a-624405a5a35d",
   "metadata": {},
   "source": [
    "And set the hazard rate - proportion of still alive population to die in the period - to 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9d9789-638d-41a6-9570-4c3658b8234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate <- 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5472e417-a85a-4dfa-becd-ee049bc8757e",
   "metadata": {},
   "source": [
    "Initialize the period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96030d2c-13d7-4161-8eb7-c0eef02bb9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "periodx <- 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dec4de6-f1e5-4074-9026-da582fac47e4",
   "metadata": {},
   "source": [
    "Randomly sample from live population using Bernoulli trials with a bias of 0.1 and record the age (period) of each individual when they die.\n",
    "\n",
    "Continue until no one stays alive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf00645-75a5-45c7-b6de-544ac5bf6b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(5)\n",
    "while(life_dt[dead == 0, .N] > 0)\n",
    "{\n",
    "    periodx <- periodx + 1\n",
    "    life_dt[dead == 0, dead := rbinom(.N, 1, rate)]\n",
    "    life_dt[dead == 1 & life == 0, life := periodx]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452e37d4-be66-40cd-9d9b-9b33fcb79a22",
   "metadata": {},
   "source": [
    "Check the inidivuduals who die at the oldest age:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b52042f-1d31-4a02-8d9f-abb5e5b71555",
   "metadata": {},
   "outputs": [],
   "source": [
    "life_dt[, sort(life, decreasing = T)][1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7194f644-d15e-436f-b83a-bbad9ee538c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "periodx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b8679d-015b-4889-acb8-b921eb8801d3",
   "metadata": {},
   "source": [
    "Histogram of simulated life expectancies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a87ea7b-ab00-4952-8bdd-2c985ca24943",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(life_dt$life)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d34add7-2428-477d-a98d-9de991a11cfd",
   "metadata": {},
   "source": [
    "The mean life expectancy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c444fff-397c-4700-9690-d05fe9c650ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "life_dt[, mean(life)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bf19e0-2f2f-4db0-8db0-20e0643eefba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d8e1892-fd62-4968-8309-86186d445d9b",
   "metadata": {},
   "source": [
    "Simulate from exponential distribution with the same hazard rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191530a4-02ae-4109-b466-95bb1cfc257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(5)\n",
    "leexp <- rexp(1e4, rate)\n",
    "hist(leexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02474ec-acb4-4470-9029-1ca94dad97c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(sort(leexp, decreasing = T)[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e23cff-381e-45da-bebe-4dfb93c25d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "life_dens <- density(life_dt[, life])[c(\"x\", \"y\")]\n",
    "setDT(life_dens)\n",
    "maxx <- life_dens[, max(x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed52f016-0b72-4788-972f-e667a12d0d80",
   "metadata": {},
   "source": [
    "And compare with theoretical density with a rate of reciprocal of initial wealth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74089817-b4fc-45d7-ba5c-20c2e44de77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(life_dens[x > 10], type = \"l\", col = \"blue\")\n",
    "lines(10:maxx, dexp(10:maxx, rate), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b51b6f-d40a-46bd-bc10-2d5da3032ddf",
   "metadata": {},
   "source": [
    "And the densities almost perfectly overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12820e93-3bdb-4992-9c56-aca006b5a577",
   "metadata": {},
   "source": [
    "We saw that, exponential distribution occurs in different areas that are governed by simple laws of nature, like Bernoulli trials with a bias, totally random and fair equal sized transactions and demographics with a fixed mortality rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0856b84-186b-4e76-bc8a-6011eff7502f",
   "metadata": {},
   "source": [
    "# Normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c96779-045e-40fb-94e5-86479db87417",
   "metadata": {},
   "source": [
    "There are some famous bells in history ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2606fdc9-7877-4ceb-a7f2-1c24a7ffb06f",
   "metadata": {},
   "source": [
    "Cowbell of İnek Şaban:\n",
    "\n",
    "<video src=\"../imagesba/cowbell2.mp4\"  \n",
    "       controls width=\"500\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b8208e-58d2-4cd7-8332-0ae497c40648",
   "metadata": {},
   "source": [
    "School bell of Hafize Ana:\n",
    "\n",
    "<video src=\"../imagesba/hazife_ana2.mp4\"  \n",
    "       controls width=\"500\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67e5b8a-3303-4066-8828-907daebca96c",
   "metadata": {},
   "source": [
    "Bell of the Notre-Dame de Paris:\n",
    "\n",
    "<img src=\"../imagesba/notredame.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ad7fae-2540-4db8-8467-37506c061e36",
   "metadata": {},
   "source": [
    "And the bell curve of normal distribution:\n",
    "\n",
    "<img src=\"../imagesba/galtonboard2.jpg\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21724fd7-8496-4304-90f8-80927c5bf4f3",
   "metadata": {},
   "source": [
    "The formula that generates the above curve is as such:\n",
    "\n",
    "$${\\huge\n",
    "{\\bf\n",
    "f(x)={\n",
    "\\frac\n",
    "{1}{\\sqrt {2\\pi \\sigma ^{2}}\n",
    "}\n",
    "}e^\n",
    "{\n",
    "{-{\\frac {(x-\\mu )^{2}}{2\\sigma ^{2}}\n",
    "}\n",
    "}\n",
    "}\n",
    "}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66ed398-de13-4933-935c-5019499b5a55",
   "metadata": {},
   "source": [
    "It seems like quite an ugly and complicated formula. But we can always simplify a complicated thing to its basic constituents:\n",
    "\n",
    "<video src=\"../imagesba/connery4.mp4\"  \n",
    "       controls width=\"1000\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94256009-2fd6-41e0-973e-a96cc934c8f1",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<th> So let's simplify Sean Connery: </th>\n",
    "<th> Into İbrahim Abi: </th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "<img src=\"../imagesba/connery.jpg\" width=\"200\"/>\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "<img src=\"../imagesba/ibrahim_abi.jpg\" width=\"200\"/>\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08226124-f096-440d-8278-8e7628ee11aa",
   "metadata": {},
   "source": [
    "The <span style=\"font-weight:bold;color:red;\">red</span> part is just a normalizing constant so that the integral of the formula or the area under the curve sums up to 1:\n",
    "\n",
    "$${\\huge\n",
    "{\\bf\n",
    "{\n",
    "\\color{red}\n",
    "{\n",
    "\\frac\n",
    "{1}{\\sqrt {2\\pi \\sigma ^{2}}\n",
    "}\n",
    "}}e^\n",
    "{\n",
    "\\color{blue}\n",
    "{\n",
    "{-{\\frac {(x-\\mu )^{2}}{2\\sigma ^{2}}\n",
    "}\n",
    "}\n",
    "}\n",
    "}\n",
    "}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d263c4c-ee06-4475-bc8e-85155eadf0eb",
   "metadata": {},
   "source": [
    "Let's get rid of that part:\n",
    "\n",
    "$${\\huge\n",
    "{\\bf\n",
    "e^\n",
    "{\n",
    "\\color{blue}\n",
    "{\n",
    "{-{\\frac {(x-\\mu )^{2}}{2\\sigma ^{2}}\n",
    "}\n",
    "}\n",
    "}\n",
    "}\n",
    "}\n",
    "}\n",
    "$$\n",
    "\n",
    "The <span style=\"font-weight:bold;color:blue;\">blue</span> part centers and scales $x$ so that we always get a similar curve, centered on 0 and with the same width. Let's assume $\\mu=0$ and $\\sigma=1$. We can also get rid of the 2 in the denominator, so the formula boils down to:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7212ab8d-471e-4c24-9601-35e2741f9324",
   "metadata": {},
   "source": [
    "$${\\huge\n",
    "{\\bf\n",
    "e^{-x^2}\n",
    "}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdad6a14-11d6-4628-9a6f-730d135efa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals <- seq(-3, 3, 0.001)\n",
    "plot(xvals, exp(-(xvals^2)), type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6337d2-c402-41bd-b376-f8fb7621f000",
   "metadata": {},
   "source": [
    "Now we confirm that the simple form $\\bf {e \\text{ \\bf to the power of minus squared } x}$ creates the famous bell shape.\n",
    "\n",
    "Let's see why that shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4a3f18-6ba0-4c8d-b3a5-f15f17582d6f",
   "metadata": {},
   "source": [
    "## Error curve: From Simpson and Laplace to Gauss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c45a3f-2ae0-449b-8f29-1f333afa3aaf",
   "metadata": {},
   "source": [
    "The historical accounts and proofs here are mostly taken from Stahl 2006, The Evolution of Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64837c7-957e-4325-92c8-8c267d644464",
   "metadata": {},
   "source": [
    "Chronographically the first idea of a bell curve came from Abraham De Moivre in 1733 when he was searching for an approximation formula for binomial distribution of large N numbers. That was a practical need before the advent of electronic calculators.\n",
    "\n",
    "We will come to that normal approximation to binomial with simulation.\n",
    "\n",
    "The need to come up with a curve arose from errors in astronomical observations: If the observations about a celestial body are prone to measurement error, how should astronomers proceed to decide on a certain quantity from these observations.\n",
    "\n",
    "Thomas Simpson proposed the first error curves denoting the probability density of measurement errors. In 1774 Pierre Simon Laplace also came up with his version of an error curve with a different shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e23e5d-4656-4c9a-a122-afcc19ab1e28",
   "metadata": {},
   "source": [
    "Let's explore some different curves..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5c7d2e-aaab-4de9-8d62-4acf19900fcc",
   "metadata": {},
   "source": [
    "The values around zero, linearly, not so useful because their probabilities are not symmetric around zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4414a81a-804c-4d46-bdba-be954b52eecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(xvals, type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1b0cc3-dcf9-4441-a416-3c918041c1ed",
   "metadata": {},
   "source": [
    "The absolute value is symmetric but, the center value is not the tip of the curver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6e1860-b818-444d-82e9-9a40348ced72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(abs(xvals), type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f28cbb-c7f7-475a-8975-e1e81e99a945",
   "metadata": {},
   "source": [
    "Let's take its negative but the density is not too concentrated around the center, similar to Simpson's curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495a0e32-1d69-4d1c-a934-8529f57fe01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(-abs(xvals), type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f6d47c-ab15-4c8a-9e35-3361edd31b9e",
   "metadata": {},
   "source": [
    "Exponentiate it, now center is more concentrated but the tip is not curved but pointed, not differentiable. This is Laplace's first curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99901755-21bb-403f-9e9a-d085a9c4f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(exp(-abs(xvals)), type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6762078d-2672-4193-99b1-1e46dbddea02",
   "metadata": {},
   "source": [
    "And at last, when Giuseppe Piazzi discovered minor planet Ceres in 1801, it was occulted behind the Sun shortly after, leaving only a handful observations. There was a race towards guessing where Ceres should reappear.\n",
    "\n",
    "Carl Friedrich Gauss estimated an area in sky that did not agree with the estimations of others and he was right!\n",
    "\n",
    "He had three assumptions:\n",
    "\n",
    "- Small errors are more likely than large errors, hence curve has a maximum at 0\n",
    "- Curve is symmetric: likelihoods of $\\epsilon$ and $-\\epsilon$ are the same\n",
    "- The most likely value is the average of measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595a5b58-5040-4cc4-9edb-9cda17a27305",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(xvals, exp(-(xvals^2)), type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d6252d-6740-4f6c-a897-1c75c0026f68",
   "metadata": {},
   "source": [
    "Simplified proof of Gauss is as follows, without going into too much mathematical rigor:\n",
    "\n",
    "The density function is defined as $\\phi(x)$. The joint density function for the likelihood of data $M$ is:\n",
    "\n",
    "$\\large {\\Omega=\\prod_{i=1}^{n}\\phi(M_i - \\bar{M})}$\n",
    "\n",
    "where $\\bar{M}$ is the average of observations.\n",
    "\n",
    "In plain English: The product of the density or likelihood values for all errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b2cbbe-16d0-4ec8-875c-d3aabfa65e8d",
   "metadata": {},
   "source": [
    "with some omitted rigorous steps, we get that:\n",
    "\n",
    "$\\large {\\sum_{i=1}^{n}\\frac{\\phi'(M_i - \\bar{M})}{\\phi(M_i - \\bar{M})}} = 0$\n",
    "\n",
    "In plain English again: The sum of the ratios of the derivative of the likelihood function to the likelihood function itself for all data values is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36186c0-8b09-462a-98b7-f8ad6d1639bc",
   "metadata": {},
   "source": [
    "With again some omitted steps, we derive the following differential equation:\n",
    "\n",
    "$\\large {\\frac{\\phi'(x)}{\\phi(x)} = kx}$\n",
    "\n",
    "In plain English: The ratio of the derivative of the likelihood function to the likelihood function itself for a data value should be a constant times that data value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ffe8ae-0d84-46f1-a846-18a63b3ce9b5",
   "metadata": {},
   "source": [
    "And the solution to this differential equation suggests that, simplified version of our function has to be in the form of:\n",
    "\n",
    "$${\\huge\n",
    "{\\bf\n",
    "e^{-x^2}\n",
    "}\n",
    "}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "- the exponent ensures the bulge in the middle with thinner tails\n",
    "- squared power ensures that we have a symmetric curve with a smooth extreme in the middle\n",
    "- And negative of the power ensures that the extreme in the middle is a maximum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4350e12-54b5-4e11-ab7b-6d25c42cdd00",
   "metadata": {},
   "source": [
    "Now let's see whether Gauss was right in his proof.\n",
    "\n",
    "First get the density values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8699e236-9048-4d48-bc9c-56b9fa39d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdvals <- dnorm(xvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dc7473-15f9-4831-a03d-4de96bcf8e6e",
   "metadata": {},
   "source": [
    "Plot the ratio of the difference of densities to densities themselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c01b44-fb49-42c8-bc99-a17f30be4835",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(xvals[-1], diff(rdvals) / rdvals[-1], type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d0f950-c18d-450b-b384-197ec1d34445",
   "metadata": {},
   "source": [
    "Or better calculating the derivative of the normal distribution curve at the data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f18ce6d-d810-4f11-a7f4-e657e0c42f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "rddvals <- ddnorm(xvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8bf911-b6a6-4d20-ab98-02b6bba647da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(xvals, rddvals / rdvals, type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2fe6af-be48-4c88-ab08-168d69f207e3",
   "metadata": {},
   "source": [
    "We confirrm the negative constant multiplied by data values in line with:\n",
    "\n",
    "$\\large {\\frac{\\phi'(x)}{\\phi(x)} = kx}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977a854c-e7f9-4efa-9485-7c5c19b03879",
   "metadata": {},
   "source": [
    "And to confirm that:\n",
    "\n",
    "$\\large {\\sum_{i=1}^{n}\\frac{\\phi'(M_i - \\bar{M})}{\\phi(M_i - \\bar{M})}} = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0940525-baa9-4a7c-8f0d-27acc8edab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(rddvals / rdvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950386c4-d677-4004-8ff9-780a8aeb87e1",
   "metadata": {},
   "source": [
    "Quite close to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8cc2ea-4635-4c5c-b55a-625308a74d80",
   "metadata": {},
   "source": [
    "## Normal Approximation to Binomial: De Moivre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960b5f5b-8327-4174-a676-9dbaa804257c",
   "metadata": {},
   "source": [
    "In 1712 Willem 's Gravesande wanted to test the hypothesis that male and female are equally likely using birth data in London between 1629-1710.\n",
    "\n",
    "Taking the average of annual births as 11,429 and calculating the range of male birth ratios and multiplying with the average annual births he got the bounds for male births as between 5,745 and 6,128.\n",
    "\n",
    "For us the hypothesis is quite easy to test the hypothesis for a single year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d312006-9560-46fd-84e3-fcbecf6a2c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbinom(6128, 11429, 0.5) - pbinom(5744, 11429, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e28d37-7e7c-4b13-b398-db36c80e689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(dbinom(5745:6128, 11429, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4b3441-7c83-4865-b291-5448b7bbd62d",
   "metadata": {},
   "source": [
    "While 's Gravesande used the recursion of Newton:\n",
    "\n",
    "${\\displaystyle {\\binom {n}{x+1}}={\\binom {n}{x}}{\\frac {n-x}{x+1}}}$\n",
    "\n",
    "For a rational approximation, it was still quite a laborous task back in 1712.\n",
    "\n",
    "(Stahl 2006, The Evolution of Normal Distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029aeafa-8c22-4884-8e5a-243c6420a35b",
   "metadata": {},
   "source": [
    "In 1733, Abraham De Moivre proved that:\n",
    "\n",
    "${\\large {n \\choose k}\\,p^{k}q^{n-k}\\simeq {\\frac {1}{\\sqrt {2\\pi npq}}}\\,e^{-{\\frac {(k-np)^{2}}{2npq}}},\\qquad p+q=1,\\ p,q>0}$\n",
    "\n",
    "(https://en.wikipedia.org/wiki/De_Moivre%E2%80%93Laplace_theorem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df21a376-01aa-4f4b-ba3f-184cabc78a49",
   "metadata": {},
   "source": [
    "Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62b2c58-2049-410c-b900-0c5c60ab2134",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx <- 1000\n",
    "kx <- 318\n",
    "px <- 0.3\n",
    "qx <- 1 - px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa37f036-304b-47e2-a3a3-fdbd9b9a4112",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbinom(kx, nx, px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cdb23a-7d8d-4001-9c77-88c32a06c037",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1/sqrt(2*pi*nx*px*qx))*exp(-(kx - nx*px)^2 / (2*nx*px*qx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b76117-9b4d-409c-98d9-7435a8bd63e4",
   "metadata": {},
   "source": [
    "Note that, the function has the same basic form as the normal distribution curve:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb80acb-588e-4b37-a834-c867d6242dbc",
   "metadata": {},
   "source": [
    "$${\\huge\n",
    "{\\bf\n",
    "e^{-x^2}\n",
    "}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6591be98-88b1-4901-a742-648f0a5a35de",
   "metadata": {},
   "source": [
    "Now let's see how binomial distribution converges to normal distribution with large n:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655cf45d-ae1c-4332-bc01-1d861cad8206",
   "metadata": {},
   "source": [
    "Let's remember the mean and variance and binomial distribution:\n",
    "\n",
    "Expected value is:\n",
    "\n",
    "${\\displaystyle \\operatorname {E} [X]=np}$\n",
    "\n",
    "And variance is:\n",
    "\n",
    "${\\displaystyle \\operatorname {Var} (X)=npq=np(1-p)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953b70f5-ca60-4de0-ac13-dafe613f5d09",
   "metadata": {},
   "source": [
    "We write a function to plot the densities of both curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ef7b51-bf2b-42fc-80a5-c91679823cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "binnorm <- function(nx, bias)\n",
    "{\n",
    "    dbin <- dbinom(0:nx, nx, bias)\n",
    "    meanbin <- nx * bias\n",
    "    varbin <- nx * bias * (1 - bias)\n",
    "    sdbin <- sqrt(varbin)\n",
    "    dnor <- dnorm(0:nx, meanbin, sdbin)\n",
    "    plot(0:nx, dbin, type = \"l\", col = \"blue\", ylim = c(min(c(dbin, dnor)), max(c(dbin, dnor))))\n",
    "    lines(0:nx, dnor, col = \"red\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e59d160-2f55-44d7-a918-dd4dea4a4668",
   "metadata": {},
   "source": [
    "For $n = 2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748d4ba8-7adb-47f6-a8c3-9560b0d123ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "binnorm(2, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee44623-1b49-45f0-a829-881ab3665f7b",
   "metadata": {},
   "source": [
    "For $n = 5$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef053a7-1c41-401a-8a6c-085d668c2683",
   "metadata": {},
   "outputs": [],
   "source": [
    "binnorm(5, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df2c225-409b-4dcd-9555-0c0726b4769d",
   "metadata": {},
   "source": [
    "For $n = 10$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5446ae7e-1ec3-49c8-9adc-021ce181f90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "binnorm(10, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38a9890-e68d-4d96-ba82-66aaeda5d2ba",
   "metadata": {},
   "source": [
    "For $n = 20$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dae2c86-33b9-4daa-b6e2-93f67aa25d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "binnorm(20, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8620cc93-4381-45da-8da4-b6305c39eb49",
   "metadata": {},
   "source": [
    "You can also play around with the **Binomial to Normal Distribution** application under 06_prob_stat_2/apps with Shiny interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219f3e51-0fb1-4e3c-ae65-ce38cd21c13a",
   "metadata": {},
   "source": [
    "Galton Board, invented by Francis Galton, who coined the term regression, is an analogue simulation that demonstrates that binomial distribution converges to normal distribution with large $N$:\n",
    "\n",
    "<video src=\"../imagesba/galton.mp4\"  \n",
    "       controls width=\"300\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae33818-3f0b-4eed-b64c-e4a28138762b",
   "metadata": {},
   "source": [
    "## Normal Approximation to Poisson Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d522702-2375-4240-8513-4a7adb0092b7",
   "metadata": {},
   "source": [
    "Since Poisson distribution is a limiting case of binomial distribution, where N approaches infinity while p approaches 0, Poisson distribution converges normal distribution for large rate values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5325dbec-25cc-48fc-90f6-e9409201d3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisnorm <- function(nx, rate)\n",
    "{\n",
    "    dp <- dpois(0:nx, rate)\n",
    "    meanpois <- rate\n",
    "    varpois <- rate\n",
    "    sdpois <- sqrt(varpois)\n",
    "    dnor <- dnorm(0:nx, meanpois, sdpois)\n",
    "    plot(0:nx, dp, type = \"l\", col = \"blue\", ylim = c(min(c(dp, dnor)), max(c(dp, dnor))))\n",
    "    lines(0:nx, dnor, col = \"red\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36c6a1a-3837-4489-a26e-446f6cf98628",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisnorm(5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb985aae-24ec-4167-804c-3d149a26cc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisnorm(10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb1db5b-622b-4566-8940-4150915866be",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisnorm(20, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e648d062-fac7-41d4-8892-31fd857110e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisnorm(50, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19bb067-bab9-41e1-8229-e278b849ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisnorm(100, 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db38c5fd-e0f1-47e8-a936-7b195bb6f170",
   "metadata": {},
   "source": [
    "You can also play around with the **Poisson to Normal Distribution** under 06_prob_stat_2/apps with Shiny interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e22e1e-f6d9-4a95-9903-f52cf3b8448c",
   "metadata": {},
   "source": [
    "## Independent and Identically Distributed Random Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b19607f-0f4a-4a43-afc5-4c6fc884d6b3",
   "metadata": {},
   "source": [
    "A collection of random variables is independent and identically distributed (i.i.d., iid, or IID) if each random variable has the same probability distribution as the others and all are mutually independent.\n",
    "\n",
    "- Identically distributed means that there are no overall trends — the distribution does not fluctuate and all items in the sample are taken from the same probability distribution.\n",
    "- Independent means that the sample items are all independent events. In other words, they are not connected to each other in any way;[2] knowledge of the value of one variable gives no information about the value of the other and vice versa.\n",
    "\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c07cc9-7385-4503-a0d5-42ba0f109dbd",
   "metadata": {},
   "source": [
    "To show the concepts of identically distributed and/or independent variables, we will generate random variables from multivariate normal distribution and diagnose their distributions and correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16727cde-ef2c-4738-a1ca-6fa89c1ae683",
   "metadata": {},
   "source": [
    "Since the version of central limit theorem that we cover here requires the variable to be i.i.d, we first run simulations how independent/not-independent and identically/unidentically distributed variables are diagnosed:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e680e8-004f-43c6-9be3-de7b18fa4ee2",
   "metadata": {},
   "source": [
    "### Independent and Identically Distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644689b8-1425-422b-83ca-e6f0325bf486",
   "metadata": {},
   "source": [
    "First let's create 3 i.i.d variables, all with mean 0 and standard deviation 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04829055-a9e8-4d73-93ab-d68ddcd2f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "nv <- 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06911bd8-3cf6-4873-83c4-78404660db6b",
   "metadata": {},
   "source": [
    "Vector of fixed means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92832398-8577-4872-88a9-8622a313e239",
   "metadata": {},
   "outputs": [],
   "source": [
    "means <- rep(0, nv)\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed81422d-8a37-4afe-a5a9-8b59830947fe",
   "metadata": {},
   "source": [
    "Fixed standard deviations as a diagonal matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7d9846-b79c-48e6-8b2e-db242e6e349f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sds <- diag(rep(2, nv))\n",
    "sds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1d5a04-cdb0-4f88-8d4c-c442cdab71bf",
   "metadata": {},
   "source": [
    "Correlation matrix where all non-diagonal entries are zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2feece9-0298-4c37-a11c-4ebc26217070",
   "metadata": {},
   "outputs": [],
   "source": [
    "corm <- diag(rep(1, nv))\n",
    "corm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dfc07e-c2bb-48d4-a760-741e61ebcd66",
   "metadata": {},
   "source": [
    "The covariance matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7513af-265c-43d3-b06c-baf5b3085e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "covr <- sds %*% corm %*% sds\n",
    "covr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc61afb-2760-4547-94d2-f66022a742f3",
   "metadata": {},
   "source": [
    "Create the sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3357b96-dd51-4a60-bfc6-8f947033e6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(3)\n",
    "samp_iid <- mvrnorm(1e3, means, covr)\n",
    "samp_iid <- as.data.table(samp_iid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbf197a-b6c9-4bb9-97fd-87a80577a494",
   "metadata": {},
   "source": [
    "See their sd, mean and five point summaries, they are identical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94915843-5221-43f9-b867-01afc7bec7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_iid %>% lapply(function(x) c(SD = sd(x), as.list(summary(x)))) %>% rbindlist %>% round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5ca653-6742-4385-b1cd-1fe062f348b0",
   "metadata": {},
   "source": [
    "See their cross correlations, they are independent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb9aaed-259c-4c1d-82f0-cac2a6d692e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(cor(samp_iid), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babd6a34-c42d-42d8-b055-32b42ca918cb",
   "metadata": {},
   "source": [
    "Pairwise scatterplots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55159549-336c-4477-b4c2-c3ac31288992",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ggpairs(samp_iid)\n",
    "pairs.panels(samp_iid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0790854-f870-4510-95ba-7ca8e738e7e3",
   "metadata": {},
   "source": [
    "See that, scatter plots form clouds, with no apparent correlation and scales and distributions of the variables are identical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333e1169-1ce2-4ceb-8ce3-4291fb5ab3b1",
   "metadata": {},
   "source": [
    "### Independent but Not Identically Distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5712c46c-9ecb-4508-93fb-3dbfa66a7bf8",
   "metadata": {},
   "source": [
    "First let's create 3 variables, means and standard deviation of which are randomly drawn from respective distributions so that they are not identical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ffa2fc-aa00-41ad-8ec3-139c89cffb73",
   "metadata": {},
   "source": [
    "Means from normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304434c9-a863-4868-882c-ceabd2d0881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "means <- rnorm(nv, 0, 2)\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395fa1c1-0f64-4153-bb0d-de14c0709322",
   "metadata": {},
   "source": [
    "Standard deviations from exponential distribution, since they should always be positive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726c57e0-b70a-4485-9004-2ede0a07ee77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set.seed(2)\n",
    "sds <- diag(rexp(nv, 1/2))\n",
    "sds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98af5aeb-87a5-4041-8b7e-5912632ef6e9",
   "metadata": {},
   "source": [
    "Correlation matrix where all non-diagonal entries are zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973ad045-c309-493a-85d0-f9b939b5d340",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corm <- diag(rep(1, nv))\n",
    "corm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92a3f3c-bfe0-4306-9ee1-e3d8ffe748d2",
   "metadata": {},
   "source": [
    "The covariance matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb71a059-4d30-4e35-9125-414e0f89e3b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "covr <- sds %*% corm %*% sds\n",
    "covr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27edab83-70bd-4ecc-b1fb-ae2a09c92b63",
   "metadata": {},
   "source": [
    "Create the sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5eeb47-1537-497d-9802-b3632ff24860",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(4)\n",
    "samp_iid <- mvrnorm(1e3, means, covr)\n",
    "samp_iid <- as.data.table(samp_iid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929112bc-64f5-4187-bead-0abe12490333",
   "metadata": {},
   "source": [
    "See their sd, mean and five point summaries, they are unidentical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d874227-0352-4dd0-b425-2322a2e9c651",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_iid %>% lapply(function(x) c(SD = sd(x), as.list(summary(x)))) %>% rbindlist %>% round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb7d10c-c208-42e1-ac92-465ea4f37bbd",
   "metadata": {},
   "source": [
    "See their cross correlations, they are independent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a84978-28cb-47ed-a844-715ebb9eeac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(cor(samp_iid), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae4f818-aa02-40fb-b43b-6bcc118ee316",
   "metadata": {},
   "source": [
    "Pairwise scatterplots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ab81a8-b607-4eea-963e-74f6545efb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ggpairs(samp_iid)\n",
    "pairs.panels(samp_iid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8865870-e732-4f11-bd4d-c08382857513",
   "metadata": {},
   "source": [
    "See that, scatter plots form clouds, with no apparent correlation. However the scales and distributions of the variables are unidentical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4bf1e2-2602-4b12-bc87-67b97452518c",
   "metadata": {},
   "source": [
    "### Not Independent but Identically Distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006123d9-d071-4e68-8eba-9bab9695a6c7",
   "metadata": {},
   "source": [
    "Let's again create 3 identically distributed variables, all with mean 0 and standard deviation 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7276acf7-5cc7-48f6-96f7-65b9e0f8cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nv <- 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea706184-ad64-4f54-91bb-0320cf45972c",
   "metadata": {},
   "source": [
    "Vector of fixed means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a3a031-22c4-497a-86b2-bddd91c9821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "means <- rep(0, nv)\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2316ec-9311-4494-b3cf-1c59d5ba083f",
   "metadata": {},
   "source": [
    "Fixed standard deviations as a diagonal matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97eeba6-bbd6-42bb-bad1-252f7a76805f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sds <- diag(rep(2, nv))\n",
    "sds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a40eaed-cdd0-48b8-ba28-695c2afe67d8",
   "metadata": {},
   "source": [
    "Correlation matrix where non-diagonal entries are 0.6, so the variables are not independent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d931d122-c09b-4550-b11d-1adb15ab7861",
   "metadata": {},
   "outputs": [],
   "source": [
    "corm <- matrix(0.6, nrow = nv, ncol = nv)\n",
    "diag(corm) <- rep(1, nv)\n",
    "corm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136f7503-b6a9-4ab0-af06-0e93432e9c41",
   "metadata": {},
   "source": [
    "The covariance matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404db1eb-7f4d-45b8-8e3c-9580efd19561",
   "metadata": {},
   "outputs": [],
   "source": [
    "covr <- sds %*% corm %*% sds\n",
    "covr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6cd3f9-9434-4040-a74f-094b80c0b75f",
   "metadata": {},
   "source": [
    "Create the sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440e637c-abf0-4e12-a416-550a60559586",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(5)\n",
    "samp_iid <- mvrnorm(1e3, means, covr)\n",
    "samp_iid <- as.data.table(samp_iid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8314fc1-5143-4471-8768-8c4730d6bef4",
   "metadata": {},
   "source": [
    "See their sd, mean and five point summaries, they are identical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49297f2c-2346-45f9-9a03-a4db79b345a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_iid %>% lapply(function(x) c(SD = sd(x), as.list(summary(x)))) %>% rbindlist %>% round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0aa085-db79-45b7-96a4-a56b2915633d",
   "metadata": {},
   "source": [
    "See their cross correlations, they are not independent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6176aad0-1c41-4f2a-b031-5c794ff7ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(cor(samp_iid), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b76376-2680-4269-a961-48f10fae94d0",
   "metadata": {},
   "source": [
    "Pairwise scatterplots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ee1eae-b379-4bc3-9a0d-b565ce382c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ggpairs(samp_iid)\n",
    "pairs.panels(samp_iid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765fc0b1-d6ef-4c9d-aa8f-09b19dd38d9a",
   "metadata": {},
   "source": [
    "See that, scatter plots have clear elliptic shapes, showing positive cross corrrelations, however, scales and distributions of the variables are identical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd97d14-15c9-4853-9bf7-569c8276cddb",
   "metadata": {},
   "source": [
    "### Not Independent or Not Identically Distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a4b1e2-eee0-4262-8026-018487d17a29",
   "metadata": {},
   "source": [
    "Let's again create 3 variables, means and standard deviation of which are randomly drawn from respective distributions so that they are not identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a7e272-a027-4e19-a196-0ce717c2b0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nv <- 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc7df83-e4d2-4858-a0b4-18d9c1d159dc",
   "metadata": {},
   "source": [
    "Means from normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cf5e77-5721-4608-9757-59099771c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(6)\n",
    "means <- rnorm(nv, 0, 2)\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90544e7f-4007-46b8-867a-a0d0dfa1b433",
   "metadata": {},
   "source": [
    "Standard deviations from exponential distribution, since they should always be positive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49d1c81-1ecc-42d6-97b6-79db28f5fc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(7)\n",
    "sds <- diag(rexp(nv, 1/2))\n",
    "sds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3965088c-ca76-4160-88b7-be097761ab5d",
   "metadata": {},
   "source": [
    "Correlation matrix where non-diagonal entries are 0.6, so the variables are not independent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c0bf5d-1efd-4378-9605-3873f800ac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "corm <- matrix(0.6, nrow = nv, ncol = nv)\n",
    "diag(corm) <- rep(1, nv)\n",
    "corm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ea940e-8e06-41d6-9b1d-d3d34554be82",
   "metadata": {},
   "source": [
    "The covariance matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe21634d-d3f3-4c9f-b542-0f09ad67e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "covr <- sds %*% corm %*% sds\n",
    "covr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121a98ac-6a80-47a8-812b-407ef7c9c01b",
   "metadata": {},
   "source": [
    "Create the sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2039607-1c9c-41d6-b202-fe8b63a255c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(8)\n",
    "samp_iid <- mvrnorm(1e3, means, covr)\n",
    "samp_iid <- as.data.table(samp_iid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e183d72-f9f0-4f67-ae33-762e7f110be8",
   "metadata": {},
   "source": [
    "See their sd, mean and five point summaries, they are unidentical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0406c7c7-49fa-4d56-830e-e7764d727df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_iid %>% lapply(function(x) c(SD = sd(x), as.list(summary(x)))) %>% rbindlist %>% round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acdfcdf-2670-4131-9f22-49f99568b332",
   "metadata": {},
   "source": [
    "See their cross correlations, they are not independent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3122f345-c2d1-41c7-99d1-39834c52cd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(cor(samp_iid), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1037aa5f-2af1-48e9-acb9-5f8fea3846ee",
   "metadata": {},
   "source": [
    "Pairwise scatterplots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d556619a-d96a-400e-905a-15252d699654",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ggpairs(samp_iid)\n",
    "pairs.panels(samp_iid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b46b7eb-8f8e-4ede-a838-e58140dffc9f",
   "metadata": {},
   "source": [
    "See that, scatter plots have clear elliptic shapes, showing positive cross corrrelations, and, scales and distributions of the variables are unidentical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb479e8-3972-41b4-9199-47b5aa4a0623",
   "metadata": {},
   "source": [
    "## Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59145da-54fc-490e-b22e-8696a28de5af",
   "metadata": {},
   "source": [
    "We have demonstrated that, the standard deviation of the means of n-sized samples from a distribution with a standard deviation of $\\sigma$ is:\n",
    "\n",
    "${\\displaystyle \\sigma _{\\bar {x}}={\\sqrt {\\frac {\\sigma ^{2}}{n}}}={\\frac {\\sigma }{\\sqrt {n}}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12363e08-1fb8-40ae-885a-3e3c008e9a9d",
   "metadata": {},
   "source": [
    "Now we come back to the distribution of sample means for central limit theorem:\n",
    "\n",
    "Let \n",
    "${\\displaystyle X_{1},X_{2},\\dots ,X_{n}}$ denote a statistical sample of size \n",
    "${\\displaystyle n}$ from a population with expected value (average) \n",
    "${\\displaystyle \\mu }$ and finite positive variance \n",
    "${\\displaystyle \\sigma ^{2}}$, and let \n",
    "${\\displaystyle {\\bar {X}}_{n}}$ denote the sample mean (which is itself a random variable). Then the limit as \n",
    "${\\displaystyle n\\to \\infty }$ of the distribution of \n",
    "${\\displaystyle ({\\bar {X}}_{n}-\\mu ){\\sqrt {n}}}$ is a normal distribution with mean \n",
    "${\\displaystyle 0}$ and variance \n",
    "${\\displaystyle \\sigma ^{2}}$\n",
    "\n",
    "In other words, suppose that a large sample of observations is obtained, each observation being randomly produced in a way that does not depend on the values of the other observations, and the average (arithmetic mean) of the observed values is computed. If this procedure is performed many times, resulting in a collection of observed averages, the central limit theorem says that if the sample size is large enough, the probability distribution of these averages will closely approximate a normal distribution.\n",
    "\n",
    "The central limit theorem has several variants. In its common form, the random variables must be independent and identically distributed (i.i.d.). This requirement can be weakened; convergence of the mean to the normal distribution also occurs for non-identical distributions or for non-independent observations if they comply with certain conditions.\n",
    "\n",
    "The earliest version of this theorem, that the normal distribution may be used as an approximation to the binomial distribution, is the de Moivre–Laplace theorem that we saw above.\n",
    "\n",
    "The actual term \"central limit theorem\" was first used by George Pólya in 1920. Pólya referred to the theorem as \"central\" due to its importance in probability theory:\n",
    "\n",
    "> The occurrence of the Gaussian probability density $1 = e^{-x^2}$ in repeated experiments, in errors of measurements, which result in the combination of very many and very small elementary errors, in diffusion processes etc., can be explained, as is well-known, by the very same limit theorem, which plays a central role in the calculus of probability\n",
    "\n",
    "(https://en.wikipedia.org/wiki/Central_limit_theorem)\n",
    "\n",
    "Here we will not go into rigorous proofs but show by simulation that sample means of i.i.d random variables from different distributions with finite means and variances converge to normal distribution as the sample size increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e707ab-1f41-47ee-b738-c3b0e07c9a45",
   "metadata": {},
   "source": [
    "### Distribution of sample means from uniform distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a15a8c9-48c4-49cc-b838-ede50d17c3bf",
   "metadata": {},
   "source": [
    "First let's start with uniform distribution.\n",
    "\n",
    "Take a large sample - a population - that we can draw smaller samples from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4bf235-d8b3-49f2-b01d-ea0b61a68da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampx <- runif(1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9ad861-a410-4dbd-9f9d-08ff91e798fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(sampx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12f651c-367e-4385-a5d0-7ae7c5331598",
   "metadata": {},
   "source": [
    "Let's get the theoretical statistics of the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7c651d-f664-464b-ba22-8ef6aa79d17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "distx <- Unif(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa916697-055d-42f9-9cce-83c8ab2808d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(distx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a5f635-af39-499a-869f-e94291fe1b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(distx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c304fc-b9c2-4b71-9097-488ba4ecb578",
   "metadata": {},
   "source": [
    "Simulate 1e4 samples of size 100 and get their means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e715eaf-9919-4bf7-aed9-74a9adc62270",
   "metadata": {},
   "outputs": [],
   "source": [
    "simx <- rowMeans(t(replicate(1e4, sample(sampx, 100))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c27231-8b27-4bac-9eb3-52f8089f2ab7",
   "metadata": {},
   "source": [
    "The shape is a bell curve but does it converge to normal distribution sufficiently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0a15b0-00e7-4307-b8cb-ed3672334474",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(simx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a511f3-9aab-44a3-a772-0afc3bd14408",
   "metadata": {},
   "source": [
    "Empirical statistics of the population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4034afcb-382d-44cb-915a-532fc11f51ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e31f70-1d82-4980-bf37-137758924580",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112707a3-d5e4-430a-a2a9-816dc1d2244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(sampx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e36120-996f-4305-b802-8d2f10d22e37",
   "metadata": {},
   "source": [
    "And empirical statistics of the sample means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971a0200-5c8c-4de4-af85-b294e0e11614",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9df076-6921-4907-84ac-964a03f545e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c9f4bd-2d05-4204-97ff-f287c3afd954",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(simx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ab12cc-7aaf-4eae-9098-60af84e5d9b9",
   "metadata": {},
   "source": [
    "Standard deviation obeys the square root law:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed17c51f-c721-4a91-af96-379bfcf9847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(distx)/sqrt(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf517b-459b-488e-8da5-c2f6cc98614b",
   "metadata": {},
   "source": [
    "Now get the density of the distribution of sample means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806fff40-2d3b-4d1a-b541-4c66e1dab9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "densx <- density(simx)[c(\"x\", \"y\")]\n",
    "setDT(densx)\n",
    "maxx <- densx[, max(x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4439d2d-45eb-477b-a5b5-9a8f000b50d0",
   "metadata": {},
   "source": [
    "And compare with theoretical density of the normal distribution with the mean of the population and sd of the population divided by square root of sample size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d51baf-76b3-4a1b-b95e-9970370b28e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(densx, type = \"l\", col = \"blue\")\n",
    "lines(densx$x, dnorm(densx$x, mean(distx), sd(distx)/sqrt(100)), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1735f906-d0bf-4107-8911-a322b48620ef",
   "metadata": {},
   "source": [
    "They almost perfectly overlap!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38d920f-2456-4dfd-bde8-862d716cb9aa",
   "metadata": {},
   "source": [
    "So means of i.i.d. samples drawn from uniform distribution converge to normal distribution as sample sizes converge to $\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b106979-715e-4628-83c2-ff445bee5efb",
   "metadata": {},
   "source": [
    "### Distribution of sample means from exponential distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d886ec3-2477-4ea7-ba06-a2f821a5d507",
   "metadata": {},
   "source": [
    "Repeat the same procedure for exponential distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6be8c94-836d-448b-8950-2a93401ffe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampx <- rexp(1e5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d39538-489e-4798-a752-e1d5de82b05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7749f527-5780-4b61-955d-ad3da420d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "distx <- Exp(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7327b932-e2c3-4dae-8c3c-71a69d397a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(distx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c1ffa9-e30a-4a9f-8620-8a0cb062346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(distx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b603ca31-a3c7-4712-a43a-e1e67a7e8e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "simx <- rowMeans(t(replicate(1e4, sample(sampx, 100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b021f59-7311-4d74-90e8-eecd5fc13ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99fde98-1be7-405a-b064-d9824d80c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a400165c-f357-42fb-bcd1-da562676b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dc7a45-4011-4ff2-9855-53ec418cd323",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c40d4f-f788-4997-9657-e9e2fbc8c42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d20add9-9696-489b-9068-a687939ffd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7078fa81-6df6-4ec4-bec7-781ec1729426",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e931d0af-c078-4471-86ac-c3925ff52284",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(distx)/sqrt(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e209bf8-ea13-440b-a20e-813c259d7c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "densx <- density(simx)[c(\"x\", \"y\")]\n",
    "setDT(densx)\n",
    "maxx <- densx[, max(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d055a9-fb64-4b02-813f-50b1fff486f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(densx, type = \"l\", col = \"blue\")\n",
    "lines(densx$x, dnorm(densx$x, mean(distx), sd(distx)/sqrt(100)), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96df8d52-0a7f-4169-ba46-52ec8c44d9da",
   "metadata": {},
   "source": [
    "They almost perfectly overlap!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ca5e9f-af46-4fa3-bd0d-cdbfe763f94e",
   "metadata": {},
   "source": [
    "So means of i.i.d. samples drawn from exponential distribution converge to normal distribution as sample sizes converge to $\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61e4ce7-098c-4575-aeac-64f57488dec5",
   "metadata": {},
   "source": [
    "### Distribution of sample means from beta distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd254c2-c935-4658-8280-381cf18f560b",
   "metadata": {},
   "source": [
    "And last, let's draw a large sample from the Jeffrey's Prior, beta distribution with $\\alpha = 0.5, \\beta = 0.5$ parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf52de0-7fa3-40f5-98ea-97afff3659b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampx <- rbeta(1e5, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7b5386-dfa3-4591-b65f-88f079cbffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da6b377-1ea7-471a-8dce-b822600e77b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "distx <- Beta(0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a05591-f062-4c0b-8c15-24ecb17072b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(distx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98ab2be-d9ad-460a-adfc-fee8a9c0fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(distx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f3daa2-aa3a-4a3e-9d57-42b4f7826233",
   "metadata": {},
   "outputs": [],
   "source": [
    "simx <- rowMeans(t(replicate(1e4, sample(sampx, 100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a457dbf4-7670-4937-b914-b11443d9e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c6c961-f155-46be-9afc-eaa852221471",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1631079b-bf3a-46d6-9398-cb184bdef59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac1bd13-a513-4e44-bde5-108fc5ec66d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c878d8ed-346e-4e4f-b019-11cec0811248",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a639ca4d-862a-44ef-97a6-feda9de11eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73592bf-5db5-4bc5-924c-935d3c93dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8aa55b-e9e2-49d9-996d-dee606ad74cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(distx)/sqrt(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9922580c-dfe8-4b0d-81f0-00e5aae3064a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7cfc2b-5443-4148-bdb4-482d9121dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "densx <- density(simx)[c(\"x\", \"y\")]\n",
    "setDT(densx)\n",
    "maxx <- densx[, max(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc70979f-7f12-4983-bddb-31240ec3781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(densx, type = \"l\", col = \"blue\")\n",
    "lines(densx$x, dnorm(densx$x, mean(distx), sd(distx)/sqrt(100)), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddafd1e6-4c1d-45a0-bdb9-cfa8961d1f43",
   "metadata": {},
   "source": [
    "They almost perfectly overlap!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6396d104-bcd1-488f-8a76-2b88548c2e5e",
   "metadata": {},
   "source": [
    "So means of i.i.d. samples drawn from beta distribution converge to normal distribution as sample sizes converge to $\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e568df5f-b770-477c-a90d-7aa62c126050",
   "metadata": {},
   "source": [
    "Sample means drom quite different distributions (with finite mean and variance) converge to normal distribution with larger sample sizes.\n",
    "\n",
    "You can also play around with the **CLT with Beta Distribution** under 06_prob_stat_2/apps with Shiny interface to see sample means from a population that obeys the Jeffrey's Prior converges to normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c65684-86ed-45b0-840d-6f421a77b6c5",
   "metadata": {},
   "source": [
    "### Distribution of sample means from gamma distribution (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865e938b-4913-496a-8161-1b6e856a667d",
   "metadata": {},
   "source": [
    "Now let's repeat the same steps with a population from gamma distribution and show that distribution of sample means converge to normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a3e527-d4fb-4cfc-9f7a-3f718169eab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampx <- rgamma(1e5, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f229c0-cc25-420f-91f6-e129544ded0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d490fe-e11e-4730-99b5-dd29b17b52c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "distx <- Gam(3, 1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a24c62d-90f4-4c77-ba0f-fd70df5b828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(distx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc815e2-b0da-4d44-96da-c26eff817a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(distx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898d76a7-dee9-4379-aa5c-a49969d4b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "simx <- rowMeans(t(replicate(1e4, sample(sampx, 100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ca4045-c066-465f-953d-2e5e5a53f518",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5a0afb-305f-48da-9af9-58234a2059b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc52142-5997-455b-bf47-bf31acf785aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e50f3b9-d2d0-4c4c-80f7-f63c7df75f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(sampx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacff7bf-5ec4-4efc-8536-7f0313d2fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23962c76-90db-44d7-8b61-944f652280fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "var(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d982f01f-2c74-45e7-8b06-2354cc96e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(simx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ab784a-3e33-4b6b-84fc-7286038f057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(distx)/sqrt(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cf6b9f-a28a-4032-aefc-a0b28238b2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c3eb93-f35c-4e6e-a3e4-107b54d2d06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "densx <- density(simx)[c(\"x\", \"y\")]\n",
    "setDT(densx)\n",
    "maxx <- densx[, max(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2337bd84-a87a-45d1-b330-374c52af4b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(densx, type = \"l\", col = \"blue\")\n",
    "lines(densx$x, dnorm(densx$x, mean(distx), sd(distx)/sqrt(100)), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceefaf74-ff3d-4461-b5e0-9cdc35c0086c",
   "metadata": {},
   "source": [
    "They almost perfectly overlap!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4031976-657f-4344-aefa-5e64118b306b",
   "metadata": {},
   "source": [
    "So means of i.i.d. samples drawn from gamma distribution converge to normal distribution as sample sizes converge to $\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a63ed2-d253-42f2-9f31-4dca270dbb8e",
   "metadata": {},
   "source": [
    "### CLT with Correlated Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff8a705-82a6-458a-ae0f-03ee1bd03e6d",
   "metadata": {},
   "source": [
    "Now let's check whether means of samples from non-independent variables converge to normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0981c5-9bb5-43a1-a0c7-6b8fa8d0be1d",
   "metadata": {},
   "source": [
    "For this we will do an easy trick: We can draw random variables from multivariate normal distribution with any covariance structure.\n",
    "\n",
    "In order to convert the normally distributed variables to any distribution:\n",
    "\n",
    "- First we will get the p values corresponding to the normally distributed q values of the random samples\n",
    "- Then we will get the q values corresponding to the p values using any distribution we would like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b9d495-eeb0-42e5-b6e8-1f872f8cf30b",
   "metadata": {},
   "source": [
    "Let's first create the multivariate normal and identically distributed sample:\n",
    "\n",
    "Number of variables and the pairwise correlation, we will start with i.i.d variables with no correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21006a4-2643-491c-bd1b-0058da092184",
   "metadata": {},
   "outputs": [],
   "source": [
    "nv <- 100\n",
    "corx <- 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14052a43-3d5f-410f-aa77-db99a42cdd41",
   "metadata": {},
   "source": [
    "Means and sd's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a25de-5656-48ac-8adf-d77bca0ce650",
   "metadata": {},
   "outputs": [],
   "source": [
    "means <- rep(0, nv)\n",
    "sds <- diag(rep(1, nv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aec71a-84c5-49c7-b1fc-1d5f2e3f033d",
   "metadata": {},
   "source": [
    "Correlation and covariance matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f590f137-69fb-4105-9da3-f01653bc03c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corm <- matrix(corx, nrow = nv, ncol = nv)\n",
    "diag(corm) <- rep(1, nv)\n",
    "covr <- sds %*% corm %*% sds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208f18a7-3f64-469f-aba6-10143e3b3e51",
   "metadata": {},
   "source": [
    "And draw the normally distributed samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cf3429-88ec-4061-a14d-d279d557732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(5)\n",
    "samp_iidx <- mvrnorm(1e3, means, covr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110285f1-d7fd-4905-8f59-db4054a8c810",
   "metadata": {},
   "source": [
    "Let's try exponential distribution. Convert q values from normal distribution to distribution-agnostic p-values than to q-values from exponential distribution with just a single line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec9d7db-31f2-4bee-8963-61a1cb076776",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(rowMeans(qexp(pnorm(samp_iidx))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f2f5ac-dba9-4374-85d5-5acd1f1d3ce4",
   "metadata": {},
   "source": [
    "Sample means from i.i.d. variables converge to normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c6cb00-64a4-4576-b0ac-2ba95d221dcf",
   "metadata": {},
   "source": [
    "Now let's try different cross correlation values:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86169da-b97d-4ddb-b82d-1165703d3488",
   "metadata": {},
   "source": [
    "First wrap the steps into a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e53957-3a85-4310-a7fb-406e5e1a4905",
   "metadata": {},
   "outputs": [],
   "source": [
    "clt_exp <- function(corx, nv = 100, nsamp = 1e3)\n",
    "{\n",
    "    means <- rep(0, nv)\n",
    "    sds <- diag(rep(1, nv))\n",
    "    corm <- matrix(corx, nrow = nv, ncol = nv)\n",
    "    diag(corm) <- rep(1, nv)\n",
    "    covr <- sds %*% corm %*% sds\n",
    "    set.seed(5)\n",
    "    samp_iidx <- mvrnorm(nsamp, means, covr)\n",
    "    rowMeans(qexp(pnorm(samp_iidx)))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ba6220-cf33-4f9d-af1a-d21ebf5b87af",
   "metadata": {},
   "source": [
    "Than initiate a data.table with different correlation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75564ca3-ffe7-4976-bfca-87a1212ab571",
   "metadata": {},
   "outputs": [],
   "source": [
    "clt_sim <- data.table(corx = seq(0, 1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd04237c-9dc8-4ed0-ad33-5a0fef28a6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clt_sim2 <- clt_sim[, .(sampm = clt_exp(corx)), by = corx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70121998-2617-454e-85b2-5ecb65b67fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_clt <- clt_sim2 %>%\n",
    "plot_ly(x = ~sampm) %>%\n",
    "layout(yaxis = list(range = c(0, 100))) %>%\n",
    "add_trace(frame = ~corx, type = \"histogram\", nbinsx = 100) %>%\n",
    "animation_opts(\n",
    "    frame = 500, redraw = T, easing = \"linear\", mode = \"next\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5811d8f3-184b-4151-9fde-436bbe550c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_clt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf75eff-6940-49a1-be37-1e1888e8ca0b",
   "metadata": {},
   "source": [
    "We see that, at lower correlation levels, the variables become independent so the sample means converge to normal distribution.\n",
    "\n",
    "As the correlation among variables increase, the distribution of sample means converge closer to exponential distribution.\n",
    "\n",
    "So in order for the CLT to hold, the independence assumption is required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0827e097-3d62-4a52-971a-4cae367fbe80",
   "metadata": {},
   "source": [
    "### CLT and Information Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31de2787-7d52-48c3-899f-602ef3dda472",
   "metadata": {},
   "source": [
    "These simulations show **HOW** sample means converge to normal distribution.\n",
    "\n",
    "In order to understand the **WHY** of that convergence without messing with rigorous proofs, we have to visit the concept of **entropy** in an information theoretic sense later on.\n",
    "\n",
    "For now, shortly we can say that, means of large samples drawn from informative distributions become less informative of the original distribution. So the resulting distribution of sample means is the least informative one, that means the distribution that we can assume with the least information we have, the mean and the standard deviation of the original population. We will understand that informativeness when we discuss entropy.\n",
    "\n",
    "Think about it: Individuals may have quite unique voices when they shout or scream:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13283925-ec6a-4866-b4ca-b9de51256437",
   "metadata": {},
   "source": [
    "[![screams](https://img.youtube.com/vi/jFpkNtg731A/0.jpg)](https://www.youtube.com/watch?v=jFpkNtg731A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b74061-e0f0-43eb-963b-eb038a82aad7",
   "metadata": {},
   "source": [
    "But the crowd roars lose that information about the uniqueness of the voices of their individuals: Almost all crowd roars and cheers are similar:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae55749-382c-4f35-8c5c-39e6db2f7621",
   "metadata": {},
   "source": [
    "[![roars](https://img.youtube.com/vi/p4BrdRnbw1I/0.jpg)](https://www.youtube.com/watch?v=p4BrdRnbw1I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376a1e67-703b-427a-a3f9-db2ab370d668",
   "metadata": {},
   "source": [
    "We will combine **maximum entropy principal** that we will learn later with **central limit theorem**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a086b6-31ec-4996-80ac-d94e028e4d08",
   "metadata": {},
   "source": [
    "## Z-Score and Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42207c6-887c-43ff-9f26-6b548e0deee5",
   "metadata": {},
   "source": [
    "Let's recall the formula for the PDF of normal distribution that creates the famous bell shape.\n",
    "\n",
    "The <span style=\"font-weight:bold;color:blue;\">blue</span> part centers and scales $x$ so that we always get a similar curve, centered on 0 and with the same width:\n",
    "\n",
    "$${\\huge\n",
    "{\\bf\n",
    "{\n",
    "\\color{red}\n",
    "{\n",
    "\\frac\n",
    "{1}{\\sqrt {2\\pi \\sigma ^{2}}\n",
    "}\n",
    "}}e^\n",
    "{\n",
    "\\color{blue}\n",
    "{\n",
    "{-{\\frac {(x-\\mu )^{2}}{2\\sigma ^{2}}\n",
    "}\n",
    "}\n",
    "}\n",
    "}\n",
    "}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f36f15-74c9-4b34-bab4-0ed8fd61cc9e",
   "metadata": {},
   "source": [
    "Without standardization, all variables may have different locations ($\\mu$) and scales ($\\sigma$):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8131fe-c50a-45c6-ad46-529a22cfe6de",
   "metadata": {},
   "source": [
    "Let's create a multivariate sample again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5123276-080e-4091-b1ac-c6cbc806cdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(3)\n",
    "means <- rnorm(nv, 0, 2)\n",
    "set.seed(1)\n",
    "sds <- diag(rexp(nv, 1/2))\n",
    "corm <- diag(rep(1, nv))\n",
    "covr <- sds %*% corm %*% sds\n",
    "samp_iid <- mvrnorm(1e3, means, covr)\n",
    "samp_iid <- as.data.table(samp_iid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39d11ee-127a-4dae-9a8e-78da63b1f35d",
   "metadata": {},
   "source": [
    "See that the locations and scales are quite different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e54e5ad-3299-489c-8b77-68db45a5b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_iid %>%\n",
    "pivot_longer(everything()) %>%\n",
    "ggplot(aes(x = value, color = name)) +\n",
    "geom_density(adjust = 2) +\n",
    "guides(color =\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bceeb9-e0b3-454b-8372-3841fddabb89",
   "metadata": {},
   "source": [
    "The Z-score centers the variable by subtracting the mean, so the mean is 0 and rescales by dividing by the standard deviation so that the resulting standardized version has a standard deviation of 1:\n",
    "\n",
    "$\\huge {\\frac {x- \\mu}{\\sigma}}$\n",
    "\n",
    "The standardized variable is called the Z-score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c874cc7-5e9c-43af-9f8c-7e11d8687297",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_iid %>%\n",
    "mutate_all(normalize) %>%\n",
    "pivot_longer(everything()) %>%\n",
    "ggplot(aes(x = value, color = name)) +\n",
    "geom_density(adjust = 2) +\n",
    "guides(color =\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bc17c5-3e57-4c65-a0b8-0dc8a4f71f03",
   "metadata": {},
   "source": [
    "## Shape of My Normal PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b654fa4-ccf5-45e6-98cf-f54c1b9f0454",
   "metadata": {},
   "source": [
    "A great movie and the debut of Natalie Portman, Léon: The Professional by Luc Besson, ends with **Shape of My Heart** by Sting:\n",
    "\n",
    "[![roars](https://img.youtube.com/vi/DOZCqVLK6JU/0.jpg)](https://www.youtube.com/watch?v=DOZCqVLK6JU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d583da-675e-4f62-aacf-090a414fc647",
   "metadata": {},
   "source": [
    "That might inspire us to explore the shape of our famous bell curve:\n",
    "\n",
    "In a tandem plot of PDF and CDF of standard normal distribution, we can track where the Z scores correspond to cumulative probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d69a37-0d5f-4f55-9b30-68b174198430",
   "metadata": {},
   "outputs": [],
   "source": [
    "qvals1 <- seq(-4, 4, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3053f22-d609-4f16-b830-8a5ad6380c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 <- plot_ly(x = qvals1, y = round(dnorm(qvals1), 3), type = \"scatter\", mode = \"lines\") %>%\n",
    "  layout(\n",
    "    xaxis = list(\n",
    "      showspikes = TRUE, \n",
    "      spikemode = \"across\", \n",
    "      spikesnap = \"cursor\", \n",
    "      spikethickness = 1.5,\n",
    "      spikecolor = \"red\"\n",
    "    ),\n",
    "    yaxis = list(showspikes = FALSE)\n",
    "  )\n",
    "\n",
    "p2 <- plot_ly(x = qvals1, y = round(pnorm(qvals1), 3), type = \"scatter\", mode = \"lines\") %>%\n",
    "  layout(\n",
    "    xaxis = list(\n",
    "      showspikes = TRUE, \n",
    "      spikemode = \"across\", \n",
    "      spikesnap = \"cursor\", \n",
    "      spikethickness = 1.5,\n",
    "      spikecolor = \"red\"\n",
    "    ),\n",
    "    yaxis = list(showspikes = FALSE)\n",
    "  )\n",
    "\n",
    "subplot(p1, p2, nrows = 2, shareX = TRUE) %>%\n",
    "  layout(\n",
    "      title = \"Standard Normal Distribution\",\n",
    "    hovermode = \"x unified\",\n",
    "      annotations = list(\n",
    " list(y = 0.9, text = \"Probability Density Function\", showarrow = F, xref='paper', yref='paper'),\n",
    "  list(y = 0.3, text = \"Cumulative Distribution Function\", showarrow = F, xref='paper', yref='paper'))\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9680b9a-38c3-4d08-9e75-c026e8ab49a1",
   "metadata": {},
   "source": [
    "We see that the cumulative probability of -1 z-score is 15.9%. That means, probability that the z-score falls within 1 standard deviation of the mean of 0 is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce458bb-e7a7-4e21-8158-c499b4be1658",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(pnorm(1) - pnorm(-1), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35515cc-711d-431e-b5d0-5265872dcde1",
   "metadata": {},
   "source": [
    "We can repeat the same calculation for 2 and 3 standard deviations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bb7374-065c-478b-aaaa-38ed7a747833",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(pnorm(1:3) - pnorm(-(1:3)), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcdf74b-ce93-48b3-9554-8fcb209a9c5e",
   "metadata": {},
   "source": [
    "Which yields the famous 68-95-99.7 rule.\n",
    "\n",
    "(https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859207b4-2afa-4fd2-b37c-980861c92fb9",
   "metadata": {},
   "source": [
    "So we can say almost everyone stands within 3 standard deviations of the mean.\n",
    "\n",
    "What do you mean \"everyone\"?\n",
    "\n",
    "[![everyone](https://img.youtube.com/vi/zTFt5wxx3g8/0.jpg)](https://www.youtube.com/watch?v=zTFt5wxx3g8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87636ff9-1d2b-4117-a375-c9ded3774e8d",
   "metadata": {},
   "source": [
    "**Trivia:** Great actor Gary Oldman, who portrays a psychopatic DEA agent passionate with Beethoven's works here in Léon, also played the role of Ludwig van Beethoven in Immortal Beloved the same year in 1994!\n",
    "\n",
    "\n",
    "[![everyone](https://img.youtube.com/vi/7qWbcosJdtU/0.jpg)](https://youtu.be/7qWbcosJdtU?t=396)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85248fc-0202-4e09-b6eb-cbf1f5e6064c",
   "metadata": {},
   "source": [
    "## Normal Distribution Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6f9796-c96b-4697-acfe-bd8fb77e7145",
   "metadata": {},
   "source": [
    "Now let's cover the four friend functions of normal distribution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32305129-c6fc-45d9-8304-1b03a5dc6e26",
   "metadata": {},
   "source": [
    "Sample from standard normal distribution with `rnorm`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1c63ee-05c6-4882-9264-6a72a9153b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsamp <- rnorm(1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1fc72-1660-4a56-b4c4-eeca5f677430",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(rsamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5c3b75-c036-4857-83e5-91b7cf2e10d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(density(rsamp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91e988c-aebf-4c9b-911f-4a62bd131a34",
   "metadata": {},
   "source": [
    "Now let's create p values between 0 and 1 but leaving small tails (so that we don't have $-\\infty$ or $\\infty$ for quantile values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57d725b-692b-4f16-ba94-a24bd50d9b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseq <- seq(0.001, 1 - 0.001, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc60a84-0176-45a8-ad43-d1395977dd2a",
   "metadata": {},
   "source": [
    "The quantile values - values of the random variable - that correspond to the given p-values - or cumulative probabilities from the left tail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09ce5b7-68a7-4f00-80f1-40f93b76a099",
   "metadata": {},
   "outputs": [],
   "source": [
    "qseq <- qnorm(pseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c049b834-c4bc-4911-8e70-65c01de26170",
   "metadata": {},
   "source": [
    "The p-values across quantiles form the cumulative distribution function CDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44c1739-b2c9-49fc-bf7b-906675219f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(qseq, pseq, type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b789661-43a4-4fd6-803f-a334ce0d2860",
   "metadata": {},
   "source": [
    "Now let's do the inverse, and get the p-values that correspond to the quantiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d77b94c-11d9-4305-8282-c0550919adb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseq2 <- pnorm(qseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e77fcd-0865-452e-ab53-4951d9074d01",
   "metadata": {},
   "source": [
    "And compare the calculated p-values and the p-values that we supplied at the beginning, see that they are equal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df48c2b1-9025-4683-93a5-13af6389480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(pseq, pseq2, type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9095a475-d7be-49a6-a631-3a0bdeb6d69d",
   "metadata": {},
   "source": [
    "Now let's get the densities - the instant rate of change in CDF - corresponding to quantile values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d521baf8-fbdf-4d2f-9be7-4b738a458801",
   "metadata": {},
   "outputs": [],
   "source": [
    "dseq <- dnorm(qseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41544bcb-956b-421b-98c2-643dc1b68a13",
   "metadata": {},
   "source": [
    "Plot of densities across quantile values form the probability density function PDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1156f7-d710-438b-9320-19c60a649cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(qseq, dseq, type = \"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c68c5e-00ba-4ec1-856b-614fcb0a9daa",
   "metadata": {},
   "source": [
    "## Resources on Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b38ac2-9e05-4ee8-883c-9a200538b7d7",
   "metadata": {},
   "source": [
    "Normal distribution is more than just some fancy mathematical function creating a certain bell shape. It is a natural outcome of the naive forces of nature and that's why normal distribution is so ubiquitous in statistics and in many aspects of the world.\n",
    "\n",
    "Some suggested further non-technical and semi-technical reading can be found below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4431d080-de71-43cf-98d1-3df24cdc703b",
   "metadata": {},
   "source": [
    "- Chapter 3 \"Adolphe Quetelet's Bell Curve Bridge\" from \"Bernoulli's Fallacy\" by Clayton (2021), is an excellent account on the history of and the reasoning behind the development of normal distribution\n",
    "\n",
    "- Chapter 7 \"The central, Gaussian or normal distribution\" from \"Probability Theory: The Logic of Science\" by Jaynes (2003) includes some great ideas behind normal distribution's ubiquity also borrowing ideas from information theory and entropy, especially in section 7.6 \"Why the ubiquitous use of Gaussian distributions?\" and section 7.7 \"Why the ubiquitous success?\". The chapter also includes some rigorous proof that you can skip.\n",
    "\n",
    "- The paper titled \"The Evolution of the Normal Distribution\" by Stahl (2006) is a detailed and accessible account on the history of the mathematical derivation of the normal distribution.\n",
    "\n",
    "- Page 76 from \"Statistical Rethinking: A Bayesian Course with Examples in R and Stan\" by McElreath (2020) provides some concise information to demistify the monstrous formulation of normal PDF."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
